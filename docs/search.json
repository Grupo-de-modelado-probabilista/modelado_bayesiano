[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modelado Bayesiano",
    "section": "",
    "text": "La estad√≠stica trata sobre la recolecci√≥n, organizaci√≥n, an√°lisis e interpretaci√≥n de datos, es por ello que la estad√≠stica es esencial para el correcto an√°lisis de datos.\nExisten dos grandes conjuntos de herramientas para analizar datos:\nAn√°lisis Exploratorio de Datos (EDA): Consiste en res√∫menes num√©ricos como la media, moda, desviaci√≥n est√°ndar, rangos intercuartiles, etc (esto se conoce tambi√©n como estad√≠stica descriptiva). Adem√°s hace √©nfasis en el uso de m√©todos visuales para inspeccionar los datos, como por ejemplo histogramas y gr√°ficos de dispersi√≥n.\nEstad√≠stica Inferencial: Consiste en usar datos para generar enunciados que exceden los propios datos. A veces esto implica realizar predicciones, a veces entender los detalles de alg√∫n fen√≥meno en particular o elegir entre varias explicaciones plausibles.\nMuchos de los cursos y libros sobre estad√≠stica, principalmente aquellos dirigidos a no-estad√≠sticos, ense√±an una serie de recetas que m√°s o menos tienen la siguiente forma.\nLa principal meta de estos cursos es la de ense√±ar a usar la lata adecuada y con suerte alguna que otra discusi√≥n sobre el emplatado. Esta aproximaci√≥n pedag√≥gica, dificulta entender conceptualmente la unidad de los diferentes m√©todos ense√±ados y tiene como resultado la reproducci√≥n de pr√°cticas poco transparentes y/o √∫tiles.\nEn este curso se intenta una aproximaci√≥n totalmente diferente. Tambi√©n aprenderemos recetas, pero intentaremos que los platos tengan un sabor m√°s casero y menos enlatado, aprenderemos a mezclar ingredientes frescos que se acomoden a diferentes situaciones gastron√≥micas.\nEste enfoque es posible por dos razones:"
  },
  {
    "objectID": "index.html#a-quienes-est√°-dirijido",
    "href": "index.html#a-quienes-est√°-dirijido",
    "title": "Modelado Bayesiano",
    "section": "A quienes est√° dirijido?",
    "text": "A quienes est√° dirijido?\nEste es un curso introductorio para personas sin conocimiento previo de estad√≠stica o ciencia de datos. Se asume familiaridad con Python y librer√≠as de Python usadas en an√°lisis de datos como Numpy, matplotlib, Pandas, etc.\nQuienes no sepan Python, pero tengan familiaridad con otros lenguajes de programaci√≥n tambi√©n podr√°n aprovechar el curso, aunque puede que experimente un poco m√°s de fricci√≥n.\nPor √∫ltimo quienes no tengan inter√©s en aprender a usar c√≥digo para analisis de datos pueden a√∫n aprovechar parte del material para obtener una visi√≥n a vuelo de p√°jaro de los m√©todos Bayesianos."
  },
  {
    "objectID": "index.html#c√≥mo-usar-este-material",
    "href": "index.html#c√≥mo-usar-este-material",
    "title": "Modelado Bayesiano",
    "section": "C√≥mo usar este material",
    "text": "C√≥mo usar este material\n\nVersi√≥n est√°tica: Esta p√°gina contiene una versi√≥n est√°tica del material. Es decir podr√°s ver el texto y las figuras pero no podr√°s modificarlos, ni interactuar con el material.\nVersi√≥n interactiva online: . Esta versi√≥n permite interactuar con el material, modificarlo y ejecutarlo en tu navegador.\nVersi√≥n interactiva local: Tambi√©n es posible descargar el material y ejecutarlo en tu propia computadora. Para ello hac√© click y segu√≠ las instrucciones de la pr√≥xima secci√≥n (Instalaci√≥n)."
  },
  {
    "objectID": "index.html#instalaci√≥n",
    "href": "index.html#instalaci√≥n",
    "title": "Modelado Bayesiano",
    "section": "Instalaci√≥n",
    "text": "Instalaci√≥n\nPara usar este material es necesario tener instalado Python. Se recomienda la versi√≥n 3.9 o superior. Adem√°s es necesario instalar los siguientes paquetes:\n\nPyMC 5.3.0\nArviZ 0.15.1\nPreliz 0.3.0\n\nSe recomienda instalar primero Anaconda. Luego instalar el resto de los paquetes con los comandos:\n\nconda install pip\npip install pymc==5.3.0 arviz==0.15.1 preliz==0.3.0"
  },
  {
    "objectID": "index.html#contribuciones",
    "href": "index.html#contribuciones",
    "title": "Modelado Bayesiano",
    "section": "Contribuciones",
    "text": "Contribuciones\nTodo el contenido de este repositorio es abierto, esto quiere decir que cualquier persona interesada puede contribuir al mismo. Todas las contribuciones ser√°n bien recibidas incluyendo:\n\nCorrecciones ortogr√°ficas\nNuevas figuras\nCorrecciones en el c√≥digo Python, incluidas mejoras de estilo\nMejores ejemplos\nMejores explicaciones\nCorrecciones de errores conceptuales\n\nLa forma de contribuir es v√≠a Github, es decir los cambios deber√°n ser hechos en forma de pull requests y los problemas/bugs deber√°n reportarse como Issues."
  },
  {
    "objectID": "00_Probabilidad.html#azahar-azar-y-dados",
    "href": "00_Probabilidad.html#azahar-azar-y-dados",
    "title": "1¬† Probabilidad",
    "section": "1.1 Azahar, azar y dados",
    "text": "1.1 Azahar, azar y dados\nLas palabras azahar y azar no son similares por casualidad ambas provienen de la misma palabra √°rabe que significa flor. Desde la antig√ºedad, y hasta el d√≠a de hoy, ciertos juegos, como el juego de la taba, utilizan un hueso con dos lados planos a modo de dado. De hecho se podr√≠a decir que la taba es el antecesor del dado moderno. Para facilitar distinguir un lado del otro, es com√∫n que uno de los lados est√© marcado de alguna forma. Resulta ser que los √°rabes usaban una flor. Con el tiempo el castellano adopt√≥ azahar, para designar solo ciertas flores como las del naranjo y azar como sin√≥nimo de aleatorio.\nEmpecemos, entonces imaginando que tenemos un dado de 6 caras, cada vez que arrojamos el dado solo es posible obtener un n√∫mero entero del 1-6 es decir {1, 2, 3, 4, 5, 6}. Al arrojar el dado podemos obtener cualquier de estos n√∫meros sin preferencia de uno sobre otro. Usando Python podemos programar un dado de 6 caras de la siguiente forma:\n\ndef dado():\n    semilla = time.perf_counter_ns()\n    return semilla % 6 + 1\n\ndado()\n\n6\n\n\nAl ejecutar la celda anterior repetidas veces podr√°n ver que en cada ejecuci√≥n se obtiene un n√∫mero (entero) distinto entre 1 y 6. Entender que est√° haciendo exactamente esta funci√≥n no es del todo relevante, pero si es √∫til entender la idea general detr√°s de esta funci√≥n. Veamos:\nLas computadoras son en esencia deterministas. Es decir para una misma entrada la salida ser√° siempre igual. Es como calcular \\(\\sqrt{4}\\) el resultado ser√° siempre \\(2\\). Esta consistencia es √∫til, en el funcionamiento de un desfibrilador autom√°tico, en un sistema de control a√©reo, o en una app para reproducir m√∫sica. Pero existen casos en donde necesitamos n√∫meros aleatorios, por ejemplo en probabilidad y estad√≠stica, pero tambi√©n otras √°reas como cyber-seguridad. Para esos casos existen algoritmos que a partir de un valor inicial llamado semilla son capaces de producir una secuencia de valores, que si bien es determinista, a los fines pr√°cticos tiene toda la pinta de aleatoria. Estos n√∫mero se llaman pseudoaleatorios\nEn el caso de la funci√≥n dado la semilla la generamos en la linea semilla = time.perf_counter_ns(), time.perf_counter_ns() es una funci√≥n que mide el tiempo con presici√≥n de nanosegundos. Cada vez que llamamos a dado ese valor ser√° distinto. Luego en la √∫ltima linea return semilla % 6 + 1 se calcula el resto de la divisi√≥n de la semilla por 6 y se le suma 1. Por ejemplo si la semilla fuese 12 el resto de dividir por 6 (12%6) ser√≠a 0, ya que \\(\\frac{12}{6}=2\\). Pero si la semilla fuese 10 entonces el resto de dividir por 6 (10%6) ser√≠a 4.\nSupongamos que ustedes, con justa raz√≥n, no me creen que dado realmente se comporta como un dado no trucado. Es decir, que todos los n√∫meros tienen igual chance de salir. ¬øC√≥mo podr√≠amos hacer para evaluar esta posibilidad?\n\nUna posibilidad es consultar a los astros o los √°ngeles.\nOtra ser√≠a pensar mucho sobre el problema para luego quiz√° declararse agn√≥stico sobre la truquez no solo de nuestro dado digital si no de los dados en general y a√∫n m√°s sobre la posibilidad misma de acceder al conocimiento.\nUna tercera alternativa es recolectar datos y analizarlos, esta √∫ltima es la opci√≥n preferida por quienes practican disciplinas cient√≠ficas, en particular la estad√≠stica.\n\nUsando Python podemos simular la recolecci√≥n de datos de la siguiente forma.\n\ndef experimento(N=100):\n    # llamamos a `dado` N veces y guardamos los resultados en `muestra`\n    muestra = [dado() for i in range(N)]   \n\n    # calculamos la proporci√≥n de veces que aparece cada valor en ` muestra` y lo imprimimos en pantalla\n    for i in range(1, 7):\n        print(f'{i}: {muestra.count(i)/N:.2g}')\n\nexperimento()\n\n1: 0.18\n2: 0.14\n3: 0.19\n4: 0.17\n5: 0.14\n6: 0.18\n\n\nLos n√∫meros en la primer columna son los posibles resultados. Los de la segunda columna corresponden con la frecuencia con la que aparece cada n√∫mero. La frecuencia es la cantidad de veces que aparece cada uno de los posibles resultados dividido por N. Siendo N el total de veces que arrojamos el dado.\nHay al menos dos aspectos que vale resaltar en este ejemplo:\n\nCada vez que se ejecuta la celda anterior, es decir cada vez que realizamos el experimento, se obtiene un resultado distinto. Esta es precisamente la raz√≥n de usar dados en juegos de azar, cada vez que los arrojamos obtenemos un n√∫mero que no podemos predecir con absoluta certeza.\nSi arrojamos muchas veces un mismo dado la capacidad de predecir cada una de las tiradas no mejora. En ese sentido recolectar datos no nos ayuda. Pero recolectar datos si mejora la capacidad de predecir el listado de las frecuencias, de hecho la capacidad mejora de forma consistente al aumentar N. Para un valor de N=10000 ver√°s que las frecuencias obtenidas son aproximadamente \\(0.17\\) y resulta ser que \\(0.17 \\approx \\frac{1}{6}\\) que es lo que esperado si cada n√∫mero en el dado tuviera la misma posibilidad de aparecer.\n\nEstas dos observaciones no est√°n restringidas a los dados y los juegos de azar. Si nos pes√°ramos todos los d√≠as obtendr√≠amos distintos valores ya que el peso tiene relaci√≥n con la cantidad de comida que ingerimos, el agua que tomamos, cuantos orinamos y defecamos, la precisi√≥n de la balanza, la ropa que usamos. Por todo ello una sola medida podr√≠a no ser representativa de nuestro peso. Es cierto que todas estas variaciones podr√≠an ser demasiado peque√±as para nuestro prop√≥sito y podriamos considerarlas irrelevantes, pero eso es adelantarse a nuestra discusi√≥n. El punto importante en este momento es que los datos van acompa√±ados de incertidumbre, gran parte de la estad√≠stica tiene que ver con m√©todos y pr√°cticas para lidiar con esa incertidumbre."
  },
  {
    "objectID": "00_Probabilidad.html#probabilidades",
    "href": "00_Probabilidad.html#probabilidades",
    "title": "1¬† Probabilidad",
    "section": "1.2 Probabilidades",
    "text": "1.2 Probabilidades\nEs posible utilizar probabilidades para asignar n√∫meros precisos a la incertidumbre de lo que observamos, medimos, modelamos, etc. Por ello Joseph K. Blitzstein y Jessica Hwang dicen La matem√°tica es la l√≥gica de la certeza mientras que la probabilidad es la l√≥gica de la incerteza.\nEntender como pensar en presencia de incerteza es central en Estad√≠stica y Ciencia de Datos y pr√°cticamente en cualquier disciplina cient√≠fica. Esta incerteza proviene de diversas fuentes, incluyendo datos incompletos, errores de medici√≥n, l√≠mites de los dise√±os experimentales, dificultad de observar ciertos eventos, aproximaciones, etc.\nA continuaci√≥n veremos una breve introducci√≥n a conceptos centrales en probabilidad a partir de lo cuales podremos comprender mejor los fundamentos del modelado Bayesiano. Para quienes tengan inter√©s en profundizar en el tema recomiendo leer el libro Introduction to Probability de Joseph K. Blitzstein y Jessica Hwang.\nEl marco matem√°tico para trabajar con las probabilidades se construye alrededor de los conjuntos matem√°ticos.\nEl espacio muestral \\(\\mathcal{X}\\) es el conjunto de todos los posibles resultados de un experimento. Un evento \\(A\\) es un subconjunto de \\(\\mathcal{X}\\). Decimos que \\(A\\) ha ocurrido si al realizar un experimento obtenemos como resultado \\(A\\). Si tuvi√©ramos un t√≠pico dado de 6 caras tendr√≠amos que:\n\\[\\mathcal{X} = \\{1, 2, 3, 4, 5, 6\\} \\tag {0.0}\\]\nPodemos definir al evento \\(A\\) como:\n\\[A = \\{2\\} \\tag {0.1}\\]\nSi queremos indicar la probabilidad del evento \\(A\\) escribimos \\(P(A=2)\\) o de forma abreviada \\(P(A)\\).\n\\(P(A)\\) puede tomar cualquier valor en el intervalo comprendido entre 0 y 1 (incluidos ambos extremos), en notaci√≥n de intervalos esto se escribe como [0, 1]. Es importante notar que no es necesariamente cierto que \\(P(A) = \\frac{1}{6}\\).\nAl definir el evento \\(A\\) podemos usar m√°s de un elemento de \\(\\mathcal{X}\\). Por ejemplo, n√∫meros impares \\(A = \\{1, 3, 5\\}\\), o n√∫meros mayores o iguales a 4 \\(A = \\{4,5,6\\}\\), o \\(A = \\{1,2,4,6\\}\\). Para cualquier problema concreto la definici√≥n de un evento como \\(A\\) depender√° directamente del problema.\nResumiendo, los eventos son subconjuntos de un espacio muestral definido adecuadamente y las probabilidades son n√∫meros entre 0 y 1 asociados a la posibilidad que esos eventos ocurran. Si el evento es imposible entonces la probabilidad de ese evento ser√° exactamente 0, si en cambio el evento sucede siempre entonces la probabilidad de ese evento ser√° de 1. Todos los valores intermedios reflejan grados de incerteza. Desde este punto de vista es natural preguntarse cual es la probabilidad que la masa de Saturno sea \\(x\\) kg, o hablar sobre la probabilidad de lluvia durante el 25 de Mayo de 1810, o la probabilidad de que ma√±ana amanezca.\nEsta interpretaci√≥n del concepto de probabilidad como medida de incertidumbre se suele llamar interpretaci√≥n Bayesiana o subjetiva. Existen otras interpretaciones, por ej seg√∫n la interpretaci√≥n fecuentista una probabilidad es la proporci√≥n de veces que un evento suceder√≠a si pudieramos repetir infinitas veces una observaci√≥n bajo las mismas condiciones. Es importante destacar que estas interpretaciones son andamiajes conceptuales, interpretaciones filos√≥ficas. El aparato matem√°tico que describe las probabilidades es uno solo y no distingue entre estas u otras interpretaciones."
  },
  {
    "objectID": "00_Probabilidad.html#probabilidad-condicional",
    "href": "00_Probabilidad.html#probabilidad-condicional",
    "title": "1¬† Probabilidad",
    "section": "1.3 Probabilidad condicional",
    "text": "1.3 Probabilidad condicional\nUna probabilidad condicional es simplemente la probabilidad de un evento dado que conocemos que otro evento ha sucedido. Al preguntar cual es la probabilidad que llueva dado que est√° nublado estamos planteando una probabilidad condicional.\nDado dos eventos \\(A\\) y \\(B\\) siendo \\(P(B) > 0\\), la probabilidad de \\(A\\) dado \\(B\\) es definida como:\n\\[\nP(A \\mid B) \\triangleq \\frac{P(A, B)}{P(B)} \\tag{0.2}\n\\]\n\\(P(A, B)\\) es la probabilidad conjunta, es decir la probabiliad que suceda el evento \\(A\\) y que ocurra el evento \\(B\\), tambi√©n se suele escribir como \\(P(A \\cap B)\\), el s√≠mbolo \\(\\cap\\) indica intersecci√≥n de conjuntos.\n\\(P(A \\mid B)\\) es lo que se conoce como probabilidad condicional, y es la probabilidad de que ocurra el evento A condicionada por el conocimiento que B ha ocurrido. Por ejemplo la probabilidad que una vereda est√© mojada puede ser diferente de la probabilidad que esa vereda est√© mojada dado que est√° lloviendo.\nUna probabilidad condicional se puede visualizar como la reducci√≥n del espacio muestral. Para ver esto de forma m√°s clara vamos a usar una figura adaptada del libro Introduction to Probability de Joseph K. Blitzstein y Jessica Hwang. En ella se puede ver como pasamos de tener los eventos \\(A\\) y \\(B\\) en el espacio muestral \\(\\mathcal{X}\\), en el primer cuadro, a tener \\(P(A \\mid B)\\) en el √∫ltimo cuadro donde el espacio muestral se redujo de \\(\\mathcal{X}\\) a \\(B\\).\n\nEl concepto de probabilidad condicional est√° en el coraz√≥n de la estad√≠stica y es central para pensar en como debemos actualizar el conocimiento que tenemos de un evento a la luz de nuevos datos. Veremos m√°s sobre esto en los proximos cap√≠tulos. Por ahora dejamos este tema con la siguiente aclaraci√≥n. Desde el punto de vista pr√°ctico, todas las probabilidades son condicionales (respecto de alg√∫n supuesto o modelo) a√∫n cuando no lo expresemos expl√≠citamente, no existen probabilidades sin contexto."
  },
  {
    "objectID": "00_Probabilidad.html#distribuciones-de-probabilidad",
    "href": "00_Probabilidad.html#distribuciones-de-probabilidad",
    "title": "1¬† Probabilidad",
    "section": "1.4 Distribuciones de probabilidad",
    "text": "1.4 Distribuciones de probabilidad\nA nosotros en general no nos interesar√° calcular la probabilidad de eventos concretos sino que nos interesar√° calcular distribuciones de probabilidad. Es decir, en vez de calcular la probabilidad de obtener el n√∫mero 5 al arrojar un dado, nos interesar√° averiguar el listado de todas las posibilidades del dado (1 al 6). Una vez obtenido este listado podremos hacer preguntas como ¬øCu√°l es la probabilidad de obtener el n√∫mero 5?, ¬øCu√°nto m√°s probable es obtener n√∫mero pares que impares? u otras preguntas relacionadas. El nombre formal de este listado es distribuci√≥n de probabilidad.\nEn el ejemplo del dado obtuvimos una distribuci√≥n de probabilidad emp√≠rica, es decir una distribuci√≥n calculada a partir de datos. Pero tambi√©n existen distribuciones te√≥ricas, las cuales son centrales en estad√≠stica entre otras razones por que permiten construir modelos probabilistas.\nLas distribuciones de probabilidad te√≥ricas tienen formulas matem√°ticas precisas, de forma similar a como las circunferencias tienen una definici√≥n matem√°tica precisa.\n\nUna circunferencia es el lugar geom√©trico de los puntos de un plano que equidistan a otro punto llamado centro.\n\nDado el par√°metro radio una circunferencia queda perfectamente definida. Si necesit√°ramos ubicar la circunferencia respecto de otros objetos en el plano, necesitar√≠amos adem√°s las coordenadas del centro, pero omitamos ese detalle por el momento.\nVeamos el siguiente ejemplo:\n\ndef dibuja_circ(radio):\n    _, ax = plt.subplots(figsize=(2, 2))\n    x = np.linspace(0, 2*np.pi, 100)\n    ax.plot(radio*np.cos(x), radio*np.sin(x))\n    ax.set_xlim(-11, 11)\n    ax.set_ylim(-11, 11)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n\ninteract(dibuja_circ,\n         radio=ipyw.FloatSlider(min=0.5, max=10, step=0.5, value=2.));\n\n\n\n\nPodr√≠amos decir que no existe una sola circunferencia, sino una familia de circunferencias donde cada miembro se diferencia del resto solo por el valor del par√°metro radio, ya que una vez definido este par√°metro la circunferencia queda definida.\nDe forma similar las distribuciones de probabilidad vienen en familias cuyos miembros quedan definidos por uno o m√°s par√°metros. Es com√∫n que los nombres de los par√°metros de las distribuciones de probabilidad sean letras del alfabeto griego, aunque esto no es siempre as√≠.\nEn el siguiente ejemplo tenemos una distribuci√≥n de probabilidad que podr√≠amos usar para representar un dado y que es controlada por dos par√°metros \\(\\alpha\\) y \\(\\beta\\):\n\ndef dist_dado(Œ±, Œ≤):\n    n = 5\n    x = np.arange(0, 6)\n    dist_pmf = special.binom(n, x) * (special.beta(x+Œ±, n-x+Œ≤) / special.beta(Œ±, Œ≤))\n    plt.vlines(x, 0, dist_pmf, colors='C0', lw=4)\n    plt.ylim(0, 1)\n    plt.xticks(x, x+1)\n\n\ninteract(dist_dado,\n         Œ±=ipyw.FloatSlider(min=0.5, max=10, step=0.5, value=1),\n         Œ≤=ipyw.FloatSlider(min=0.5, max=10, step=0.5, value=1));\n\n\n\n\nEsta distribuci√≥n (o familia de distribuciones) se llama beta-binomial, si cambiamos los par√°metros \\(\\alpha\\) y \\(\\beta\\) la ‚Äúforma particular‚Äù de la distribuci√≥n cambiar√°, podemos hacer que sea plana o concentrada m√°s hacia el medio o hacia uno u otro extremo, etc. As√≠ como el radio de la circunferencia debe ser positivo, los par√°metros \\(\\alpha\\) y \\(\\beta\\) tambi√©n est√°n restringidos a ser positivos."
  },
  {
    "objectID": "00_Probabilidad.html#variables-aleatorias-discretas-y-distribuciones-de-probabilidad",
    "href": "00_Probabilidad.html#variables-aleatorias-discretas-y-distribuciones-de-probabilidad",
    "title": "1¬† Probabilidad",
    "section": "1.5 Variables aleatorias discretas y distribuciones de probabilidad",
    "text": "1.5 Variables aleatorias discretas y distribuciones de probabilidad\nUna variable aleatoria es una funci√≥n que asocia n√∫meros reales \\(\\mathbb{R}\\) con un espacio muestral. Continuando con el ejemplo del dado si los eventos de inter√©s fuesen los n√∫meros del dado entonces el mapeo es simple, ya que asociamos ‚öÄ con el n√∫mero 1, ‚öÅ con el 2, etc. Si tuvi√©ramos dos dados podr√≠amos definir una variable aleatoria \\(S\\) como la suma de ambos dados. En este caso la variable aleatoria tomar√≠a los valores \\(\\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}\\) y si los dados no est√°n trucados la distribuci√≥n de probabilidad de la variable ser√≠a\n\nOtra variable aleatoria podr√≠a ser \\(C\\) cuyo espacio muestral es \\(\\{rojo, verde, azul\\}\\). Si los eventos de inter√©s fuesen rojo, verde, azul, entonces podr√≠amos codificarlos de la siguiente forma:\nC(rojo) = 0, C(verde)=1, C(azul)=2\nEsta codificaci√≥n es √∫til ya que en general es m√°s f√°cil operar con n√∫meros que con cadenas (strings), ya sea que las operaciones las hagamos manualmente o con una computadora.\nUna variable es aleatoria en el sentido de que en cada experimento es posible obtener un evento distinto sin que la sucesi√≥n de eventos siga un patr√≥n determinista. Por ejemplo si preguntamos cual es el valor de \\(C\\) tres veces seguida podr√≠amos obtener, rojo, rojo, azul o quiz√° azul, verde, azul, etc.\nCuando se habla de variables aleatorias, es com√∫n que surgan algunos malos entendidos:\n\nLa variable NO puede tomar cualquier valor imaginable, en el ejemplo de los colores solo son posibles 3 valores. En el ejemplo del dado solo 6 valores son posibles.\nAleatorio NO implica que todos los eventos tengan igual probabilidad.\n\nbien podr√≠a darse el siguiente ejemplo:\n\\[P(C=rojo) = \\frac{1}{2}, P(C=verde) = \\frac{1}{4}, P(C=azul) = \\frac{1}{4}\\]\nLa equiprobabilidad de los eventos es solo un caso especial.\n\nUna variable aleatoria discreta es una variable que puede tomar valores discretos, los cuales forman un conjunto finito (o infinito numerable). En nuestro ejemplo \\(C\\) es discreta ya que solo puede tomar 3 valores, sin posibilidad de valores intermedios entre ellos, no es posible obtener el valor verde-rojizo! \\(S\\) tambi√©n es discreta y como ya dijimos solo es posible obtener los enteros en el intervalo [2-12].\nSi en vez de ‚Äúr√≥tulos‚Äù hubi√©ramos usado el espectro continuo de longitudes onda visibles otro ser√≠a el caso, ya que podr√≠amos haber definido a \\(C=\\{400 \\text{ nm} ... 750\\text{ nm}\\}\\) y en este caso no hay dudas que ser√≠a posible obtener un valor a mitad de camino entre rojo (\\(\\approx 700 \\text{ nm}\\)) y verde (\\(\\approx 530 \\text{ nm}\\)), de hecho podemos encontrar infinitos valores entre ellos. Este ser√≠a el ejemplo de una variable aleatoria continua.\nUna variable aleatoria tiene una lista asociada con la probabilidad de cada evento. El nombre formal de esta lista es disribuci√≥n de probabilidad, en el caso particular de variables aleatorias discretas se le suele llamar tambi√©n funci√≥n de masa de probabilidad (o pmf por su sigla en ingl√©s). Es importante destacar que la \\(pmf\\) es una funci√≥n que devuelve probabilidades, por lo tanto siempre obtendremos valores comprendidos entre [0, 1] y cuya suma total (sobre todos los eventos) dar√° 1.\nEn principio nada impide que uno defina su propia distribuci√≥n de probabilidad. Pero a lo largo de los √∫ltimos 3 siglos se han identificado y estudiado muchas distribuciones de probabilidad que dado su utilidad se les ha asignado ‚Äúnombre propio‚Äù, por lo que conviene saber sobre su existencia. El siguiente listado no es exhaustivo ni tiene como prop√≥sito que memoricen las distribuciones y sus propiedades, solo que ganen cierta familiaridad con las mismas. Si en el futuro necesitan utilizar alguna \\(pmf\\) pueden volver a esta notebook o pueden revisar Wikipedia donde encontrar√°n informaci√≥n muy completa.\nEn las siguientes gr√°ficas las alturas de los puntos azules indican la probabilidad de cada valor de \\(x\\). Se indican, adem√°s, la media (\\(\\mu\\)) y desviaci√≥n est√°ndar (\\(\\sigma\\)) de las distribuciones, es importante destacar que estos valores NO son calculados a partir de datos, de hecho no hay datos solo objetos matem√°ticos. Los valores de \\(\\mu\\) y \\(\\sigma\\) son propiedades matem√°ticas de las distribuciones, de la misma forma que el √°rea de un c√≠rculo es una propiedad que queda definida una vez que fijamos el par√°metro radio.\n\n1.5.1 Distribuci√≥n uniforme discreta\nEs una distribuci√≥n que asigna igual probabilidad a un conjunto finitos de valores, su \\(pmf\\) es:\n\\[p(k \\mid a, b)={\\frac {1}{b - a + 1}} = \\frac{1}{n}\\tag {0.3}\\]\nPara valores de \\(k\\) en el intervalo [a, b], fuera de este intervalo \\(p(k) = 0\\), donde \\(n=b-a+1\\) es la cantidad total de valores que puede tomar \\(k\\).\nPodemos usar esta distribuci√≥n para modelar, por ejemplo un dado no cargado.\n\ndist = pz.DiscreteUniform(lower=1, upper=6)\nax = dist.plot_pdf(moments=\"md\", support=(0, 7))\nax.set_xlabel('x')\nax.set_ylabel('p(x)', rotation=0, labelpad=25);\n\n\n\n\nEn la figura anterior la altura de cada punto indica la probabilidad de cada evento, usamos puntos y lineas punteadas para remarcar que la distribuci√≥n es discreta. En este ejemplo en concreto la distribuci√≥n uniforme est√° definida en el intervalo [1, 6]. Por lo tanto todos los valores menores a 1 y mayores a 6 tienen probabilidad 0. Al ser una distribuci√≥n uniforme todos los puntos tienen la misma altura y esa altura es \\(\\frac{1}{6}\\).\nLos par√°metros de la distribuci√≥n discreta uniforme son dos: * El l√≠mite inferior representado con la letra ‚Äúa‚Äù en la expresi√≥n 0.3 * El l√≠mite superior representado con la letra ‚Äúb‚Äù en la expresi√≥n 0.3\nSi cambiamos los par√°metros la ‚Äúforma particular‚Äù de la distribuci√≥n cambiar√° (prueben por ejemplo reemplazar upper=6 en el bloque de c√≥digo anterior por upper=4). Es por ello que se suele hablar de familia de distribuciones, cada miembro de esa familia es una distribuci√≥n con una combinaci√≥n particular y v√°lida de par√°metros. Por ejemplo la familia de distribuciones discretas uniforme es aquella indicada en la expresi√≥n 0.3, siempre y cuando: * \\(a < b\\) * \\(a \\in \\mathbb {Z}\\) * \\(b \\in \\mathbb {Z}\\)\ndonde \\(\\mathbb {Z}\\) es el conjunto de los n√∫meros enteros.\nEs com√∫n vincular los par√°metros con cantidades que tienen sentido f√≠sico por ejemplo en un dado de 6 caras tiene sentido que \\(a=1\\) y \\(b=6\\). A veces desconocemos los valores de los par√°metros y es nuestro trabajo utilizar datos y m√©todos estad√≠sticos para encontrar esos valores.\n\n\n1.5.2 Distribuci√≥n binomial\nEs la distribuci√≥n de probabilidad discreta que cuenta el n√∫mero de √©xitos en una secuencia de \\(n\\) ensayos de Bernoulli (experimentos si/no) independientes entre s√≠, con una probabilidad fija \\(p\\) de ocurrencia del √©xito entre los ensayos. Cuando \\(n=1\\) esta distribuci√≥n se reduce a la distribuci√≥n de Bernoulli.\n\\[p(x \\mid n,p) = \\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x} \\tag {0.4}\\]\nEl t√©rmino \\(p^x(1-p)^{n-x}\\) indica la probabilidad de obtener \\(x\\) √©xitos en \\(n\\) intentos. Este t√©rmino solo tiene en cuenta el n√∫mero total de √©xitos obtenidos pero no la secuencia en la que aparecieron. El primer t√©rmino conocido como coeficiente binomial calcula todas las posibles combinaciones de \\(n\\) en \\(x\\), es decir el n√∫mero de subconjuntos de \\(x\\) elementos escogidos de un conjunto con \\(n\\) elementos.\n\ndist = pz.Binomial(n=4, p=0.5)\nax = dist.plot_pdf(moments=\"md\")\nax.set_xlabel('x')\nax.set_ylabel('p(x)', rotation=0, labelpad=25);\n\n\n\n\n\n\n1.5.3 Distribuci√≥n de Poisson\nEs una distribuci√≥n de probabilidad discreta que expresa la probabilidad que \\(x\\) eventos sucedan en un intervalo fijo de tiempo (o espacio o volumen) cuando estos eventos suceden con una tasa promedio \\(\\mu\\) y de forma independiente entre si. Se la utiliza para modelar eventos con probabilidades peque√±as (sucesos raros) como accidentes de tr√°fico o decaimiento radiactivo.\n\\[\np(x \\mid \\mu) = \\frac{\\mu^{x} e^{-\\mu}}{x!} \\tag {0.5}\n\\]\nTanto la media como la varianza de esta distribuci√≥n est√°n dadas por \\(\\mu\\).\nA medida que \\(\\mu\\) aumenta la distribuci√≥n de Poisson se aproxima a una distribuci√≥n Gaussiana (aunque sigue siendo discreta). La distribuci√≥n de Poisson tiene estrecha relaci√≥n con otra distribuci√≥n de probabilidad, la binomial. Una distribuci√≥n binomial puede ser aproximada con una distribuci√≥n de Poisson, cuando \\(n >> p\\), es decir, cuando la cantidad de ‚Äú√©xitos‚Äù (\\(p\\)) es baja respecto de la cantidad de ‚Äúintentos‚Äù (p) entonces \\(\\text{Poisson}(np) \\approx \\text{Binon}(n, p)\\). Por esta raz√≥n la distribuci√≥n de Poisson tambi√©n se conoce como ‚Äúley de los peque√±os n√∫meros‚Äù o ‚Äúley de los eventos raros‚Äù. Ojo que esto no implica que \\(\\mu\\) deba ser peque√±a, quien es peque√±o/raro es \\(p\\) respecto de \\(n\\).\n\ndist = pz.Poisson(mu=2.3)  # n√∫mero de veces que se espera que ocurra un evento.\nax = dist.plot_pdf(moments=\"md\")\nax.set_xlabel('x')\nax.set_ylabel('p(x)', rotation=0, labelpad=25);"
  },
  {
    "objectID": "00_Probabilidad.html#variables-aleatorias-y-distribuciones-de-probabilidad-continuas",
    "href": "00_Probabilidad.html#variables-aleatorias-y-distribuciones-de-probabilidad-continuas",
    "title": "1¬† Probabilidad",
    "section": "1.6 Variables aleatorias y distribuciones de probabilidad continuas",
    "text": "1.6 Variables aleatorias y distribuciones de probabilidad continuas\nHasta ahora hemos visto variables aleatorias discretas y distribuciones de masa de probabilidad. Existe otro tipo de variable aleatoria que son muy usadas y son las llamadas variables aleatorias continuas, ya que toman valores en \\(\\mathbb{R}\\).\nLa diferencia m√°s importante entre variables aleatoria discretas y continuas es que para las continuas \\(P(X=x) = 0\\), es decir, la probabilidad de cualquier valor es exactamente 0.\nEn las gr√°ficas anteriores, para variables discretas, es la altura de los puntos lo que define la probabilidad de cada evento. Si sumamos todas las alturas siempre obtenemos 1. En una distribuci√≥n continua no tenemos una cantidad finita de puntos que sumar, en cambio tenemos una cantidad infinita de puntos que definen una curva continua, la altura de esa curva es la densidad de probabilidad. Si queremos averiguar cuanto m√°s probable es el valor \\(x_1\\) respecto de \\(x_2\\) basta calcular:\n\\[\\frac{pdf(x_1)}{pdf(x_2)} \\tag {0.6}\\]\nDonde \\(pdf\\) es la funci√≥n de densidad de probabilidad (por su sigla en ingl√©s). Y es an√°loga a la \\(pmf\\) que vimos para variables discretas. Una diferencia importante es que la \\(pdf(x)\\) puede ser mayor a 1. Para obtener una probabilidad a partir de una pdf debemos integrar en un intervalo dado, ya que es el √°rea bajo la curva y no la altura lo que nos da la probabilidad, es decir es esta integral la que debe dar entre 0 y 1.\n\\[P(a \\lt X \\lt b) =  \\int_a^b pdf(x) dx\\]\nEn muchos textos es com√∫n usar \\(p\\) para referirse a la probabilidad de un evento en particular o a la \\(pmf\\) o a la \\(pdf\\), esperando que la diferencia se entienda por contexto.\nA continuaci√≥n veremos varias distribuciones continuas.\n\n1.6.1 Distribuci√≥n uniforme\nA√∫n siendo simple, la distribuci√≥n uniforme es muy usada en estad√≠stica, por ejemplo para representar nuestra ignorancia sobre el valor que pueda tomar un par√°metro.\n\\[\np(x \\mid a,b)=\\begin{cases} \\frac{1}{b-a} & para\\ a \\le x \\le b \\\\ 0 &  \\text{para el resto} \\end{cases} \\tag {0.7}\n\\]\n\ndist = pz.Uniform(0, 1)  \nx_rvs = dist.rvs(500)  # muestrear 500 valores de la distribuci√≥n\nax = dist.plot_pdf(moments=\"md\")\nax.hist(x_rvs, density=True)\nax.set_xlabel('x')\nax.set_ylabel('pdf(x)', rotation=0, labelpad=25);\n\n\n\n\nEn la figura anterior la curva azul representa la \\(pdf\\). La \\(pdf\\) es un objeto matem√°tico que da la descripci√≥n exacta de la distribuci√≥n, no es algo que exista en la realidad si no una construcci√≥n matem√°tica que es √∫til para aproximar o modelar alg√∫n aspecto de la realidad. La \\(pdf\\) es como las esferas, las esferas no existen pero pueden ser √∫tiles para describir objetos tales como pelotas, planetas, √°tomos, a√∫n cuando ni las pelotas, planetas o √°tomos sean esferas.\nEl histograma en turquesa representa una muestra tomadas a partir de la \\(pdf\\) representada en azul. A diferencia de la curva azul, que es un objeto (matem√°tico) concreto. Una muestra es aleatoria. Cada vez que ejecutemos la celda anterior la curva azul ser√° la misma pero el histograma cambiar√°.\nUna aclaraci√≥n antes de continuar. Los histogramas no son lo mismo que los gr√°ficos de barras. Los histogramas son una forma de representaci√≥n visual de datos que usa barras a fin de aproximar una distribuci√≥n continua. Si bien la cantidad de barras es discreta, la distribuci√≥n que intenta aproximar es continua, es por ello que las barras se dibujan de forma contigua, mientras que en los gr√°ficos de barras (que representan distribuciones discretas) las barras se dibujan espaciadas.\nLuego de estas aclaraciones continuemos con otras distribuciones de probabilidad continuas.\n\n\n1.6.2 Distribuci√≥n Gaussiana (o normal)\nEs quiz√° la distribuci√≥n m√°s conocida. Por un lado por que muchos fen√≥menos pueden ser descriptos (aproximadamente) usando esta distribuci√≥n. Por otro lado por que posee ciertas propiedades matem√°ticas que facilitan trabajar con ella de forma anal√≠tica. Es por ello que muchos de los resultados de la estad√≠stica se basan en asumir una distribuci√≥n Gaussiana.\nLa distribuci√≥n Gaussiana queda definida por dos par√°metros, la media \\(\\mu\\) y la desviaci√≥n est√°ndar \\(\\sigma\\). Una distribuci√≥n Gaussiana con \\(\\mu = 0\\) y \\(\\sigma = 1\\) es conocida como la distribuci√≥n Gaussiana est√°ndar.\n\\[\np(x \\mid \\mu,\\sigma) = \\frac{1}{\\sigma \\sqrt{ 2 \\pi}} e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2}} \\tag {0.8}\n\\]\n\ndist = pz.Normal(mu=0, sigma=1)  \nx_rvs = dist.rvs(500)  # muestrear 500 valores de la distribuci√≥n\nax = dist.plot_pdf(moments=\"md\")\nax.hist(x_rvs, density=True)\nax.set_xlabel('x')\nax.set_ylabel('pdf(x)', rotation=0, labelpad=25);\n\n\n\n\n\n\n1.6.3 Distribuci√≥n t de Student\nHist√≥ricamente esta distribuci√≥n surgi√≥ para estimar la media de una poblaci√≥n normalmente distribuida cuando el tama√±o de la muestra es peque√±o. En estad√≠stica Bayesiana su uso m√°s frecuente es el de generar modelos robustos a datos aberrantes.\n\\[p(x \\mid \\nu,\\mu,\\sigma) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\Gamma(\\frac{\\nu}{2})\\sqrt{\\pi\\nu}\\sigma} \\left(1+\\frac{1}{\\nu}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2\\right)^{-\\frac{\\nu+1}{2}} \\tag {0.9}\n\\]\ndonde \\(\\Gamma\\) es la funci√≥n gamma y donde \\(\\nu\\) es un par√°metro llamado grados de libertad en la mayor√≠a de los textos aunque tambi√©n se le dice grado de normalidad, ya que a medida que \\(\\nu\\) aumenta la distribuci√≥n se aproxima a una Gaussiana. En el caso extremo de \\(\\lim_{\\nu\\to\\infty}\\) la distribuci√≥n es exactamente igual a una Gaussiana.\nEn el otro extremo, cuando \\(\\nu=1\\), (aunque en realidad \\(\\nu\\) puede tomar valores por debajo de 1) estamos frente a una distribuci√≥n de Cauchy. Es similar a una Gaussiana pero las colas decrecen muy lentamente, eso provoca que en teor√≠a esta distribuci√≥n no poseen una media o varianza definidas. Es decir, es posible calcular a partir de un conjunto de datos una media, pero si los datos provienen de una distribuci√≥n de Cauchy, la dispersi√≥n alrededor de la media ser√° alta y esta dispersi√≥n no disminuir√° a medida que aumente el tama√±o de la muestra. La raz√≥n de este comportamiento extra√±o es que en distribuciones como la Cauchy est√°n dominadas por lo que sucede en las colas de la distribuci√≥n, contrario a lo que sucede por ejemplo con la distribuci√≥n Gaussiana.\nPara esta distribuci√≥n \\(\\sigma\\) no es la desviaci√≥n est√°ndar, que como ya se dijo podr√≠a estar indefinida, \\(\\sigma\\) es la escala. A medida que \\(\\nu\\) aumenta la escala converge a la desviaci√≥n est√°ndar de una distribuci√≥n Gaussiana.\n\ndist = pz.StudentT(nu=4, mu=0, sigma=2)  \nx_rvs = dist.rvs(500)  # muestrear 500 valores de la distribuci√≥n\nax = dist.plot_pdf(moments=\"md\")\nax.hist(x_rvs, density=True)\nax.set_xlabel('x')\nax.set_ylabel('pdf(x)', rotation=0, labelpad=25);\n\n\n\n\n\n\n1.6.4 Distribuci√≥n exponencial\nLa distribuci√≥n exponencial se define solo para \\(x > 0\\). Esta distribuci√≥n se suele usar para describir el tiempo que transcurre entre dos eventos que ocurren de forma continua e independiente a una taza fija. El n√∫mero de tales eventos para un tiempo fijo lo da la distribuci√≥n de Poisson.\n\\[\np(x \\mid \\lambda) = \\lambda e^{-\\lambda x} \\tag {0.10}\n\\]\nLa media y la desviaci√≥n est√°ndar de esta distribuci√≥n est√°n dadas por \\(\\frac{1}{\\lambda}\\)\nScipy usa una parametrizaci√≥n diferente donde la escala es igual a \\(\\frac{1}{\\lambda}\\)\n\ndist = pz.Exponential(3)  \nx_rvs = dist.rvs(500)  # muestrear 500 valores de la distribuci√≥n\nax = dist.plot_pdf(moments=\"md\")\nax.hist(x_rvs, density=True)\nax.set_xlabel('x')\nax.set_ylabel('pdf(x)', rotation=0, labelpad=25);\n\n\n\n\n\n\n1.6.5 Distribuci√≥n de Laplace\nTambi√©n llamada distribuci√≥n doble exponencial, ya que puede pensarse como una distribuci√≥n exponencial ‚Äúm√°s su imagen especular‚Äù. Esta distribuci√≥n surge de medir la diferencia entre dos variables exponenciales (id√©nticamente distribuidas).\n\\[p(x \\mid \\mu, b) = \\frac{1}{2b} \\exp \\left\\{ - \\frac{|x - \\mu|}{b} \\right\\} \\tag {0.11}\\]\n\ndist = pz.Laplace(0, 0.7)  \nx_rvs = dist.rvs(500)  # muestrear 500 valores de la distribuci√≥n\nax = dist.plot_pdf(moments=\"md\")\nax.hist(x_rvs, density=True)\nax.set_xlabel('x')\nax.set_ylabel('pdf(x)', rotation=0, labelpad=25);\n\n\n\n\n\n\n1.6.6 Distribuci√≥n Beta\nEs una distribuci√≥n definida en el intervalo [0, 1]. Se usa para modelar el comportamiento de variables aleatorias limitadas a un intervalo finito. Es √∫til para modelar proporciones o porcentajes.\n\\[\np(x \\mid \\alpha, \\beta)= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\, x^{\\alpha-1}(1-x)^{\\beta-1} \\tag {0.12}\n\\]\nEl primer t√©rmino es simplemente una constante de normalizaci√≥n que asegura que la integral de la \\(pdf\\) de 1. \\(\\Gamma\\) es la funci√≥n gamma. Cuando \\(\\alpha=1\\) y \\(\\beta=1\\) la distribuci√≥n beta se reduce a la distribuci√≥n uniforme.\nSi queremos expresar la distribuci√≥n beta en funci√≥n de la media y la dispersi√≥n alrededor de la media podemos hacerlo de la siguiente forma.\n\\[\\alpha = \\mu \\kappa\\] \\[\\beta = (1 ‚àí \\mu) \\kappa\\]\nSiendo \\(\\mu\\) la media y \\(\\kappa\\) una par√°metro llamado concentraci√≥n a media que \\(\\kappa\\) aumenta la dispersi√≥n disminuye. N√≥tese, adem√°s que \\(\\kappa = \\alpha + \\beta\\).\n\ndist = pz.Beta(5, 2)  \nx_rvs = dist.rvs(500)  # muestrear 500 valores de la distribuci√≥n\nax = dist.plot_pdf(moments=\"md\")\nax.hist(x_rvs, density=True)\nax.set_xlabel('x')\nax.set_ylabel('pdf(x)', rotation=0, labelpad=25);\n\n\n\n\n\n\n1.6.7 Distribuci√≥n Gamma\nScipy parametriza a la distribuci√≥n gamma usando un par√°metro \\(\\alpha\\) y uno \\(\\theta\\), usando estos par√°metros la \\(pdf\\) es:\n\\[\np(x \\mid \\alpha, \\theta) = \\frac{1}{\\Gamma(\\alpha) \\theta^\\alpha} x^{\\alpha \\,-\\, 1} e^{-\\frac{x}{\\theta}} \\tag {0.13}\n\\]\nUna parametrizaci√≥n m√°s com√∫n en estad√≠stica Bayesiana usa los par√°metros \\(\\alpha\\) y \\(\\beta\\), siendo \\(\\beta = \\frac{1}{\\theta}\\). En este caso la pdf queda como:\n\\[\np(x \\mid \\alpha, \\beta) = \\frac{\\beta^{\\alpha}x^{\\alpha-1}e^{-\\beta x}}{\\Gamma(\\alpha)} \\tag {0.14}\n\\]\nLa distribuci√≥n gamma se reduce a la exponencial cuando \\(\\alpha=1\\).\n\ndist = pz.Gamma(alpha=3, beta=0.5)\nx_rvs = dist.rvs(500)  # muestrear 500 valores de la distribuci√≥n\nax = dist.plot_pdf(moments=\"md\")\nax.hist(x_rvs, density=True)\nax.set_xlabel('x')\nax.set_ylabel('pdf(x)', rotation=0, labelpad=25);"
  },
  {
    "objectID": "00_Probabilidad.html#valor-esperado",
    "href": "00_Probabilidad.html#valor-esperado",
    "title": "1¬† Probabilidad",
    "section": "1.7 Valor esperado",
    "text": "1.7 Valor esperado\nEl valor esperado (tambi√©n conocido como esperanza o media) es un n√∫mero que resume el centro de masa de una distribuci√≥n. Por ejemplo, si \\(X\\) es una variable aleatoria discreta, podemos calcular su valor esperado como:\n\\[\n    \\mathbb{E}(X) = \\sum_x x P(X = x)\n\\]\nEn estad√≠stica usualmente tambi√©n queremos medir la dispersi√≥n de una distribuci√≥n, por ejemplo, para representar la incertidumbre en torno a una estimaci√≥n puntual como la media. Podemos hacer esto con la varianza, que tambi√©n es un valor esperado:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X - \\mathbb{E}X)^2 = \\mathbb{E}(X^2 ) - (\\mathbb{E}X)^2\n\\]\nLa varianza aparece naturalmente en muchos c√°lculos estad√≠sticos. Sin embargo, para reportar los resultados de un an√°lisis suele ser m√°s √∫til la desviaci√≥n est√°ndar, que es la ra√≠z cuadrada de la varianza. La principal ventaja es que esta √∫ltima est√° en la mismas escala/unidades que la variable aleatoria.\nEl \\(n\\)-√©simo momento de una variable aleatoria \\(X\\) es \\(\\mathbb{E}(X^n)\\), por lo que el valor esperado (media) y la varianza tambi√©n se conocen como el primer y segundo momento de una distribuci√≥n.\nUna vez fijados los par√°metros de una distribuci√≥n de probabilidad. Es posible calcularle sus momentos, el primer momento es la media y el segundo la varianza. Es importante notar que estos valores son propiedades de la distribuci√≥n y no propiedades de una muestra. Por ejemplo la media y varianza de una distribuci√≥n Beta(4, 6) es 0.4 y \\(\\approx 0.22\\), respectivamente\n\npz.Beta(4, 6).plot_pdf(moments=\"mv\");\n\n\n\n\nExisten otros momentos, el tercer momento se conoce como sesgo y habla de la asimetr√≠a de una distribuci√≥n\n\npz.Beta(4, 4).plot_pdf(moments=\"s\");\npz.Beta(4, 10).plot_pdf(moments=\"s\");\npz.Beta(10, 4).plot_pdf(moments=\"s\");\n\n\n\n\nEl cuarto momento, conocido como curtosis, nos habla del comportamiento de las colas o valores extremos. Suele calcularse de forma tal que de 0 para una Normal. Adem√°s las discusiones suelen centrarse en torno a distribuciones con curtosis positiva (como la distribuci√≥n de Laplace o Student T con \\(\\nu > 4\\)) por lo que es com√∫n hablar de exceso de curtosis. Mientras m√°s grande la curtosis de una distribuci√≥n m√°s pesadas sus colas, es decir es m√°s factible observar valores alejados de la media.\n\npz.Normal(0, 1).plot_pdf(moments=\"k\");\npz.StudentT(4.1, 0, 1).plot_pdf(moments=\"k\");\npz.Uniform(-3, 3).plot_pdf(moments=\"k\");"
  },
  {
    "objectID": "00_Probabilidad.html#distribuci√≥n-acumulada",
    "href": "00_Probabilidad.html#distribuci√≥n-acumulada",
    "title": "1¬† Probabilidad",
    "section": "1.8 Distribuci√≥n acumulada",
    "text": "1.8 Distribuci√≥n acumulada\nLa pdf (o la pmf) son formas comunes de representar y trabajar con variables aleatorias, pero no son las √∫nicas formas posibles. Existen otras representaciones equivalentes. Por ejemplo la funci√≥n de distribuci√≥n acumulada (cdf en ingl√©s). Al integrar una pdf se obtiene la correspondiente cdf, y al derivar la cdf se obtiene la pdf.\nLa integral de la pdf es llamada funci√≥n de distribuci√≥n acumulada (cdf):\n\\[\ncdf(x) = \\int_{-\\infty}^{x} pdf(x) d(x) \\tag {0.17}\n\\]\nEn algunas situaciones se prefiere hablar de la funci√≥n de supervivencia:\n\\[\nS(x) = 1 - cdf  \\tag {0.18}\n\\]\nA continuaci√≥n un ejemplo de la pdf y cdf para 4 distribuciones de la familia Gaussiana.\n\n_, ax = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\nx_valores = np.linspace(-4, 4, 500)\nvalores = [(0., .2), (0., 1.), (0., 2.), (2., .5)]\nfor val in valores:\n    pz.Normal(*val).plot_pdf(ax=ax[0])\n    pz.Normal(*val).plot_cdf(ax=ax[1])\n    ax[1].get_legend().remove()\n\n\n\n\nLa siguiente figura tomada del libro Think Stats resume las relaciones entre la cdf, pdf y pmf."
  },
  {
    "objectID": "00_Probabilidad.html#relaci√≥n-entre-probabilidad-conjunta-condicional-y-marginal",
    "href": "00_Probabilidad.html#relaci√≥n-entre-probabilidad-conjunta-condicional-y-marginal",
    "title": "1¬† Probabilidad",
    "section": "1.9 Relaci√≥n entre probabilidad conjunta, condicional y marginal",
    "text": "1.9 Relaci√≥n entre probabilidad conjunta, condicional y marginal\nAl definir probabilidad condicional usamos la expresi√≥n 0.2. Ahora que ya estamos familiarizados con las distribuciones de probabilidad podemos representar gr√°ficamente los tres t√©rminos en la expresi√≥n 0.2, tal como se muestra en la siguiente figura.\n\n\nProbabilidad conjunta \\(p(A, B)\\)\nProbabilidad marginal \\(p(A)\\) o \\(p(B)\\)\nProbabilidad condicional \\(p(A \\mid B)\\)\n\nPodemos re-escribir la expresi√≥n 0.2 de la siguiente manera:\n\\[\np(A, B) = p(A \\mid B) {p(B)}  \\tag {0.15}\n\\]\nEs decir si tomo una probabilidad condicional y la eval√∫o para todos los valores de la cantidad condicionante (\\(B\\) en este caso), obtengo la distribuci√≥n conjunta. Esto se puede ver graficamente si pensamos que \\(p(A \\mid B)\\) es una rebanada de p(A, B); rebanada que tomamos a la altura de \\(B\\). Si tomamos todas las rebanadas entonces obtendremos \\(p(A, B)\\).\nPara obtener las probabilidades marginales, que se encuentran en los margenes üòâ, podemos calcular algo similar:\n\\[\np(A) = \\sum_B p(A, B) = \\sum_B p(A \\mid B) {p(B)} \\tag {0.16}\n\\]\nCambiando la sumatoria por una integral para distribuciones continuas."
  },
  {
    "objectID": "00_Probabilidad.html#l√≠mites",
    "href": "00_Probabilidad.html#l√≠mites",
    "title": "1¬† Probabilidad",
    "section": "1.10 L√≠mites",
    "text": "1.10 L√≠mites\nLos dos teoremas m√°s conocidos y usados en probabilidad son la ley de los grandes n√∫meros y el teorema del l√≠mite central. Ambos nos dicen que le sucede a la media muestral a medida que el tama√±o de la muestra aumenta.\n\n1.10.1 La ley de los grandes n√∫meros\nEl valor promedio calculado para una muestra converge al valor esperado (media) de dicha distribuci√≥n. Esto no es cierto para algunas distribuciones como la distribuci√≥n de Cauchy (la cual no tiene media ni varianza finita).\nLa ley de los grandes n√∫meros se suele malinterpretar y dar lugar a la paradoja del apostador. Un ejemplo de esta paradoja es creer que conviene apostar en la loter√≠a/quiniela a un n√∫mero atrasado, es decir un n√∫mero que hace tiempo que no sale. El razonamiento, err√≥neo, es que como todos los n√∫meros tienen la misma probabilidad a largo plazo si un n√∫mero viene atrasado entonces hay alguna especie de fuerza que aumenta la probabilidad de ese n√∫mero en los pr√≥ximo sorteos para as√≠ re-establecer la equiprobabilidad de los n√∫meros.\n\ntama√±o_muestra = 200\nmuestras = range(1, tama√±o_muestra)\ndist = stats.uniform(0, 1)\nmedia_verdadera = dist.stats(moments='m')\n\nfor _ in range(3):\n    muestra = dist.rvs(tama√±o_muestra)\n    media_estimada = [muestra[:i].mean() for i in muestras]\n    plt.plot(muestras, media_estimada, lw=1.5)\n\nplt.hlines(media_verdadera, 0, tama√±o_muestra, linestyle='--', color='k')\nplt.ylabel(\"media\", fontsize=14)\nplt.xlabel(\"# de muestras\", fontsize=14);\n\n\n\n\n\n\n1.10.2 El teorema central del l√≠mite\nEl teorema central del l√≠mite (tambi√©n llamado teorema del l√≠mite central) establece que si tomamos \\(n\\) valores (de forma independiente) de una distribuci√≥n arbitraria la media \\(\\bar X\\) de esos valores se distribuir√° aproximadamente como una Gaussiana a medida que \\({n \\rightarrow \\infty}\\):\n\\[\n\\bar X_n \\dot\\sim \\mathcal{N} \\left(\\mu,  \\frac{\\sigma^2}{n}\\right) \\tag {0.19}\n\\]\nDonde \\(\\mu\\) y \\(\\sigma^2\\) son la media y varianza poblacionales.\nPara que el teorema del l√≠mite central se cumpla se deben cumplir los siguientes supuestos:\n\nLas variables se muestrean de forma independiente\nLas variables provienen de la misma distribuci√≥n\nLa media y la desviaci√≥n est√°ndar de la distribuci√≥n tiene que ser finitas\n\nLos criterios 1 y 2 se pueden relajar bastante y a√∫n as√≠ obtendremos aproximadamente una Gaussiana, pero del criterio 3 no hay forma de escapar. Para distribuciones como la distribuci√≥n de Cauchy, que no posen media ni varianza definida este teorema no se aplica. El promedio de \\(N\\) valores provenientes de una distribuci√≥n Cauchy no siguen una Gaussiana sino una distribuci√≥n de Cauchy.\nEl teorema del l√≠mite central explica la prevalencia de la distribuci√≥n Gaussiana en la naturaleza. Muchos de los fen√≥menos que estudiamos se pueden explicar como fluctuaciones alrededor de una media, o ser el resultado de la suma de muchos factores diferentes. Adem√°s, las Gaussianas son muy comunes en probabilidad, estad√≠stica y machine learning ya que que esta familia de distribuciones son m√°s simples de manipular matem√°ticamente que muchas otras distribuciones.\nA continuaci√≥n vemos una simulaci√≥n que nos muestra el teorema del l√≠mite central en acci√≥n.\n\niters = 2000\ndistri = stats.expon(scale=1)\nmedia, var = distri.stats(moments='mv')\n\n_, ax = plt.subplots(2, 3)\n\nfor i, n in enumerate([1, 5, 100]):\n    sample = np.mean(distri.rvs((n, iters)), axis=0)\n\n    sd = (var/n)**0.5 \n    x = np.linspace(media - 4 * sd, media + 4 * sd, 200)\n    ax[0, i].plot(x, stats.norm(media, sd).pdf(x))\n    ax[0, i].hist(sample, density=True, bins=20)\n    ax[0, i].set_title('n = {}'.format(n))\n    osm, osr = stats.probplot(sample, dist=stats.norm(media, sd), fit=False)\n    ax[1, i].plot(osm, osm)\n    ax[1, i].plot(osm, osr, 'o')\nax[1, 0].set_ylabel('observados')\nax[1, 1].set_xlabel('esperados');"
  },
  {
    "objectID": "00_Probabilidad.html#ejercicios",
    "href": "00_Probabilidad.html#ejercicios",
    "title": "1¬† Probabilidad",
    "section": "1.11 Ejercicios",
    "text": "1.11 Ejercicios\n\nDe las siguientes expresiones cual(es) se corresponde(n) con el enunciado ‚Äúla probabilidad de lluvia dado que es 25 de Mayo de 1810‚Äù?\n\np(lluvia)\np(lluvia | mayo)\np(25 de Mayo de 1810 | lluvia)\np(lluvia | 25 de Mayo de 1810 )\np(lluvia, 25 de Mayo de 1810) / p(25 de Mayo de 1810)\n\nEnuncie con palabras cada una de las expresiones del punto anterior.\nSeg√∫n la definici√≥n de probabilidad condicional\n\nCual es el valor de \\(P(A \\mid A)\\)?\nCual es la probabilidad de \\(P(A, B)\\)?\nCual es la probabilidad de \\(P(A, B)\\) en el caso especial que \\(A\\) y \\(B\\) sean independientes?\nCuando se cumple que \\(P(A \\mid B) = P(A)\\)?\nEs posible que \\(P(A \\mid B) > P(A)\\), cuando?\nEs posible que \\(P(A \\mid B) < P(A)\\), cuando?\n\n\nLos siguientes ejercicios se deben realizar usando Python (y NumPy, SciPy, Matplotlib) 1. Ilustrar que la distribuci√≥n de Poisson se aproxima a una binomial cuando para la binomial \\(n >> p\\).\n\nPara alguna de las distribuciones discretas presentadas en esta notebook verificar que la probabilidad total es 1.\nPara alguna de las distribuciones continuas presentadas en esta notebook verificar que el √°rea bajo la curva es 1.\nObtener la cdf a partir de la pdf (usar el m√©todo pdf provisto por SciPy). La funci√≥n np.cumsum puede ser de utilidad.\nObtener la pdf a partir de la cdf (usar el m√©todo cdf provisto por SciPy). La funci√≥n np.diff puede ser de utilidad.\nRepetir la simulaci√≥n para la ley de los grandes n√∫meros para al menos 3 distribuciones de probabilidad. Para cada distribuci√≥n probar m√°s de un conjunto de par√°metros.\nRepetir la simulaci√≥n para el teorema central del l√≠mite para al menos 3 distribuciones de probabilidad. Para cada distribuci√≥n probar m√°s de un conjunto de par√°metros.\nMostrar en un gr√°fico que la media \\(\\bar X\\) converge a \\(\\mu\\) y la varianza converge a \\(\\frac{\\sigma^2}{n}\\) a medida que aumenta el tama√±o de la muestra."
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#el-universo-bayesiano",
    "href": "01_Inferencia_Bayesiana.html#el-universo-bayesiano",
    "title": "2¬† Inferencia Bayesiana",
    "section": "2.1 El universo Bayesiano",
    "text": "2.1 El universo Bayesiano\nEn este curso aprenderemos sobre una forma de hacer estad√≠stica llamada usualmente estad√≠stica Bayesiana. El nombre se debe a Thomas Bayes (1702-1761) un ministro presbiteriano, y matem√°tico aficionado, quien deriv√≥ por primera vez lo que ahora conocemos como el teorema de Bayes, el cual fue publicado (postumanente) en 1763. Sin embargo una de las primeras personas en realmente desarrollar m√©todos Bayesianos, fue Pierre-Simon Laplace (1749-1827), por lo que tal vez ser√≠a un poco m√°s correcto hablar de Estad√≠stica Laplaciana y no Bayesiana.\nExiste otro paradigma estad√≠stico llamado estad√≠stica cl√°sica o frecuentista. Si ustedes han tenido un curso de estad√≠stica (ya sea en el grado o posgrado) es casi seguro que dicho curso fue sobre m√©todos frecuentistas (aun cuando esto no haya sido explicitado). Es interesante notar que mientras los or√≠genes de las estad√≠stica Bayesiana se remontan al siglo XVIII. Los m√©todos ‚Äúcl√°sicos‚Äù (o frecuentistas) fueron desarrollados principalmente durante el siglo XX! De hecho una de las motivaciones para desarrollar m√©todos frecuentistas fue un sentimiento e ideolog√≠a anti-bayesiano. A lo largo del curso nos centraremos en los m√©todos Bayesianos.\nHay dos ideas centrales que hacen que un m√©todo sea Bayesiano:\n\nToda cantidad desconocida es modelada utilizando una distribuci√≥n de probabilidad de alg√∫n tipo.\nEl teorema de Bayes es usado para actualizar dicha distribuci√≥n a la luz de los datos.\n\nEn el universo Bayesiano las cantidades conocidas son consideradas fijas y usualmente les llamamos datos. Por el contrario toda cantidad desconocida es considerada como una variable aleatoria y modelada usando una distribuci√≥n de probabilidad.\n\n2.1.1 Teorema de Bayes\nEl teorema de Bayes es una consecuencia directa de la regla del producto, veamos.\n\\[\np(\\theta, Y) = p(\\theta \\mid Y)\\; p(Y) \\\\\np(\\theta, Y) = p(Y \\mid \\theta)\\; p(\\theta)\n\\] Dado que los dos t√©rminos a la derecha de la igualdad son iguales entre si podemos escribir que:\n\\[\np(\\theta \\mid Y) \\; p(Y) = p(Y \\mid \\theta)\\; p(\\theta)\n\\]\nReordenando llegamos al Teorema de Bayes!\n\\[\np(\\theta \\mid Y) = \\frac{p(Y \\mid \\theta) p(\\theta)}{p(Y)}\n\\]\nEl cual tambi√©n suele ser escrito de la siguiente forma:\n\\[\n\\overbrace{p(\\theta \\mid Y)}^{\\text{posterior}} = \\frac{\\overbrace{p(Y \\mid \\theta)}^{\\text{likelihood}} \\overbrace{p(\\theta)}^{\\text{prior}}}{\\underbrace{\\int_{\\Theta} p(Y \\mid \\theta) p(\\theta) \\text{d}\\theta}_{\\text{likelihood marginal}}}\n\\]\nEl a priori es la forma de introducir conocimiento previo sobre los valores que pueden tomar los par√°metros. A veces cuando no sabemos demasiado se suelen usar a prioris que asignan igual probabilidad a todos los valores de los par√°metros, otras veces se puede elegir a prioris que restrijan los valores de los par√°metros a rangos razonables, algo que se conoce como regularizaci√≥n, por ejemplo solo valores positivos. Muchas veces contamos con informaci√≥n mucho m√°s precisa como medidas experimentales previas o l√≠mites impuesto por alguna teor√≠a.\nEl likelihood es la forma de incluir nuestros datos en el an√°lisis. Es una expresi√≥n matem√°tica que especifica la plausibilidad de los datos. El likelihood es central tanto en estad√≠stica Bayesiana como en estad√≠stica no-Bayesiana. A medida que la cantidad de datos aumenta el likelihood tiene cada vez m√°s peso en los resultados, esto explica el porqu√© a veces los resultados de la estad√≠stica Bayesiana y frecuentista coinciden cuando la muestra es grande.\nEl a posteriori es la distribuci√≥n de probabilidad para los par√°metros. Es la consecuencia l√≥gica de haber usado un conjunto de datos, un likelihood y un a priori. Se lo suele pensar como la versi√≥n actualizada del a priori. De hecho un a posteriori puede ser un a priori de un an√°lisis a futuro.\nLa likelihood marginal (tambi√©n llamado evidencia) es el likelihood promediado sobre todas los posibles hip√≥tesis (o conjunto de par√°metros) \\(\\theta\\), esto es equivalente a \\(p(Y)\\). En general, la evidencia puede ser vista como una simple constante de normalizaci√≥n que en la mayor√≠a de los problemas pr√°cticos puede (y suele) omitirse. Por lo que el teorema de Bayes suele aparecer escrito como:\n\\[\np(\\theta \\mid Y) \\propto p(Y \\mid \\theta) p(\\theta)\n\\]\nEl rol de todos estos t√©rminos ir√° quedando m√°s claro a medida que avancemos.\n\n\n2.1.2 El a posteriori como √∫nico estimador\nEl a posteriori representa todo lo que sabemos de un problema, dado un modelo y un conjunto de datos. Y por lo tanto cualquier cantidad que nos interese sobre el problema puede deducirse a partir de √©l. Tipicamente esto toma la forma de integrales como la siguiente.\n\\[\nJ = \\int \\varphi(\\theta) \\ \\ p(\\theta \\mid Y) d\\theta\n\\]\nPor ejemplo, para calcular la media de \\(\\theta\\) deber√≠amos reemplazar \\(\\varphi(\\theta)\\), por \\(\\theta\\):\n\\[\n\\bar \\theta = \\int \\theta \\ \\ p(\\theta \\mid Y) d\\theta\n\\]\nEsto no es m√°s que la definici√≥n de un promedio pesado, donde cada valor de \\(\\theta\\) es pesado seg√∫n la probabilidad asignada por el a posteriori.\nEn la pr√°ctica, y al usar m√©todos computacionales como los usados en este curso, estas integrales pueden aproximarse usando sumas.\n\n\n2.1.3 Estad√≠stica Bayesiana en tres pasos\nEl teorema de Bayes es el √∫nico estimador usado en estad√≠stica Bayesiana. Por lo que conceptualmente la estad√≠stica Bayesiana resulta muy simple. Seg√∫n George Box y Andrew Gelman et al.¬†(2013) la estad√≠stica Bayesiana se reduce a tres pasos:\n\nCrear un modelo probabil√≠stico. Los modelos probabil√≠sticos son historias que dan cuenta de como se generan los datos observados (o por observar). Los modelos se expresan usando distribuciones de probabilidad.\nCondicionar el modelo a los datos observados a fin de obtener el a posteriori. Usando el teorema de Bayes se actualizan las probabilidades asignadas a priori de acuerdo a los datos observados obteni√©ndose las probabilidades a posteriori.\nCriticar el ajuste del modelo generado a los datos y evaluar las consecuencias del modelo. Se puede demostrar que dada la informaci√≥n previa y los datos observados no existe otro mecanismo capaz de generar una mejor inferencia que la estad√≠stica Bayesiana. Esto parece maravilloso, pero hay un problema, solo es cierto si se asumen que los datos y el modelo son correctos. En la pr√°ctica, los datos pueden contener errores y los modelos son a duras penas aproximaciones de fen√≥menos reales. Por lo tanto es necesario realizar varias evaluaciones, incluyendo si las predicciones generadas por el modelo se ajustan a los datos observados, si las conclusiones obtenidas tienen sentido dado el marco conceptual en el que uno trabaja, la sensibilidad de los resultados a los detalles del modelo (sobre todo a detalles para los cuales no tenemos demasiada informaci√≥n), etc."
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#inferencia-bayesiana",
    "href": "01_Inferencia_Bayesiana.html#inferencia-bayesiana",
    "title": "2¬† Inferencia Bayesiana",
    "section": "2.2 Inferencia Bayesiana",
    "text": "2.2 Inferencia Bayesiana\nEn la pr√°ctica la mayor√≠a de los modelos tendr√°n m√°s de un par√°metro, pero al usar software como PyMC modelar 1 o 1000 par√°metros es m√°s o menos lo mismo. Sin embargo, esos modelos pueden distraernos de los conceptos esenciales, por lo que considero importante comenzar por el caso m√°s sencillo.\n\n2.2.1 El problema de la moneda\nA juzgar por la cantidad de ejemplos sobre monedas arrojadas al aires en libros de estad√≠stica y probabilidad, pareciera que las monedas son uno de los objetos de estudio centrales de estas disciplinas.\nUna de las razones detr√°s de la ubiquidad de este ejemplo es que las monedas son objetos familiares que facilitan discutir conceptos que de otra forma podr√≠an sonar demasiado abstractos. De todas formas quiz√° la raz√≥n m√°s importante sea que el problema puede ser modelado de forma simple y que muchos problemas reales son conceptualmente similares, de hecho cualquier problema en donde obtengamos resultados binarios (0/1, enfermo/sano, spam/no-spam, etc) puede ser pensado como si estuvi√©ramos hablando de monedas. En definitiva el modelo que veremos a continuaci√≥n (ejemplificado con monedas) sirve para cualquier situaci√≥n en la cual los datos observados solo pueden tomar dos valores mutuamente excluyentes. Debido a que estos valores son nominales y son dos, a este modelo se le llama binomial.\nEn el siguiente ejemplo trataremos de determinar el grado en que una moneda est√° sesgada. En general cuando se habla de sesgo se hace referencia a la desviaci√≥n de alg√∫n valor (por ejemplo, igual proporci√≥n de caras y cecas), pero aqu√≠ usaremos el termino sesgo de forma m√°s general. Diremos que el sesgo es un valor en el intervalo [0, 1], siendo 0 para una moneda que siempre cae ceca y 1 para una moneda que siempre cae cara y lo representaremos con la variable \\(\\theta\\). A fin de cuantificar \\(\\theta\\) arrojaremos una moneda al aire repetidas veces, por practicidad arrojaremos la moneda de forma computacional (¬°pero nada nos impide hacerlo manualmente!). Llevaremos registro del resultado en la variable \\(y\\). Siendo \\(y\\) la cantidad de caras obtenidas en un experimento.\nHabiendo definido nuestro problema debemos expresarlo en t√©rminos del teorema de Bayes,\n\\[\np(\\theta \\mid Y) \\propto p(Y \\mid  \\theta) p(\\theta)\n\\]\nDonde, como dijimos \\(\\theta = 1\\) quiere decir 100% cara y \\(\\theta = 0\\) 100% ceca.\nAhora solo restar reemplazar los dos t√©rminos a la derecha de la igualdad, el a priori y el likelihood, por distribuciones de probabilidad adecuadas y luego multiplicarlas para obtener el t√©rmino a la izquierda, el a posteriori. Como es la primera vez que haremos √©sto, lo haremos paso a paso y anal√≠ticamente. En el pr√≥ximo cap√≠tulo veremos c√≥mo hacerlo computacionalmente.\n\n\n2.2.2 Definiendo el a priori\nEl a priori lo modelaremos usando una distribuci√≥n beta, que es una distribuci√≥n muy usada en estad√≠stica Bayesiana. La \\(pdf\\) de esta distribuci√≥n es:\n\\[\np(\\theta)= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\, \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\n\\]\nEl primer t√©rmino es una constante de normalizaci√≥n. Por suerte para nuestro problema nos basta con establecer una proporcionalidad, por lo que podemos simplificar esta expresi√≥n y escribir la distribuci√≥n beta de la siguiente forma.\n\\[\np(\\theta) \\propto  \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\n\\]\nHay varias razones para usar una distribuci√≥n beta para este y otros problemas:\n\nLa distribuci√≥n beta var√≠a entre 0 y 1, de igual forma que lo hace \\(\\theta\\) en nuestro modelo.\nEsta distribuci√≥n combinada con la que elegiremos como likelihood (ver m√°s adelante), nos permitir√° resolver el problema de forma anal√≠tica.\nEs una distribuci√≥n vers√°til para expresar distintas situaciones.\n\nRespecto al √∫ltimo punto, veamos un ejemplo. Supongamos que el experimento de la moneda es realizado por tres personas. Una de ellas dice no saber nada de la moneda por lo tanto a priori todos los valores de \\(\\theta\\) son igualmente probables. La segunda persona desconf√≠a de la moneda, ya que sospecha que es una moneda trucada, por lo tanto considera que est√° sesgada, pero no sabe para cual de las dos opciones. Por √∫ltimo, la tercer persona asegura que lo m√°s probable es que \\(\\theta\\) tome un valor alrededor de 0.5 ya que as√≠ lo indican experimentos previos y an√°lisis te√≥ricos sobre tiradas de monedas. Todas estas situaciones pueden ser modeladas por la distribuci√≥n beta, como se ve a continuaci√≥n.\n\n_, axes = plt.subplots(1, 3, figsize=(12, 3), sharey=True)\nx = np.linspace(0, 1, 100)\n\nparams = [(1, 1), (0.5, 0.5), (20, 20)]\n\nfor (a, b), ax  in zip(params, axes):\n    y = pz.Beta(a, b).rv_frozen.pdf(x)\n    ax.plot(x, y)\n    ax.set_yticks([])\n    ax.set_title(f'Œ± = {a} Œ≤ = {b}')\n\n\n\n\n\ndef beta(Œ±, Œ≤):\n    x = np.linspace(0, 1, 130)\n    plt.plot(x, pz.Beta(Œ±, Œ≤).rv_frozen.pdf(x))\n    plt.yticks([])\n    plt.ylim(0, 6)\n\ninteract(beta,\n         Œ±=ipyw.FloatSlider(min=0.5, max=7, step=0.5, value=2),\n         Œ≤=ipyw.FloatSlider(min=0.5, max=7, step=0.5, value=2));\n\n\n\n\n\n\n\n\n\n2.2.3 Definiendo el likelihood\nHabiendo definido el a priori veamos ahora el likelihood. Asumiendo que el resultado obtenido al arrojar una moneda no influye en el resultado de posteriores experimentos (es decir los experimentos son independientes entre s√≠) es razonable utilizar como likelihood la distribuci√≥n binomial.\n\\[\np(y \\mid \\theta) = \\frac{N!}{y!(N-y)!} \\theta^y (1 - \\theta)^{N‚àíy}\n\\]\nDonde N es la cantidad total de experimentos (monedas arrojadas al aire) e \\(y\\) es la cantidad de caras obtenidas. A los fines pr√°cticos podr√≠amos simplificar la igualdad anterior y convertirla en una proporcionalidad, eliminando el t√©rmino \\(\\frac{N!}{y!(N-y)!}\\) ya que ese t√©rmino no depende de \\(\\theta\\) que es lo que nos interesa averiguar. Por lo que podr√≠amos establecer que:\n\\[\np(y \\mid \\theta) \\propto \\theta^y (1 - \\theta)^{N‚àíy}\n\\]\nLa elecci√≥n de esta distribuci√≥n para modelar nuestro problema es razonable ya que \\(\\theta\\) es la chance de obtener una cara al arrojar una moneda y ese hecho ha ocurrido \\(y\\) veces, de la misma forma \\(1-\\theta\\) es la chance de obtener ceca lo cual ha sido observado \\(N-y\\) veces.\n\ndef binomial(n, Œ∏):\n    plt.bar(range(n+1), pz.Binomial(n, Œ∏).rv_frozen.pmf(range(n+1)))\n    plt.xticks(range(n+1))\n    plt.ylim(0, 1);\n\ninteract(binomial, n=ipyw.IntSlider(min=1, max=10, value=1), Œ∏=ipyw.FloatSlider(min=0, max=1, step=0.05, value=0.5));\n\n\n\n\n\n\n\n\n\n2.2.4 Obteniendo el a posteriori\nSe puede demostrar que siempre que usemos como prior una funci√≥n beta y como likelihood una distribuci√≥n binomial obtendremos como resultado una distribuci√≥n a posteriori, la cual ser√° una beta con los siguientes par√°metros:\n\\[\np(\\theta \\mid y) \\propto \\operatorname{Beta}(\\alpha_{a priori} + y, \\beta_{a priori} + N - y)\n\\]\nVeamos de donde surge este resultado, seg√∫n el teorema de Bayes la distribuci√≥n a posteriori es el producto del likelihood y la distribuci√≥n a priori.\n\\[\np(\\theta \\mid y) \\propto p(y \\mid \\theta) p(\\theta)\n\\]\nPor lo tanto, en nuestro caso tendremos que:\n\\[\np(\\theta \\mid y) \\propto \\theta^y (1 - \\theta)^{N‚àíy} \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\n\\]\nReordenando, obtenemos que el a posteriori es:\n\\[\np(\\theta \\mid y) \\propto \\theta^{\\alpha-1+y}(1-\\theta)^{\\beta-1+N‚àíy}\n\\]\nEsto es una distribuci√≥n Beta (sin considerar la constante de normalizaci√≥n).\nCuando se cumple que para un cierto likelihood la forma funcional del a priori y la del a posteriori coinciden se dice que el a priori es conjugado con el likelihood. Historicamente los problemas en estad√≠stica Bayesiana estuvieron restringidos al uso de a prioris conjugados, ya que estos garantizan la tratabilidad matem√°tica del problema, es decir garantizan que es posible obtener una expresi√≥n anal√≠tica para nuestro problema. En el pr√≥ximo cap√≠tulo veremos t√©cnicas computacionales modernas que permiten calcular la distribuci√≥n a posteriori incluso cuando no se usan a prioris conjugados. Estas t√©cnicas computacionales han permitido el resurgimiento de la estad√≠stica Bayesiana en las √∫ltimas d√©cadas.\n\n\n2.2.5 Notaci√≥n y visualizaci√≥n de modelos Bayesianos\nPara representar modelos en estad√≠stica Bayesiana (y en probabilidad en general) se suele utilizar la siguiente notaci√≥n\n\\[\n\\begin{align}\n\\theta \\sim & \\operatorname{Beta}(\\alpha, \\beta) \\\\\nY \\sim & \\operatorname{Bin}(n=1, p=\\theta)\n\\end{align}\n\\]\nEl s√≠mbolo \\(\\sim\\) indica que la variable a la izquierda se distribuye seg√∫n la distribuci√≥n a la derecha. Entonces podr√≠amos decir que \\(\\mathbf{\\theta}\\) es una variable aleatoria con distribuci√≥n \\(\\operatorname{Beta}\\), y que \\(\\operatorname{Beta}\\) est√° definida por los par√°metros \\(\\alpha\\) y \\(\\beta\\), este es nuestro a priori. En la siguiente linea tenemos el likelihood el cual est√° definido por una distribuci√≥n binomial con par√°metros \\(n=1\\) y \\(p=\\theta\\).\nGr√°ficamente esto se puede representar usando los diagramas de Kruschke:\n\nEn el primer nivel (de arriba hacia abajo) se observa el a priori, luego el likelihood, y por √∫ltimo los datos. Las flechas indican la vinculaci√≥n entre las partes del modelo y el signo \\(\\sim\\) la naturaleza estoc√°stica de las variables.\n\n\n2.2.6 Obteniendo los datos\nBien, ahora que sabemos c√≥mo calcular el a posteriori, lo √∫nico que resta es conseguir los datos. En este ejemplo los datos son sint√©ticos, es decir los obtuve computacionalmente mediante un generador de n√∫meros (pseudo)aleatorios, pero bien podr√≠an haber surgido de un experimento con una moneda real.\n\n\n2.2.7 Calculando el a posteriori\nEn el pr√≥ximo cap√≠tulo veremos c√≥mo usar m√©todos computacionales para computar un a posteriori sin necesidad de derivarlo anal√≠ticamente. Esto es lo que haremos para resolver el resto de los problemas del curso. Pero dado que ya nos tomamos el trabajo de derivar anal√≠ticamente la expresi√≥n para el a posteriori vamos a usar esa expresi√≥n. Si miran el c√≥digo de la siguiente celda ver√°n que la mayor√≠a de las lineas se encargan de dibujar los resultados y no de calcularlos. El c√°lculo del a posteriori ocurre en la l√≠nea 20. Cada una de estas lineas computa el a posteriori para cada uno de los a prioris que vimos antes. El c√°lculo es simple, tan solo se computa el valor del a posteriori (usando la funci√≥n pdf de la distribuci√≥n beta provista por SciPy) para 2000 puntos igualmente espaciados entre 0 y 1 (linea 9). El loop que empieza en la linea 11 se debe a que exploraremos c√≥mo cambian las distribuciones a posteriori para distinta cantidad de datos (n_intentos). Con un c√≠rculo negro de contorno blanco se indica el valor real de \\(\\theta\\), valor que por supuesto es desconocido en una situaci√≥n real, pero conocido para m√≠, ya que los datos son sint√©ticos.\n\nplt.figure(figsize=(12, 9))\n\nn_trials = [0, 1, 2, 3, 4, 8, 16, 32, 50, 150]\ndata = [0, 1, 1, 1, 1, 4, 6, 9, 13, 48]\ntheta_real = 0.35\n\nbeta_params = [(1, 1), (0.5, 0.5), (20, 20)]\ndist = pz.Beta\nx = np.linspace(0, 1, 2000)\n\nfor idx, N in enumerate(n_trials):\n    if idx == 0:\n        plt.subplot(4, 3, 2)\n        plt.xlabel('Œ∏')\n    else:\n        plt.subplot(4, 3, idx+3)\n        plt.xticks([])\n    y = data[idx]\n    for (a_prior, b_prior) in beta_params:\n        posterior = dist(a_prior + y, b_prior + N - y).rv_frozen.pdf(x)\n        plt.fill_between(x, 0, posterior, alpha=0.7)\n\n    plt.plot(theta_real, 0, ms=9, marker='o', mec='w', mfc='k')\n    plt.plot(0, 0, label=f'{N:4d} experimentos\\n{y:4d} caras', alpha=0)\n    plt.xlim(0, 1)\n    plt.ylim(0, 12)\n    plt.legend()\n    plt.yticks([])"
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#analizando-los-resultados",
    "href": "01_Inferencia_Bayesiana.html#analizando-los-resultados",
    "title": "2¬† Inferencia Bayesiana",
    "section": "2.3 Analizando los resultados",
    "text": "2.3 Analizando los resultados\nLa primer figura del panel muestra los a priori, nuestra estimaci√≥n de \\(\\theta\\) dado que no hemos realizado ning√∫n experimento. Las sucesivas nueve figuras muestran las distribuciones a posteriori y se indica la cantidad de experimentos y de caras obtenidas. Adem√°s se puede ver un c√≠rculo negro de contorno blanco en 0.35, la cual representa el valor verdadero de \\(\\theta\\). Por supuesto que en problemas reales este valor es desconocido.\nEste ejemplo es realmente ilustrativo en varios aspectos.\n\nEl resultado de un an√°lisis Bayesiano NO es un solo valor, si no una distribuci√≥n (a posteriori) de los valores plausibles de los par√°metros (dado los datos y el modelo).\nLa dispersi√≥n o ancho de las curvas es una medida de la incertidumbre sobre los valores.\nEl valor m√°s probable viene dado por la moda de la distribuci√≥n (el pico de la distribuci√≥n).\nA√∫n cuando \\(\\frac{2}{1} = \\frac{8}{4}\\) son num√©ricamente iguales tenemos menor incertidumbre en un resultado cuando el n√∫mero de experimentos es mayor.\nDada una cantidad suficiente de datos los resultados tienden a converger sin importar el a priori usado.\nLa rapidez con la que los resultados convergen var√≠a. En este ejemplo las curvas azul y turquesa parecen converger con tan solo 8 experimentos, pero se necesitan m√°s de 50 experimentos para que las tres curvas se muestren similares. A√∫n con 150 experimentos se observan ligeras diferencias.\nPartiendo de los a priori uniforme (azul) o sesgado (turquesa) y habiendo realizado un solo experimento y observado una sola cara, lo m√°s razonable es pensar que estamos frente a una moneda con dos caras!\nLa situaci√≥n cambia dr√°sticamente al ver por primera vez una moneda caer ceca. Ahora lo m√°s probable (dado cualquiera de los tres a prioris) es inferir que \\(\\theta=0.5\\). Los valores de \\(\\theta\\) exactamente 0 o 1 se vuelven imposibles.\nEl a priori naranja es m√°s informativo que los otros dos (la distribuci√≥n esta m√°s concentrada), por ello se requiere de un n√∫mero mas grande de experimentos para ‚Äúmoverlo‚Äù.\nEl a priori uniforme (azul) es lo que se conoce como no informativo. El resultado de un an√°lisis Bayesiano usando un a priori no-informativos en general coinciden con los resultados de an√°lisis frecuentistas (en este caso el valor esperado de \\(\\theta = \\frac{y}{N}\\)).\n\n\n2.3.1 Influencia y elecci√≥n del a priori\nDe los ejemplos anteriores deber√≠a quedar claro que los a priori influencian los resultados de nuestros c√°lculos. Esto tiene total sentido si no fuese as√≠ no har√≠a falta incluirlos en el an√°lisis y todo ser√≠a m√°s simple (aunque nos perder√≠amos la oportunidad de usar informaci√≥n previa). De los ejemplos anteriores tambi√©n deber√≠a quedar claro que a medida que aumentan los datos (como las tiradas de monedas) los resultados son cada vez menos sensibles al a priori. De hecho, para una cantidad infinita de datos el a priori no tiene ning√∫n efecto. Exactamente cuantos datos son necesarios para que el efecto del a priori sea despreciable var√≠a seg√∫n el problema y los modelos usados. En el ejemplo de la moneda se puede ver que 50 experimentos bastan para hacer que dos de los resultados sean pr√°cticamente indistinguibles, pero hacen falta m√°s de 150 experimentos para que los 3 resultados se vuelvan practicamente independientes del a priori. Esto es as√≠ por que los dos primeros a prioris son relativamente planos, mientras que el tercer a priori concentra casi toda la probabilidad en una regi√≥n relativamente peque√±a. El tercer a priori no solo considera que el valor m√°s probable de \\(\\theta\\) es 0.5, si no que considera que la mayor√≠a de los otros valores son muy poco probables. ¬øC√≥mo cambiar√≠an los resultados si hubi√©ramos usado como a priori \\(\\operatorname{Beta}(\\alpha=2, \\beta=2)\\)?\nLa elecci√≥n de los a priori puede poner nervioso a quienes se inician en el an√°lisis Bayesiano (o a los detractores de este paradigma). ¬°El temor es que los a prioris censuren a los datos y no les permitan hablar por s√≠ mismos! Eso est√° muy bien, pero el punto es que los datos no saben hablar, con suerte murmuran. Los datos solo tienen sentido a la luz de los modelos (matem√°ticos y mentales) usados para interpretarlos, y los a prioris son parte de esos modelos.\nHay quienes prefieren usar a priori no-informativos (tambi√©n conocidos como a priori planos, vagos, o difusos). Estos a priori aportan la menor cantidad posible de informaci√≥n y por lo tanto tienen el menor impacto posible en el an√°lisis. Si bien es posible usarlos, en general hay razones pr√°cticas para no preferirlos. En este curso usaremos a priori ligeramente informativos siguendo las recomendaciones de Gelman, McElreath, Kruschke, y otros. En muchos problemas sabemos al menos algo de los valores posibles que pueden tomar nuestros par√°metros, por ejemplo que solo pueden ser positivos, o que est√°n restringidos a sumar 1 o el rango aproximado, etc. En esos casos podemos usar a prioris que introduzcan esta ligera informaci√≥n. En estos casos podemos pensar que la funci√≥n del a priori es la de mantener las inferencias dentro de l√≠mites razonables. Estos a priori se suelen llamar regularizadores.\nPor supuesto que tambi√©n es posible usar a prioris informativos (o fuertes). Hacer esto es razonable solo si contamos con informaci√≥n previa confiable. Esto puede ser ventajoso en casos en que los datos contengan poca informaci√≥n sobre el problema. Si la informaci√≥n no viene por el likelihood (datos), entonces puede venir por el a priori. A modo de ejemplo, en bioinform√°tica estructural es com√∫n usar toda la informaci√≥n previa posible (de forma Bayesiana y no-Bayesiana) para resolver problemas. Esto es posible por la existencia de bases de datos que almacenan los resultados de cientos o miles experimentos realizados a lo largo de d√©cadas de esfuerzo (¬°No usar esta informaci√≥n ser√≠a casi absurdo!). En resumen, si cont√°s con informaci√≥n confiable no hay raz√≥n para descartarla, menos si el argumento es algo relacionado con pretender ser objetivo (¬°No hay objetividad en negar lo que se sabe!).\nHasta ahora hemos visto que es posible clasificar, aunque sea de forma vaga o aproximada, a los a priori en funci√≥n de la informaci√≥n que contienen. Pero saber esta clasificaci√≥n no necesariamente hace las cosas m√°s simples a la hora de elegir un a priori. ¬øAcaso no ser√≠a mejor eliminar los a prioris de nuestro an√°lisis? Eso har√≠a el asunto mucho mas simple. Bueno, el punto es que desde una perspectiva Bayesiana todos los modelos tienen a prioris, aun cuando no sean expl√≠citos. De hecho muchos resultados de la estad√≠stica frecuentista pueden considerarse casos especiales de modelos Bayesianos usando a prioris planos. Volviendo a la figura anterior se puede ver que la moda del a posteriori para la curva azul. Coincide con la estimaci√≥n (puntual) frecuentista para el valor de \\(\\theta\\)\n\\[\n\\hat \\theta = {{y} \\over {N}}\n\\]\nNotar que \\(\\hat \\theta\\) es una estimaci√≥n puntual (un n√∫mero) y no una distribuci√≥n.\nEste ejemplo nos muestra que no es posible hacer an√°lisis estad√≠sticos y sacarse los a prioris de encima. Un posible corolario es que es m√°s flexible y transparente especificar los a prioris de forma expl√≠cita que esconderlos bajo la cama. Al hacerlo ganamos mayor control sobre nuestro modelo, mayor transparencia y por el mismo precio la estimaci√≥n de la incertidumbre con la que se estima cada par√°metro.\nPor √∫ltimo, hay que recordar que el modelado estad√≠stico (como otras formas de modelado) es un proceso iterativo e interactivo. Nada nos impide usar m√°s de un a priori (o un likelihood) si as√≠ lo quisi√©ramos. Una parte importante del modelado es la de cuestionar los supuestos y los a prioris son simplemente un tipo de supuestos (como lo son los likelihoods). Si tuvieramos m√°s de un a priori razonable podr√≠amos realizar un an√°lisis de sensibilidad, es decir evaluar como cambian los resultados con los a prioris, podr√≠amos llegar a la conclusi√≥n que para un rango amplio de a prioris ¬°los resultados no var√≠an! M√°s adelante veremos varias herramientas para comparar distintos modelos.\nDado que los a prioris tienen un papel central en la estad√≠stica Bayesiana, seguiremos discuti√©ndolos a medida que vayamos viendo problemas concretos. Por lo que si esta discusi√≥n no ha aclarado todas tus dudas y segu√≠s algo confundido, mejor mantener la calma y no preocuparse demasiado, este tema ha sido motivo de discusi√≥n y confusi√≥n durante d√©cadas ¬°y la discusi√≥n todav√≠a continua!\n\n\n2.3.2 Cuantificando el peso del a priori\nEn general la distribuci√≥n m√°s familiar para la mayor√≠a de las personas es la distribuci√≥n Gaussiana, como esta distribuci√≥n est√° definida por dos par√°metros, la media y la dispersi√≥n de ese valor medio, suele resultarnos natural pensar las distribuciones en esos t√©rminos. Si queremos expresar la distribuci√≥n beta en funci√≥n de la media y la dispersi√≥n podemos hacerlo de la siguiente forma:\n\\[\\begin{align}\n\\alpha &= \\mu \\kappa \\\\\n\\beta &= (1 - \\mu) \\kappa\n\\end{align}\\]\ndonde \\(\\mu\\) es la media y \\(\\kappa\\) es un par√°metro llamado concentraci√≥n. Por ejemplo si \\(\\mu=0.5\\) y \\(\\kappa=40\\), tenemos que:\n\\[\\begin{align}\n\\alpha = 0.5 \\times 40 &= 20 \\\\\n\\beta = (1-0.5) \\times 40 &= 20\n\\end{align}\\]\n\\(\\kappa\\) se puede interpretar como la cantidad de experimentos si/no que realizamos d√°ndonos como resultado la media \\(\\mu\\). Es decir el a priori no sesgado (naranja) equivale a haber arrojado una moneda 40 veces y haber obtenido como media 0.5. Es decir que si usamos ese a priori reci√©n al observar 40 experimentos si/no, los datos tendr√°n el mismo peso relativo que el a priori, por debajo de este n√∫mero el a priori contribuye m√°s que los datos al resultado final y por encima menos. El a priori azul (uniforme) equivale a haber observado a la moneda caer una vez cara y otra vez ceca (\\(\\kappa = 2\\)). Cuando \\(\\kappa < 2\\), la cosa se pone un poco extra√±a, por ejemplo el a priori sesgado (turquesa) equivale a haber observado una sola moneda (\\(\\kappa = 1\\)) pero en una especie de (a falta de mejor analog√≠a) ¬°superposici√≥n cu√°ntica de estados!\n\n\n2.3.3 Resumiendo el a posteriori\nEl resultado de un an√°lisis Bayesiano es siempre una distribuci√≥n de probabilidad.\nA la hora de comunicar los resultados de un an√°lisis Bayesiano, lo m√°s informativo es reportar la distribuci√≥n completa, aunque esto no siempre es posible o deseable, por ejemplo el a posteriori de una distribuci√≥n multidimensional es imposible de dibujar en papel. En general, se suele recurrir a distintas medidas que resumen el a priori, por ejemplo reportando la media de la distribuci√≥n a posteriori. Algo un poco m√°s informativo es reportar adem√°s un intervalo de credibilidad. Existen varios criterios para definir intervalos de credibilidad, el que usaremos en este curso (y que tambi√©n es ampliamente usado en la literatura) es lo que se conoce como intervalo de m√°s alta densidad y nos referiremos a √©l por su sigla en ingles, HDI (Highest Posterior Density interval). Un HDI es el intervalo, m√°s corto, que contiene una porci√≥n fija de la densidad de probabilidad, generalmente el 95% (aunque otros valores como 90% o 50% son comunes). Cualquier punto dentro de este intervalo tiene mayor densidad que cualquier punto fuera del intervalo. Para una distribuci√≥n unimodal, el HDI 95 es simplemente el intervalo entre los percentiles 2,5 y 97,5.\nArviZ es un paquete de Python para an√°lisis exploratorio de modelos Bayesianos. ArviZ provee de funciones que facilitan el resumir el a posteriori. Por ejemplo plot_posterior puede ser usado para generar un gr√°fico con la media y HDI. En el siguiente ejemplo en vez de un a posteriori de un ejemplo real estamos usando datos generados al azar seg√∫n una distribuci√≥n beta.\n\nmock_posterior = pz.Beta(5, 11).rvs(size=1000)\naz.plot_posterior(mock_posterior, figsize=(8, 4));\n\n\n\n\nAhora que estamos aprendiendo que es un HDI por primera vez y antes de que automaticemos el concepto conviene aclarar un par de puntos.\n\nLa elecci√≥n autom√°tica de 95% (o cualquier otro valor) es totalmente arbitraria. En principio no hay ninguna raz√≥n para pensar que describir el a posteriori con un HDI 95 sea mejor que describirlo con un HDI 98 o que no podamos usar valores como 87% o 66%. El valor de 95% es tan solo un accidente hist√≥rico. Como un sutil recordatorio de esto ArviZ usa por defecto el intervalo de 94%.\nUn intervalo de credibilidad (que es Bayesiano) no es lo mismo que un intervalo de confianza (que es frecuentista). Un intervalo de confianza es un intervalo que se define seg√∫n un nivel de confianza, en general del 95%. Un intervalo de confianza se construye de tal forma que si repiti√©ramos infinitas veces un experimento obtendr√≠amos que la proporci√≥n de intervalos que contienen el valor verdadero del par√°metro que nos interesa coincide con el nivel de confianza estipulado. Contra-intuitivamente esto no es lo mismo que decir que un intervalo en particular tiene una probabilidad \\(x\\) de contener el par√°metro (esto ser√≠a la definici√≥n de un intervalo de credibilidad, que es Bayesiano). De hecho, un intervalo de confianza en particular contiene o no contiene al valor, la teor√≠a frecuentista no nos deja hablar de probabilidades de los par√°metros, ya que estos tienen valores fijos. Si no queda clara la diferencia no te hagas problema, la diferencia entre estos dos conceptos suele ser tan dif√≠cil de entender que en la pr√°ctica estudiantes y cient√≠ficos por igual interpretan los intervalos de confianza (frecuentistas) como intervalos de credibilidad (Bayesianos).\n\n\nSi bien desde la perspectiva Bayesiana podemos afirmar que un intervalo de credibilidad nos permite asegurar que la probabilidad de un par√°metro est√° acotado en cierto rango. Siempre hay que tener presente que dicha afirmaci√≥n es correcta SOLO en sentido te√≥rico. Es decir, solo si todos los supuestos contenidos en el modelo son ciertos. Una inferencia es siempre dependiente de los datos y modelos usados."
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#distribuci√≥n-predictivas",
    "href": "01_Inferencia_Bayesiana.html#distribuci√≥n-predictivas",
    "title": "2¬† Inferencia Bayesiana",
    "section": "2.4 Distribuci√≥n predictivas",
    "text": "2.4 Distribuci√≥n predictivas\nSi bien el objeto central de la estad√≠stica Bayesiana es la distribuci√≥n a posteriori. Existen otras distribuciones muy importantes. Una de ellas es la distribuci√≥n predictiva a posteriori, otra es la distribuci√≥n predictiva a priori.\n\n2.4.1 Distribuci√≥n predictivas a posteriori\nEsta distribuci√≥n representa las predicciones \\(\\tilde{y}\\) de un modelo una vez obtenido el a posteriori. Se calcula de la siguiente manera:\n\\[\np(\\tilde{y}  \\mid  y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta\n\\]\nEs decir integramos \\(\\theta\\) de acuerdo a la distribuci√≥n a posteriori.\nComputacionalmente podemos generar muestras de esta distribuci√≥n seg√∫n el siguiente procedimiento:\n\nElegimos un valor de \\(\\theta\\) de acuerdo a la distribuci√≥n a posteriori \\(p(\\theta \\mid y)\\)\nFijamos \\(\\theta\\) en la distribuci√≥n que usamos como likelihood \\(p(\\tilde{y} \\mid \\theta)\\) y generamos una muestra aleatoria\nRepetimos desde 1, tantas veces como muestras necesitemos\n\nLos datos generados son predictivos ya que son los datos que se esperar√≠a ver por ejemplo en un futuro experimento, es decir son variables no observadas pero potencialmente observables. Como veremos en el siguiente cap√≠tulo un uso muy com√∫n para la distribuci√≥n predictiva a posteriori es compararla con los datos observados y as√≠ evaluar si el posterior calculado es razonable.\n\n\n2.4.2 Distribuci√≥n predictiva a priori\nAsi como es posible generar datos sint√©ticos desde el a posteriori. Es posible hacerlo desde el prior. En este caso la distribuci√≥n se llama distribuci√≥n predictiva a priori. Y representa los datos \\(p(Y^\\ast)\\) que el modelo espera ver antes de haber visto los datos. O m√°s formalmente antes de haber sido condicionado a los datos. Se calcula como:\n\\[\np(Y^\\ast) =  \\int_{\\Theta} p(Y^\\ast \\mid \\theta) \\; p(\\theta) \\; d\\theta\n\\]\nEs importante notar que la definici√≥n es muy similar a la distribuci√≥n predictiva a posteriori, solo que ahora integramos a lo largo del prior en vez del posterior.\nLos datos generados son predictivos ya que son los datos que el modelo esperara ver, es decir son datos no observados pero potencialmente observables. Como veremos en el siguiente cap√≠tulo un uso muy com√∫n para la distribuci√≥n predictiva a priori es compararla con nuestro conocimiento previo y as√≠ evaluar si el modelo es capaz de generar resultados razonable, incluso antes de haber incorporado los datos.\n\n\n2.4.3 Distribuci√≥n predictiva a priori y a posterior para el problema de la moneda.\nEn el caso del modelo beta-binomial es posible obtener anal√≠ticamente tanto la distribuci√≥n predictiva a priori como a posteriori y estas son:\n\\[\np(Y^\\ast) \\propto \\operatorname{Beta-binomial}(n=N, \\alpha_{a priori}, \\beta_{a priori})\n\\]\n\\[\np(\\tilde{Y}  \\mid  Y)  \\propto \\operatorname{Beta-binomial}(n=N, \\alpha_{a priori} + y, \\beta_{a priori} + N - y)\n\\]\nOmitiremos la discusi√≥n de como se obtienen estas distribuciones\n\n\n2.4.4 Cuarteto Bayesiano\nEl siguiente bloque de c√≥digo computa las distribuciones a priori, a posteriori, predictica a priori y predictiva a posteriori. En vez de usar la distribuci√≥n \\(\\operatorname{Beta-binomial}\\) para las distribuciones predictivas hemos optado por usar una aproximaci√≥n m√°s computacional y muestrear primero de la distribuciones beta y luego de la binomial. Esperamos que esta decisi√≥n contribuya a comprender mejor que representan estas distribuciones.\nEs importante notar que mientras la distribuciones a priori y a posteriori son distribuci√≥n sobre los par√°metros en un modelo, la distribuci√≥n predictivas a priori y a posteriori son distribuciones sobre los datos (predichos).\n\nfig, axes = plt.subplots(2, 2, figsize=(10, 8), sharex=\"row\", sharey=\"row\")\naxes = np.ravel(axes)\ndist = pz.Beta\na_prior = 1\nb_prior = 1\nN = 12\ny = 3\nx = np.linspace(0, 1, 100)\n\n\nprior = dist(a_prior, b_prior).rv_frozen.pdf(x)\naxes[0].fill_between(x, 0, prior)\naxes[0].set_title(\"Prior\")\naxes[0].set_yticks([])\n\n\nposterior = dist(a_prior + y, b_prior + N - y).rv_frozen.pdf(x)\naxes[1].fill_between(x, 0, posterior)\naxes[1].set_title(\"Posterior\")\n\n\nprior = dist(a_prior, b_prior).rvs(500)\nprior_predictive = np.hstack([pz.Binomial(n=N, p=p).rvs(N) for p in prior])\naxes[2].hist(prior_predictive, bins=range(0, N+2), rwidth=0.9, align=\"left\", density=True)\naxes[2].set_title(\"Prior predictive\")\n\nposterior = dist(a_prior + y, b_prior + N - y).rvs(500)\nprior_predictive = np.hstack([pz.Binomial(n=N, p=p).rvs(N) for p in posterior])\naxes[3].hist(prior_predictive, bins=range(0, N+2), rwidth=0.9, align=\"left\", density=True)\naxes[3].set_title(\"Posterior predictive\");\n\nfig.suptitle(\"Cuarteto Bayesiano\", fontweight=\"bold\", fontsize=16);"
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#resumen",
    "href": "01_Inferencia_Bayesiana.html#resumen",
    "title": "2¬† Inferencia Bayesiana",
    "section": "2.5 Resumen",
    "text": "2.5 Resumen\nEmpezamos este cap√≠tulo con una breve discusi√≥n sobre el modelado estad√≠stico y la teor√≠a de la probabilidad y teorema de Bayes que se deriva de ella. Luego utilizamos el problema de la moneda como una excusa para introducir aspectos b√°sicos del modelado Bayesiano y el an√°lisis de datos. Utilizamos este ejemplo cl√°sico para transmitir algunas de las ideas m√°s importantes de las estad√≠stica Bayesiana, fundamentalmente el uso de distribuciones de probabilidad para construir modelos y representar la incertidumbre. Tratamos de desmitificar el uso de los a prioris d√°ndoles el mismo estatus epistemol√≥gico-metodol√≥gico que otros elementos que forman parte del proceso de modelado e inferencia, como el likelihood o incluso meta-preguntas, ¬øPor qu√© me interesa este problema en particular? Concluimos el cap√≠tulo con una breve y simple descripci√≥n de c√≥mo interpretar y comunicar los resultados de un an√°lisis bayesiano.\nLa siguiente figura, inspirada en una figura de Sumio Watanabe resume el flujo de trabajo Bayesiano tal cual se describi√≥ en este cap√≠tulo.\n\n\nSuponemos que existe una distribuci√≥n verdadera que, en general, es desconocida (ya sea en la pr√°ctica o intr√≠nsecamente). De esta distribucci√≥n se obtiene una muestra finita, ya sea haciendo un experimento, una encuesta, una observaci√≥n, una simulaci√≥n, etc.\nA partir de la muestra realizamos una inferencia Bayesiana obteniendo una distribuci√≥n a posteriori. Esta distribuci√≥n es el objeto central de la estad√≠stica Bayesiana ya que contiene toda la informaci√≥n sobre un problema (de acuero al modelo y los datos).\nUna cantidad que podemos derivar del a posteriori es la distribuci√≥n predictiva a posteriori, es decir predicciones. Una forma de evaluar un modelo es comparar la distribuci√≥n predictiva a posteriori con la muestra finita que obtuvimos en primer lugar.\n\nLa figura anterior es muy general y omite varios pasos, pero contiene la idea esencial que el modelado es un proceso iterativo. En los siguientes cap√≠tulo, veremos como sumar nuevos pasos, como que hacer cuando tenemos m√°s de un modelo y profundizar sobre estos pasos y lo aprendido en este cap√≠tulo"
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#ejercicios",
    "href": "01_Inferencia_Bayesiana.html#ejercicios",
    "title": "2¬† Inferencia Bayesiana",
    "section": "2.6 Ejercicios",
    "text": "2.6 Ejercicios\n\nEl estad√≠stico Bruno de Finetti declar√≥ que ‚ÄúLas probabilidades no existen‚Äù, queriendo indicar que las probabildiades son solo una herramienta para cuantificar la incerteza y que no tienen existencia objetiva en s√≠ mismas. Edwin Jaynes, f√≠sico, declar√≥ que la teor√≠a de probabilidad es la l√≥gica de la ciencia. Discuta estos enunciados a la luz de lo expuesto en este y el anterior cap√≠tulo.\nSupongamos que tenemos dos monedas una que cae la mitad de veces cara y la mitad ceca y una moneda trucada que cae siempre cara. Si tomamos una de las monedas al azar y obtenemos cara, cual es la probabilidad que esa moneda sea la trucada.\nEst√°s en un programa de concursos: Hay tres puertas, detr√°s de una de ellas un 0km, detr√°s de las otras dos, una cup√≥n para tomar el t√© con Eduardo Feinmann. Sin saber cu√°l puerta esconde cada ‚Äúpremio‚Äù se te pide que elijas una de ella. Una vez elegida el conductor del programa (que si sabe que hay detr√°s de cada puerta), abre una de las puertas que contiene el cup√≥n para pasar un rato con Eduardo Feinmann. En ese momento el conductor te advierte que tienes la posiblidad de cambiar de puerta o quedarte con la puerta que elegiste inicialmente. ¬øCu√°l es la mejor opci√≥n?\nEn la cola del supermercado una mujer les cuenta que es madre de dos ni√±es. Asumiendo que la probabilidad a priori de ni√±a es la misma que la de ni√±o y es igual a 1/2.\n\nUstedes le preguntan si tiene alg√∫n var√≥n y la mujer dice que s√≠ ¬øCu√°l es la probabilidad que une de les ni√±es sea ni√±a?\nSupongamos que en vez del escenario anterior, sucede otra cosa mientras est√°n conversando aparece su hijo var√≥n y la abraza. ¬øCu√°l es la probabilidad que la mujer tenga una hija?\n\nEn una escena del crimen se encuentra sangre. La sangre es de un tipo que solo est√° presente en el 1% de la poblaci√≥n.\n\nEl fiscal enuncia: ‚ÄúSi el acusado fuese inocente, la probabilidad que tuviese el mismo tipo de sangre encontrado en la escena del crimen ser√≠a de 1%, y de 99% si fuese culpable, por lo tanto ¬°lo m√°s probable es que sea culpable!‚Äù. Este razonamiento es incorrecto, explique el porqu√©.\nEl abogado defensor enuncia: ‚ÄúEl crimen ocurri√≥ en una ciudad de 500000 habitantes por lo que 5000 personas tienen ese tipo de sangre, por lo tanto el acusado s√≥lo tiene una probabiliad de 1/5000 de ser el responsable‚Äù. Este razonamiento tambi√©n es incorrecto, explique el porqu√©.\n\nUse la siguiente funci√≥n para explorar diversas combinaciones de priors y likelihoods. Enuncie las conclusiones que considere m√°s relevantes.\n\n\ndef a_posteriori_grilla(grilla=10, a=1, b=1, caras=6, tiradas=9):\n    grid = np.linspace(0, 1, grilla)\n    prior = pz.Beta(a, b).pdf(grid)\n    likelihood = pz.Binomial(n=tiradas, p=grid).pdf(caras)\n    posterior = likelihood * prior\n    posterior /= posterior.sum()\n    _, ax = plt.subplots(1, 3, sharex=True, figsize=(16, 4))\n    ax[0].set_title('caras = {}\\ntiradas = {}'.format(caras, tiradas))\n    for i, (e, e_n) in enumerate(zip([prior, likelihood, posterior], ['a priori', 'likelihood', 'a posteriori'])):\n        ax[i].set_yticks([])\n        ax[i].plot(grid, e, 'o-', label=e_n)\n        ax[i].legend(fontsize=14)\n\n\ninteract(a_posteriori_grilla, grilla=ipyw.IntSlider(min=2, max=100, step=1, value=15), a=ipyw.FloatSlider(min=1, max=7, step=1, value=1), b=ipyw.FloatSlider(\n    min=1, max=7, step=1, value=1), caras=ipyw.IntSlider(min=0, max=20, step=1, value=6), tiradas=ipyw.IntSlider(min=0, max=20, step=1, value=9));"
  },
  {
    "objectID": "02_Programaci√≥n_probabil√≠stica.html#introducci√≥n-a-pymc",
    "href": "02_Programaci√≥n_probabil√≠stica.html#introducci√≥n-a-pymc",
    "title": "3¬† Programaci√≥n probabilista",
    "section": "3.1 Introducci√≥n a PyMC",
    "text": "3.1 Introducci√≥n a PyMC\nPyMC es un paquete para programaci√≥n probabil√≠stica bajo Python. PyMC es lo suficientemente madura para resolver muchos problemas estad√≠sticos. PyMC permite crear modelos probabil√≠sticos usando una sintaxis intuitiva y f√°cil de leer que es muy similar a la sintaxis usada para describir modelos probabil√≠sticos.\nLa mayor√≠a de las funciones de PyMC est√°n escritas en Python. Mientras que las partes computacionalmente demandantes est√°n escritas en NumPy y PyTensor. Pytensor es una biblioteca de Python que permite definir, optimizar y evaluar expresiones matem√°ticas que involucran matrices multidimensionales de manera eficiente. PyTensor es hija de Theano una librer√≠a de Python originalmente desarrollada para deep learning (que es a su vez la antesesora de TensorFlow, PyTorch, etc).\n\n3.1.1 El problema de la moneda, ahora usando PyMC y ArviZ\nA continuaci√≥n revisitaremos el problema de la moneda visto en el cap√≠tulo anterior, usando esta vez PyMC para definir nuestro modelo y hacer inferencia. Luego usaremos ArviZ para analizar el a posterori.\nA continuaci√≥n generaremos datos sint√©ticos, en este caso asumiremos que conocemos el valor the \\(\\theta\\) y lo llamaremos theta_real, y luego intentaremos averiguar este valor como si no lo conocieramos. En un problema real theta_real ser√≠a desconocido y realizar√≠amos un proceso de inferencia precisamtente para averiguar su valor.\n\nnp.random.seed(123)\nn_experimentos = 4\ntheta_real = 0.35  # en una situaci√≥n real este valor es desconocido\ndatos = pz.Binomial(n=1, p=theta_real).rvs(size=n_experimentos)\ndatos\n\narray([1, 0, 0, 0])\n\n\n\n\n3.1.2 Creaci√≥n del modelo\nAhora que tenemos nuestros datos es necesario especificar el modelo. Para ello usaremos una distribuci√≥n beta (con par√°metros \\(\\alpha=\\beta=1\\)) como a priori y la distribuci√≥n de Bernoulli como likelihood. Usando la notaci√≥n usual en estad√≠stica tenemos:\n\\[\\begin{align}\n\\theta &\\sim \\operatorname{Beta}(\\alpha=1, \\beta=1)\\\\\nY &\\sim \\operatorname{Bin}(n=1, p=\\theta)\n\\end{align}\\]\n\nCada uno de los elementos del array datos es un experimento de Bernoulli, es decir un experimento donde solo es posible obtener dos valores (0 o 1) si en cambio tuviera el n√∫mero total de ‚Äúcaras‚Äù obtenidas en varios experimentos de Bernoulli podr√≠amos modelar el likelihood como una distribuci√≥n Binomial.\n\nEsto modelo se traduce casi literalmente a PyMC, veamos:\n\nwith pm.Model() as nuestro_primer_modelo:\n    Œ∏ = pm.Beta(\"Œ∏\", alpha=1, beta=1)  # a priori\n    y = pm.Bernoulli(\"y\", p=Œ∏, observed=datos)  # likelihood\n    # y = pm.Binomial('y',n=n_experimentos, p=Œ∏, observed=sum(datos))\n\nEn la primer linea hemos creado un nuevo objeto llamado nuestro_primer_modelo. Este objeto contiene informaci√≥n sobre el modelo y las variables que lo conforman. PyMC usa el bloque with para indicar que todas las lineas que est√°n dentro de √©l hacen referencia al mismo modelo (que en este caso se llama nuestro_primer_modelo).\nLa segunda linea de c√≥digo, especifica el a priori, como pueden ver la sintaxis sigue de cerca a la notaci√≥n matem√°tica, la √∫nica diferencia es que el primer argumento es siempre una cadena que especifica el nombre de la variable aleatoria (el nombre es usado internamente por PyMC), este nombre siempre deber√° coincidir con el nombre de la variable de Python a la que se le asigna. De no ser as√≠ el c√≥digo correr√° igual, pero puede conducir a errores y confusiones al analizar el modelo.\n\nEs importante recalcar que las variables de PyMC, como \\(\\theta\\), no son n√∫meros sino objetos que representan distribuciones. Es decir objetos a partir de los cuales es posible calcular probabilidades y generar n√∫meros aleatorios.\n\nEn la tercer linea de c√≥digo se especifica el likelihood, que como ver√°n es similar a la linea anterior con la diferencia que hemos agregado un argumento llamado observed al cual le asignamos nuestros datos. Esta es la forma de indicarle a PyMC cuales son los datos. Los datos pueden ser n√∫meros, listas de Python, arrays de NumPy o data_frames de Pandas.\n\n\n3.1.3 Inferencia\nNuestro modelo ya est√° completamente especificado, lo √∫nico que nos resta hacer es obtener el a posteriori. En el cap√≠tulo anterior vimos como hacerlo de forma anal√≠tica, ahora lo haremos con m√©todos num√©ricos.\nEn PyMC la inferencia se realiza escribiendo las siguientes lineas:\n\nwith nuestro_primer_modelo:\n    idata = pm.sample(1000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ∏]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n\n\nPrimero llamamos al objeto que definimos como nuestro modelo (nuestro_primer_modelo), indicando de esta forma que es sobre ese objeto que queremos realizar la inferencia. En la segunda linea le indicamos a PyMC que deseamos 1000 muestras. Esta linea luce inocente, pero internamente PyMC est√° haciendo muchas cosas por nosotros. Algunas de las cuales son detalladas en el mensaje que se imprime en pantalla.\nVeamos este mensaje:\n\nLa primer linea indica que PyMC ha asignado el m√©todo de muestreo NUTS, el cual es un muy buen m√©todo para variables continuas.\nLa segunda linea nos da informaci√≥n sobre c√≥mo se inicializaron los valores de NUTS. Un detalle que por ahora no nos preocupa.\nLa tercer linea indica que PyMC correr√° cuatro cadenas en paralelo, es decir generar√° cuatro muestras independientes del a posteriori. Esta cantidad puede ser diferente en sus computadoras ya que es determinada autom√°ticamente en funci√≥n de los procesadores disponibles (que en mi caso, 4). sample tiene un argumento chains que permite modificar este comportamiento.\nLa cuarta linea indica qu√© variable ha sido asignada a cual m√©todo de muestreo. En este caso la informaci√≥n es redundante, ya que tenemos una sola variable, pero esto no siempre es as√≠. PyMC permite combinar m√©todos de muestreo, ya sea de forma autom√°tica basado en propiedades de las variables a muestrear o especificado por el usuario usando el argumento step.\nLa quinta linea es una barra de progreso con varias m√©tricas sobre la velocidad del muestreo, que en este caso (y para referencia futura) es muy alta. Tambi√©m indica la cantidad de cadenas usadas y la cantidad de divergencias. Tener 0 divergencias es ideal, m√°s adelante discutiremos la raz√≥n.\nPor √∫ltimo tenemos un detalle de la cantidad de muestras generadas, aunque pedimos 1000 obtuvimos 8000, la raz√≥n es que es son 1000 por cadena (4 cadenas en mi caso), es decir 4000. Todav√≠a nos queda explicar 4000 muestras extras, estas se corresponden a 1000 por cadena y son muestras que PyMC utiliza para auto-tunear el m√©todo de muestreo. Est√°s muestras son luego descartadas autom√°ticametne ya que no son muestras representativas del posterior. La cantidad de pasos que se usan para tunear el algoritmo de muestro se puede cambiar con el argumento tune de la funci√≥n pm.sample(.).\n\n\n\n3.1.4 Resumiendo el a posteriori\nPor lo general, la primer tarea a realizar luego de haber realizado un muestreo es evaluar como lucen los resultados. La funci√≥n plot_forestplot de ArviZ es muy √∫til para esta tarea.\n\naz.plot_forest(idata, combined=True, figsize=(6, 2));\n\n\n\n\nEl punto indica la media, la linea gruesa el rango intercuartial y las lineas finas el HDI 94%\n\nEs importante notar que la variable y es una variable observada, es decir conocida. Mientras que en gr√°fico anterior estamos dibujando solo \\(\\theta\\) que es la √∫nica variables desconocida, y por lo tanto muestreada.\n\nSi quisieramos un res√∫men num√©rico de los resultados podemos usar:\n\naz.summary(idata, kind=\"stats\")\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n    \n  \n  \n    \n      Œ∏\n      0.332\n      0.176\n      0.035\n      0.646\n    \n  \n\n\n\n\nComo resultado obtenemos un DataFrame con los valores de la media, la desviaci√≥n est√°ndar y el intervalo HDI 94% (hdi_3 hdi_97).\nOtra forma de resumir visualmente el a posteriori es usar la funci√≥n plot_posterior que viene con ArviZ, ya hemos utilizado esta distribuci√≥n en el cap√≠tulo anterior para un falso a posteriori. Vamos a usarlo ahora con un posterior real. Por defecto, esta funci√≥n muestra un histograma para variables discretas y KDEs para variables continuas. Tambi√©n obtenemos la media de la distribuci√≥n (podemos preguntar por la mediana o moda usando el argumento point_estimate) y el 94% HDI como una l√≠nea negra en la parte inferior de la gr√°fica. Se pueden establecer diferentes valores de intervalo para el HDI con el argumento hdi_prob. Este tipo de gr√°fica fue presentado por John K. Kruschke en su gran libro ‚ÄúDoing Bayesian Data Analysis‚Äù.\n\naz.plot_posterior(idata);"
  },
  {
    "objectID": "02_Programaci√≥n_probabil√≠stica.html#decisiones-basadas-en-el-posterior",
    "href": "02_Programaci√≥n_probabil√≠stica.html#decisiones-basadas-en-el-posterior",
    "title": "3¬† Programaci√≥n probabilista",
    "section": "3.2 Decisiones basadas en el posterior",
    "text": "3.2 Decisiones basadas en el posterior\nA veces describir el a posteriori no es suficiente, y es necesario tomar decisiones basadas en nuestras inferencias. Esto suele implicar reducir una estimaci√≥n continua a una dicot√≥mica: s√≠-no, enfermo-sano, contaminado-seguro, etc. Es posible, por ejemplo, que tengamos que decidir si la moneda est√° o no sesgada. Una moneda sesgada ser√≠a una que no caiga cara con probabilidad 0.5. Por lo tanto una forma de evaluar el sesgo es comparar el valor de referencia 0.5 contra el intervalo HPD. En la figura anterior, podemos ver que el HPD va de \\(\\approx 0.02\\) a \\(\\approx 0.71\\) y, por lo tanto, 0.5 est√° incluido en el HPD. Seg√∫n el a posterioriri la moneda parece estar sesgada hacia las cecas, pero no podemos descartar por completo el valor de 0.5. Si esta conclusi√≥n nos deja sabor a poco entonces tendremos que recopilar m√°s datos para as√≠ reducir la varianza del a posteriori o buscar informaci√≥n para definir un a priori m√°s informativo.\n\n3.2.1 ROPE\nEstrictamente la probabilidad de observar el valor exacto de 0.5 es nula, adem√°s en la pr√°ctica no nos suele interesar tener precisi√≥n infinita si no que solemos tener una idea del rango de error que es tolerable o despreciable. Una posibilidad consiste en definir lo que se conoce como regi√≥n de equivalencia pr√°ctica o ROPE (Region Of Practical Equivalence). Podr√≠amos tener buenas razones para considerar que cualquier valor entre 0,45 y 0,55 es pr√°cticamente equivalente a 0.5. No hay reglas generales para definir un ROPE ya que esta es una decisi√≥n contexto-dependiente. Para algunos problemas 0.05 podr√≠a ser mucho para otros poco, en algunos casos un rango sim√©trico es √∫til en otros es una mala idea.\nYa establecido la ROPE podemos usar las siguientes reglas para tomar una decisi√≥n:\n\nEl valor de un par√°metro es considerado improbable (o rechazado) si la totalidad de la ROPE cae por fuera del HPD 94% del par√°metro en cuesti√≥n.\nEl valor de un par√°metro es aceptado si la ROPE contiene por completo al HPD 94% del par√°metro en cuesti√≥n.\n\n\nUna ROPE es un intervalo arbitrario que se determina usando conocimiento previo y relevante sobre un tema. Cualquier valor dentro de este inervalo es considera equivalente.\n\nUsando la funci√≥n plot_posterior de ArviZ, podemos graficar el posterior junto con el HPD y la ROPE.\n\naz.plot_posterior(idata, rope=[0.45, 0.55]);\n\n\n\n\nOtra herramienta que nos puede asistir en la toma de decisiones es comparar el a posteriori con un valor de referencia. La funci√≥n plot_posterior tambi√©n nos permite hacer esto:\n\naz.plot_posterior(idata, ref_val=0.5);\n\n\n\n\nEl valor de referencia est√° indicado con una linea turquesa, junto con la proporci√≥n del posterior por debajo y por arriba del valor de referencia.\nPara una discusi√≥n m√°s detallada del uso de la ROPE pueden leer el cap√≠tulo 12 del gran libro ‚ÄúDoing Bayesian Data Analysis‚Äù de John Kruschke. Este cap√≠tulo tambi√©n discute c√≥mo realizar pruebas de hip√≥tesis de forma Bayesiana y los problemas de realizar este tipo de an√°lisis, ya sea de forma Bayesiana o no-Bayesiana.\n\n\n3.2.2 Funciones de perdida\nUna alternativa m√°s formal al uso de las ROPEs son las Funciones de p√©rdida. Para poder tomar la mejor decisi√≥n posible es necesario tener la mejor descripci√≥n posible de un problema y luego una evaluaci√≥n correcta de los costos y beneficios. Bajo el marco Bayesiano lo primero implica obtener una distribuci√≥n a posteriori, lo segundo se puede conseguir mediante la aplicaci√≥n de una funci√≥n de perdida. Una funci√≥n de perdida es una forma de medir cuan distinta es una estimaci√≥n respecto del valor real (o de referencia) de un par√°metro. Algunos ejemplos comunes son:\n\nLa perdida cuadr√°tica \\((\\theta - \\hat \\theta)^2\\)\nLa perdida absoluta $|- | $\nLa perdida 0-1 \\(I(\\theta \\ne \\hat{\\theta})\\) siendo \\(I\\) la funci√≥n indicatriz\n\nLa funci√≥n de perdida (o su inversa) reciben diversos nombres seg√∫n el campo de aplicaci√≥n como funciones de costo, funciones objetivo, funciones de fitness (sic), funciones de utilidad, etc.\nEn la pr√°ctica generalmente desconocemos el valor correcto de \\(\\theta\\) y a duras penas tendremos un posterior adecuado, por lo tanto lo que se hace es tratar de encontrar el valor de \\(\\hat \\theta\\) que minimice el valor esperado de la funci√≥n de perdida. Esto implica promediar la funci√≥n de perdida sobre todo el posterior, promediamos sobre el posterior porque desconocemos el valor de \\(\\theta\\).\nEn el siguiente ejemplo tenemos dos funciones de p√©rdida. La funci√≥n absoluta lossf_a y la cuadr√°tica lossf_b. Evaluamos cada una de las funciones para distintos valores de \\(\\hat \\theta\\) sobre una grilla de 500 puntos y encontramos el m√≠nimo.\n\n_, ax = plt.subplots(1)\ngrid = np.linspace(0, 1, 500)\nŒ∏_pos = az.extract(idata, var_names=\"Œ∏\")\nlossf_a = [np.mean(abs(i - Œ∏_pos)) for i in grid]\nlossf_b = [np.mean((i - Œ∏_pos) ** 2) for i in grid]\n\nfor i, (lossf, c) in enumerate(zip([lossf_a, lossf_b], [\"C0\", \"C1\"])):\n    mini = np.argmin(lossf)\n    ax.plot(grid, lossf, c)\n    ax.plot(\n        grid[mini],\n        lossf[mini],\n        \"o\",\n        color=c,\n        label=f\"funci√≥n de perdida {['a','b'][i]}\",\n    )\n    pos = (np.max(lossf) - np.min(lossf)) * 0.05\n    ax.annotate(f\"{grid[mini]:.2f}\", (grid[mini], lossf[mini] + pos), color=c)\n    ax.set_yticks([])\n    ax.set_xlabel(r\"$\\hat \\theta$\")\n    ax.legend()\n\n\n\n\nLas curvas son similares entre s√≠ e incluso los m√≠nimos son simialres, \\(\\hat{\\theta} \\approx 0.31\\) para lossf_a y \\(\\hat{\\theta} \\approx 0.33\\) para lossf_b\nLo que es interesante es que el primer valor se corresponde con la mediana del posterior y el segundo con su media.\n\nnp.median(Œ∏_pos).item(), np.mean(Œ∏_pos).item()\n\n(0.31254373513365896, 0.33241202565639266)\n\n\nSi bien esto no es una prueba formal, espero que haya sido un ejemplo lo suficientemente claro como para ilustrar el mensaje m√°s importante de esta secci√≥n:\n\nDiferentes funciones de p√©rdida se relacionan con diferentes estimaciones puntuales\n\nPor lo tanto, si queremos ser formales al momento de computar una estimaci√≥n puntual, debemos decidir qu√© funci√≥n de costo utilizar. O a la inversa, si elegimos una estimaci√≥n puntual implicitamente estamos eligiendo una funci√≥n de p√©rdida.\nLa ventaja de elegir explicitamente una funci√≥n de perdida es que podemos ajustarla a las necesidades de un problema particular, en vez de utilizar un criterio predefinido. En muchos casos el costo asociado a una toma de decisi√≥n es asim√©trico, esto es com√∫n en salud p√∫blica como sucede con vacunas o con la interrupci√≥n voluntaria del embarazo; procedimientos simples, baratos y seguros que previenen una gran cantidad de inconvenientes con un bajo riesgo de complicaciones.\nDado que, en general, el a posteriori toma la forma de muestras finitas almacenadas en una computadora, es posible escribir c√≥digo que refleje funciones de perdidas sin necesidad de estar acotado por la conveniencia matem√°tica o la simplicidad. El siguiente es un ejemplo bastante pavo de esto.\n\nlossf = []\nfor i in grid:\n    f = np.cos(i) * (1 - i) + np.sin(i) * (i)\n    lossf.append(f)\n\nmini = np.argmin(lossf)\nplt.plot(grid, lossf)\nplt.plot(grid[mini], lossf[mini], \"o\")\npos = (np.max(lossf) - np.min(lossf)) * 0.05\nplt.annotate(f\"{grid[mini]:.2f}\", (grid[mini], lossf[mini] + pos))\nplt.yticks([])\nplt.xlabel(r\"$\\hat \\theta$\");\n\n\n\n\nAhora bien, en la pr√°ctica no es cierto que todo el mundo elija una estimaci√≥n puntual porque realmente acuerda, o tiene presente, alguna funci√≥n de perdida en particular, en general la elecci√≥n es por conveniencia, o tradici√≥n. Se usa la mediana porque es m√°s robusta que la media a valores extremos o se usa la media porque es un concepto familiar y simple de entender, o porque pensamos que tal o cual observable es realmente un promedio de alg√∫n fen√≥meo subyacente (como mol√©culas golpeandose entre s√≠ o genes interactuando con el ambiente)."
  },
  {
    "objectID": "02_Programaci√≥n_probabil√≠stica.html#modelos-multiparam√©tricos",
    "href": "02_Programaci√≥n_probabil√≠stica.html#modelos-multiparam√©tricos",
    "title": "3¬† Programaci√≥n probabilista",
    "section": "3.3 Modelos Multiparam√©tricos",
    "text": "3.3 Modelos Multiparam√©tricos\nPr√°cticamente todos los modelos de inter√©s en estad√≠stica, son multiparam√©tricos, es decir modelos con m√°s de un par√°metro.\nSuele suceder que no todos los par√°metros requeridos para construir un modelo son de inter√©s, supongamos que quisi√©ramos estimar el valor medio de una distribuci√≥n Gaussiana, a menos que sepamos el valor real de la desviaci√≥n est√°ndar, nuestro modelo deber√° contener un par√°metro para la media y uno para la desviaci√≥n est√°ndar. Los par√°metros que no son de inmediato inter√©s pero son necesarios para definir un modelo de forma completa se llaman nuisance parameters (o par√°metro estorbo).\nEn estad√≠stica Bayesiana todos los par√°metros tienen el mismo estatus, por lo que la diferencia entre nuisance o no nuisance no es fundamental bajo ning√∫n concepto, sino que depende completamente de nuestras preguntas.\nEn principio podr√≠a parecer que incorporar par√°metros que no nos interesan es un ejercicio de futilidad. Sin embargo, es todo lo contrario, al incorporar estos par√°metros permitimos que la incertidumbre que tenemos sobre ellos se propague de forma adecuada a los resultados.\n\n3.3.1 Inferencias lum√≠nicas\nA finales del siglo XIX Simon Newcomb realiz√≥ varios experimentos para determinar la velocidad de la luz. En uno de ellos Newcomb midi√≥ el tiempo que le tomaba a la luz recorrer 7442 metros.\nA continuaci√≥n se muestra sus resultados, 66 mediciones.\n\ndatos = np.array([248.28, 248.26, 248.33, 248.24, 248.34, 247.56, 248.27, 248.16,\n                  248.4, 247.98, 248.29, 248.22, 248.24, 248.21, 248.25, 248.3,\n                  248.23, 248.29, 248.31, 248.19, 248.24, 248.2, 248.36, 248.32,\n                  248.36, 248.28, 248.25, 248.21, 248.28, 248.29, 248.37, 248.25,\n                  248.28, 248.26, 248.3, 248.32, 248.36, 248.26, 248.3, 248.22,\n                  248.36, 248.23, 248.27, 248.27, 248.28, 248.27, 248.31, 248.27,\n                  248.26, 248.33, 248.26, 248.32, 248.32, 248.24, 248.39, 248.28,\n                  248.24, 248.25, 248.32, 248.25, 248.29, 248.27, 248.28, 248.29,\n                  248.16, 248.23])\n\nSi graficamos estas medidas veremos que la distribuci√≥n parece Gaussiana excepto por dos medidas inusualmente bajas.\n\nax = az.plot_kde(datos, rug=True)\nax.set_yticks([]);\n\n\n\n\nPor simplicidad vamos a suponer que los datos siguen una distribuci√≥n Gaussiana, despu√©s de todo es lo que en general se esperar√≠a, en general, al medir una misma cosa varias veces. Una distribuci√≥n Gaussiana queda definida por dos par√°metros, la media y la desviaci√≥n est√°ndar, como desconocemos estas dos cantidades necesitamos establecer dos a prioris uno para cada par√°metro. Un modelo probabil√≠stico razonable ser√≠a el siguiente.\n\\[\\begin{align}\n\\mu &\\sim U(l, h) \\\\\n\\sigma &\\sim \\mathcal{HN}(\\sigma_{\\sigma}) \\\\\ny &\\sim \\mathcal{N}(\\mu, \\sigma)\n\\end{align}\\]\nEs decir, \\(\\mu\\) proviene de una distribuci√≥n uniforme entre los l√≠mites \\(l\\) y \\(h\\) y \\(\\sigma\\) proviene de una media-normal (half-normal) con desviaci√≥n est√°ndar \\(\\sigma_{\\sigma}\\), esta distribuci√≥n es como una Gaussiana pero restringida al rango \\([0, \\infty]\\). Por √∫ltimo los datos \\(y\\), como dijimos anteriormente, proviene de una distribuci√≥n normal, especificada por \\(\\mu\\) y \\(\\sigma\\).\nSi desconocemos por completo cuales podr√≠an ser los valores de \\(\\mu\\) y de \\(\\sigma\\), podemos fijar valores para los a prioris que reflejen nuestra ignorancia.\nPara la distribuci√≥n uniforme una opci√≥n podr√≠a ser un intervalo con l√≠mite inferior de 0 y superior de 1 segundo. El l√≠mite inferior de 0 tiene sentido ya que las velocidades no pueden ser negativas, el l√≠mite superior de un 1 segundo es un valor elevado en la escala de los datos. Otra posibilidad ser√≠a usar los datos como gu√≠a por ejemplo \\((l=datos.min() / 100, h=l+datos.min() * 100)\\). De esta forma garantizamos que el a priori contenga el rango de los datos pero que sea mucho m√°s amplio, reflejando que no tenemos demasiado informaci√≥n para fijar un a priori de forma m√°s precisa. Los Bayesianos puristas consideran usar los datos para estimar los a prioris ¬°como alta traici√≥n! Ojo con las almas de cristal (¬°en todo √°mbito!).\nBajo ciertas condiciones los a prioris uniformes puede ser problem√°ticos, tanto desde el punto de vista estad√≠stico como computacional, por lo que se recomienda evitarlos, en general se recomienda evitar a prioris con l√≠mites, como la distribuci√≥n uniforme, a menos que tengamos informaci√≥n confiable sobre esos l√≠mites. Por ejemplo sabemos que las probabilidades est√°n restringidas al intervalo [0, 1]. Pero no hay una buena raz√≥n para limitar la velocidad de la luz (bueno ¬°no la hab√≠a en los tiempos de Newcomb!).\nEn la siguiente celda podr√°n ver que he elegido un par de a prioris y hay otros comentados. Comparen c√≥mo corre el modelo con los distintos a prioris, tanto en t√©rminos de los resultados como los tiempos y calidad del muestreo.\n\nwith pm.Model() as modelo_g:\n    # los a prioris\n    Œº = pm.Uniform(\"Œº\", 240, 250)\n    # Œº = pm.Normal('Œº', 240, 100) # otro a priori alternativo\n    œÉ = pm.HalfNormal(\"œÉ\", sigma=1)\n    # œÉ = pm.HalfNormal('œÉ', sigma=datos.std() * 100)\n    # el likelihood\n    y = pm.Normal(\"y\", mu=Œº, sigma=œÉ, observed=datos)\n    idata_g = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œº, œÉ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n\n\nComo se puede ver el plot-posterior tiene ahora dos subpaneles, una por cada par√°metro. Cada uno se corresponde a una variable marginal del a posteriori que en este caso es bi-dimensional.\n\naz.plot_posterior(idata_g);\n\n\n\n\nLa siguiente figura muestra la distribuci√≥n a posteriori (que como ya mencionamos en bidimensional), junto con las distribuciones marginales para los par√°metros \\(\\mu\\) y \\(\\sigma\\).\n\naz.plot_pair(idata_g, kind=\"kde\", marginals=True);\n\n\n\n\nUna vez computado el a posteriori podemos realizar diversos c√°lculos a partir de √©l. Uno de esos c√°lculos consiste en simular datos (\\(\\tilde{y}\\)). Matem√°ticamente lo que queremos calcular es:\n\\[\\begin{equation}\np(\\tilde{y} \\,|\\, y) = \\int p(\\tilde{y} \\,|\\, \\theta) \\, p(\\theta \\,|\\, y) \\, d\\theta\n\\end{equation}\\]\ndonde:\n\\(y\\) son los datos observados mientras que \\(\\theta\\) corresponde a los par√°metros del modelo.\nSiguiendo el ejemplo de la velocidad de la luz, \\(\\theta\\) corresponde a \\(\\mu\\) y a \\(\\sigma\\). Computacionalmente podemos obtener \\(\\tilde{y}\\) de la siguiente forma:\n\nElegimos una muestra al azar de las generadas por PyMC (un valor para \\(\\mu_i\\) y \\(\\sigma_i\\))\nGeneramos un dato sint√©tico usando el mismo likelihood que usamos en el modelo, en este caso \\(\\tilde{y_i} \\sim N(\\mu_i, \\sigma_i)\\)\nRepetimos 1 y 2 hasta obtener la cantidad requerida de muestras.\n\nUsando PyMC podemos calcular esto llamando a la funci√≥n sample_ppc. El siguiente c√≥digo devuelve 100 predicciones cada una de ellas de igual tama√±o al de los datos.\n\nppc_g = pm.sample_posterior_predictive(idata_g, model=modelo_g)\n\nSampling: [y]\n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00<00:00]\n    \n    \n\n\nLos datos simulados los podemos usar para compararlos con los datos observados y de esta forma evaluar el modelo. Esto se conoce como prueba predictivas a posteriori, como ya adelantamos algo en el cap√≠tulo anterior. En la siguiente gr√°fica la linea negra corresponde a los datos observados mientras que las lineas azules (semitrasparentes) corresponden a datos predichos por el modelo.\n\naz.plot_ppc(ppc_g, num_pp_samples=200);\n\n\n\n\nSeg√∫n la gr√°fica anterior ¬øCu√°n bueno consider√°s que es nuestro modelo?\n\n\n3.3.2 Modelos robustos\nUn problema con el modelo anterior es que asume una distribuci√≥n normal pero tenemos dos puntos que caen muy alejados de los valores medios. Esos puntos podr√≠an estar alejados debido a errores experimentales en la toma de esos dos datos o podr√≠a haber un error al registrarlos o al trascribirlos. Si algo de esto sucedi√≥ podr√≠amos justificar su eliminaci√≥n de nuestro conjunto de datos (dejando registro de la eliminaci√≥n y de las razones por las cuales lo hicimos). Otra opci√≥n es usar el rango inter-cuartil (u otro m√©todo estad√≠stico) para declarar esos dos puntos como datos aberrantes ¬°y desterrarlos de nuestros datos! Otra opci√≥n es dejarlos pero utilizar un modelo m√°s robusto a valores alejados de la media.\nUno de los inconvenientes al asumir normalidad, es que la media es muy sensible a valores aberrantes. La raz√≥n est√° en la colas de la Gaussiana, a√∫n cuando las colas se extienden de \\(-\\infty\\) a \\(\\infty\\), la probabilidad de encontrar un valor cae r√°pidamente a medida que nos alejamos de la media, como se puede apreciar en la siguiente tabla que indica el porcentaje de valores que se encuentra a medida que nos alejamos de la media en unidades de desviaci√≥n est√°ndar (sd).\n\n\n\nsd\n1\n2\n3\n4\n5\n\n\n\n\n%\n68\n95\n99.7\n99.994\n99.99994\n\n\n\nUna alternativa a la distribuci√≥n Gaussiana es usar una distribuci√≥n t de Student, lo interesante de esta distribuci√≥n es que adem√°s de estar definida por una media y una escala (an√°logo de la desviaci√≥n est√°ndar) est√° definida por un par√°metro \\(\\nu\\), usualmente llamado grados de libertad, o grados de normalidad, ya que \\(\\nu\\) controla cuan pesadas son las colas de la distribuci√≥n. Cuando \\(\\nu = 1\\) (la distribuci√≥n se llama de Cauchy o de Lorentz) las colas son muy pesadas, el 95% de los puntos est√° entre -12,7 y 12,7, en cambio en una Gaussiana (con desviaci√≥n est√°ndar 1) esto ocurre entre -1,96 y 1,96. En el l√≠mite de \\(\\nu\\) tendiendo a infinito estamos en presencia de una Gaussiana. La distribuci√≥n t es realmente particular, cuando \\(\\nu <= 1\\) la distribuci√≥n no tiene media definida y la varianza solo est√° definida para valores de \\(\\nu > 2\\).\nLa siguiente figura muestra una distribuci√≥n t de Student para distintos valores de \\(\\nu\\).\n\n_, ax = plt.subplots(figsize=(10, 5))\n\nx_values = np.linspace(-10, 10, 500)\nfor df in [1, 2, 5, 20, np.inf]:\n    ax = pz.StudentT(df, 0, 1).plot_pdf(support=(-7, 7))\n\n\nax.legend(loc=\"center left\", bbox_to_anchor=(0.65, 0.5));\n\n\n\n\nAhora que conocemos la distribuci√≥n t de Student, podemos usarla en nuestro modelo:\n\\[\\begin{align}\n\\mu &\\sim U(l, h) \\\\\n\\sigma &\\sim \\mathcal{HN}(\\sigma_h) \\\\\n\\nu &\\sim Expon(\\lambda) \\\\\ny &\\sim StudentT(\\mu, \\sigma, \\nu)\n\\end{align}\\]\nEn algunos modelos puede ser buena idea sumar 1 a la distribuci√≥n exponencial a fin de asegurarse que \\(\\nu \\ge 1\\) . En principio \\(\\nu\\) puede tomar valores de [0, \\(\\infty]\\), pero en mi experiencia valores de \\(\\nu < 1\\) pueden traer problemas durante el muestreo, ya que pueden aparecer valores demasiado alejados de la media (las colas son extremadamente gordas!). Esto puede ocurrir con modelos con datos marcadamente aberrantes, veremos un ejemplo de esto en el cap√≠tulo 4.\nGr√°ficamente:\n\n\nwith pm.Model() as modelo_t:\n    # los a prioris\n    Œº = pm.Uniform(\"Œº\", 240, 250)\n    œÉ = pm.HalfNormal(\"œÉ\", sigma=100)\n    ŒΩ = pm.Exponential(\"ŒΩ\", 1 / 30)\n    # el likelihood\n    y = pm.StudentT(\"y\", mu=Œº, sigma=œÉ, nu=ŒΩ, observed=datos)\n    idata_t = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œº, œÉ, ŒΩ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\nComparemos las estimaciones entre ambos modelos\n\naz.summary(idata_g)\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      Œº\n      248.262\n      0.014\n      248.235\n      248.286\n      0.0\n      0.0\n      4325.0\n      3343.0\n      1.0\n    \n    \n      œÉ\n      0.109\n      0.010\n      0.092\n      0.128\n      0.0\n      0.0\n      3632.0\n      2723.0\n      1.0\n    \n  \n\n\n\n\n\naz.summary(idata_t)\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      Œº\n      248.274\n      0.006\n      248.262\n      248.286\n      0.000\n      0.000\n      3774.0\n      2893.0\n      1.0\n    \n    \n      œÉ\n      0.041\n      0.007\n      0.029\n      0.054\n      0.000\n      0.000\n      2315.0\n      2464.0\n      1.0\n    \n    \n      ŒΩ\n      2.578\n      0.885\n      1.156\n      4.200\n      0.018\n      0.012\n      2514.0\n      2517.0\n      1.0\n    \n  \n\n\n\n\nEn este caso, vemos que la estimaci√≥n de \\(\\mu\\) es muy similar entre los dos modelos, aunque la estimaci√≥n de \\(\\sigma\\), pas√≥ de ser de ~10 a ~4. Esto es consecuencia de que la distribuci√≥n t asigna menos peso a los valores alejados de la media que la distribuci√≥n Gaussiana.\nHagamos un prueba predictiva a posteriori para el nuevo modelo.\n\nppc_t = pm.sample_posterior_predictive(idata_t, model=modelo_t)\n\nSampling: [y]\n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00<00:00]\n    \n    \n\n\n\naz.plot_ppc(ppc_t, num_pp_samples=200)\nplt.xlim(247, 250);\n\n\n\n\n¬øQu√© conclusi√≥n se puede sacar de comparar esta prueba predictiva a posteriori con la anterior?\n\n\n3.3.3 Accidentes mineros\nEste ejemplo est√° tomado del tutorial de PyMC.\nEl problema es el siguiente, tenemos un registro del n√∫mero de accidentes en minas de carb√≥n, ubicadas en el Reino Unido, que ocurrieron entre 1851 y 1962 (Jarrett, 1979). Se sospecha que la aplicaci√≥n de ciertas regulaciones de seguridad tuvo como efecto una disminuci√≥n en la cantidad de cat√°strofes. Por lo tanto nos interesa averiguar el a√±o en que la tasa cambi√≥ y nos interesa estimar ambas tasas.\nLos datos son los siguientes, por un lado tenemos la variable accidentes que contiene la cantidad de accidentes por a√±o y por el otro la variable a√±os conteniendo el rango de a√±os para los cuales tenemos datos. Si prestan atenci√≥n ver√°n que accidentes es un arreglo enmascarado (o masked array). Esto es un tipo especial de arreglo de NumPy donde cada elemento del arreglo contiene asociado un valor True o False el cual indica si el elemento debe o no ser usado durante cualquier tipo de operaci√≥n. En este caso como faltan datos para dos a√±os lo que se ha hecho es marcar esa falta de datos con un valor centinela de -999, esta es la forma de indicarle a PyMC la presencia de datos faltantes, alternativamente se pueden pasar los datos como un dataframe de Pandas conteniendo el valor especial NAN (que es el valor por defecto en Pandas para lidiar con datos faltantes).\nBien, pero para que molestarse con datos faltantes si en general es m√°s f√°cil eliminarlos. una de las razones es que esto puede conducir a p√©rdida de informaci√≥n cuando por cada observaci√≥n tenemos m√°s de una variable o cantidad de inter√©s. Por ejemplo si tenemos 50 sujetos a los que les hemos medido la presi√≥n, la temperatura y el ritmo card√≠aco, pero sucede que para 4 de ellos no contamos con el datos de la presi√≥n (porque alguien se olvid√≥ de medirlo o registrarlo, o porque el tensi√≥metro se rompi√≥, o por lo que sea). Podemos eliminar esos cuatro sujetos del an√°lisis y perder por lo tanto informaci√≥n sobre la presi√≥n y ritmo card√≠aco, o podemos usar todos los datos disponibles y adem√°s estimar los valores de temperatura faltantes. En el contexto de la estad√≠stica Bayesiana los datos faltantes se tratan como un par√°metro desconocido del modelo que puede ser estimado.\n\naccidentes = pd.Series([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n                       3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n                       2, 2, 3, 4, 2, 1, 3, np.nan, 2, 1, 1, 1, 1, 3, 0, 0,\n                       1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n                       0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n                       3, 3, 1, np.nan, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n                       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])\na√±os = np.arange(1851, 1962)\n\n\nplt.plot(a√±os, accidentes, \".\")\nplt.ylabel(\"N√∫mero de accidentes\")\nplt.xlabel(\"A√±o\");\n\n\n\n\nPara modelar los accidentes usaremos una distribuci√≥n de Poisson. Como creemos que la cantidad media de accidentes es distinta antes y despu√©s de la introducci√≥n de regulaciones de seguridad usaremos dos valores de tasas medias de accidentes (\\(t_0\\) y \\(t_1\\)). Adem√°s deberemos estimar un punto de corte (\\(pc\\)) que dividir√° los a√±os para los cuales se aplica la tasa de accidentes \\(t_0\\) de los cuales se aplica la tasa \\(t_1\\):\n\\[\\begin{equation}\nA_t \\sim Poisson(tasa)\n\\end{equation}\\]\n\\[\\begin{equation}\ntasa = \\begin{cases}\nt_0, \\text{si } t \\ge pc,\\\\\nt_1, \\text{si } t \\lt pc\n\\end{cases}\n\\end{equation}\\]\nLos a prioris que usaremos ser√°n:\n\\[\\begin{align}\nt_0 \\sim Expon(1) \\\\\nt_1 \\sim Expon(1) \\\\\npc \\sim U(A_0, A_1)\n\\end{align}\\]\nDonde la distribucion uniforme es discreta y \\(A_0\\) y \\(A_1\\) corresponden al primer y √∫ltimo a√±o considerado en el an√°lisis respectivamente.\nGr√°ficamente el modelo es:\n\nUna peculiaridad de la implementaci√≥n de este modelo en PyMC es el uso de la funci√≥n pm.switch (linea 10). Esta es en realidad una funci√≥n de PyMC y equivale a un if else de Python. Si el primer argumento es True entonces devuelve el segundo argumento caso contrario el tercer argumento. Como resultado tenemos que tasa es un vector de longitud igual a la de a√±os y cuyos elementos corresponden a una repetici√≥n \\(t_0\\) seguida de una repetici√≥n \\(t_1\\), la cantidad exacta de repeticiones de \\(t_0\\) y \\(t_1\\) est√° controlada por la condici√≥n \\(pc \\ge\\) a√±os. De esta forma, podemos al muestrear \\(pc\\), modificar que a√±os reciben cual tasa para el c√°lculo del likelihood.\n\nwith pm.Model() as modelo_cat:\n\n    pc = pm.DiscreteUniform(\"pc\", lower=a√±os.min(), upper=a√±os.max())\n\n    # Priors para las tasas antes y despu√©s del cambio.\n    t_0 = pm.Exponential(\"t_0\", 1)\n    t_1 = pm.Exponential(\"t_1\", 1)\n\n    # Asignamos las tasas a los a√±os de acuerdo a pc\n    tasa = pm.Deterministic(\"tasa\", pm.math.switch(pc >= a√±os, t_0, t_1))\n\n    acc = pm.Poisson(\"acc\", tasa, observed=accidentes)\n    idata_cat = pm.sample(1000, random_seed=1791, idata_kwargs={\"log_likelihood\": True})\n\n/home/osvaldo/anaconda3/envs/bayes/lib/python3.10/site-packages/pymc/model.py:1384: RuntimeWarning: invalid value encountered in cast\n  data = convert_observed_data(data).astype(rv_var.dtype)\n/home/osvaldo/anaconda3/envs/bayes/lib/python3.10/site-packages/pymc/model.py:1407: ImputationWarning: Data in acc contains missing values and will be automatically imputed from the sampling distribution.\n  warnings.warn(impute_message, ImputationWarning)\nMultiprocess sampling (4 chains in 4 jobs)\nCompoundStep\n>CompoundStep\n>>Metropolis: [pc]\n>>Metropolis: [acc_missing]\n>NUTS: [t_0, t_1]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n\nidata_cat\n\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset>\nDimensions:            (chain: 4, draw: 1000, acc_missing_dim_0: 2,\n                        tasa_dim_0: 111, acc_dim_0: 111)\nCoordinates:\n  * chain              (chain) int64 0 1 2 3\n  * draw               (draw) int64 0 1 2 3 4 5 6 ... 994 995 996 997 998 999\n  * acc_missing_dim_0  (acc_missing_dim_0) int64 0 1\n  * tasa_dim_0         (tasa_dim_0) int64 0 1 2 3 4 5 ... 106 107 108 109 110\n  * acc_dim_0          (acc_dim_0) int64 0 1 2 3 4 5 ... 105 106 107 108 109 110\nData variables:\n    pc                 (chain, draw) int64 1889 1886 1886 ... 1889 1892 1892\n    acc_missing        (chain, draw, acc_missing_dim_0) int64 0 0 0 1 ... 1 3 1\n    t_0                (chain, draw) float64 3.273 3.31 2.694 ... 2.881 2.946\n    t_1                (chain, draw) float64 0.8727 0.8444 ... 1.008 0.8809\n    tasa               (chain, draw, tasa_dim_0) float64 3.273 3.273 ... 0.8809\n    acc                (chain, draw, acc_dim_0) int64 4 5 4 0 1 4 ... 0 0 1 0 1\nAttributes:\n    created_at:                 2023-04-20T21:18:39.548868\n    arviz_version:              0.15.1\n    inference_library:          pymc\n    inference_library_version:  5.3.0\n    sampling_time:              2.365055799484253\n    tuning_steps:               1000xarray.DatasetDimensions:chain: 4draw: 1000acc_missing_dim_0: 2tasa_dim_0: 111acc_dim_0: 111Coordinates: (5)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])acc_missing_dim_0(acc_missing_dim_0)int640 1array([0, 1])tasa_dim_0(tasa_dim_0)int640 1 2 3 4 5 ... 106 107 108 109 110array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110])acc_dim_0(acc_dim_0)int640 1 2 3 4 5 ... 106 107 108 109 110array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110])Data variables: (6)pc(chain, draw)int641889 1886 1886 ... 1889 1892 1892array([[1889, 1886, 1886, ..., 1888, 1887, 1888],\n       [1892, 1891, 1891, ..., 1890, 1888, 1890],\n       [1889, 1889, 1889, ..., 1890, 1890, 1890],\n       [1890, 1889, 1889, ..., 1889, 1892, 1892]])acc_missing(chain, draw, acc_missing_dim_0)int640 0 0 1 0 1 0 0 ... 2 0 2 0 2 1 3 1array([[[0, 0],\n        [0, 1],\n        [0, 1],\n        ...,\n        [3, 1],\n        [3, 1],\n        [3, 1]],\n\n       [[6, 1],\n        [6, 1],\n        [6, 3],\n        ...,\n        [2, 1],\n        [2, 1],\n        [2, 1]],\n\n       [[1, 1],\n        [1, 2],\n        [1, 0],\n        ...,\n        [4, 2],\n        [2, 2],\n        [2, 2]],\n\n       [[1, 0],\n        [1, 0],\n        [1, 0],\n        ...,\n        [2, 0],\n        [2, 1],\n        [3, 1]]])t_0(chain, draw)float643.273 3.31 2.694 ... 2.881 2.946array([[3.27300145, 3.31004382, 2.69385652, ..., 3.361489  , 3.40956827,\n        3.40956827],\n       [3.10592073, 3.36085222, 3.00534019, ..., 2.54307457, 2.51920588,\n        3.5372262 ],\n       [2.71227824, 2.71227824, 3.0856883 , ..., 2.86019813, 2.99960294,\n        2.89937231],\n       [2.86208697, 3.20730475, 2.95804455, ..., 3.36485285, 2.88077941,\n        2.94647035]])t_1(chain, draw)float640.8727 0.8444 ... 1.008 0.8809array([[0.87270139, 0.84441641, 1.0630722 , ..., 1.00885421, 1.00662329,\n        1.00662329],\n       [1.05576985, 0.91125974, 0.85414828, ..., 1.04231662, 1.05555764,\n        0.77176679],\n       [0.89805765, 0.89805765, 0.79840082, ..., 0.6720661 , 0.7872776 ,\n        0.72575752],\n       [0.75190232, 1.20079714, 0.77526223, ..., 0.73696447, 1.00761759,\n        0.88086743]])tasa(chain, draw, tasa_dim_0)float643.273 3.273 3.273 ... 0.8809 0.8809array([[[3.27300145, 3.27300145, 3.27300145, ..., 0.87270139,\n         0.87270139, 0.87270139],\n        [3.31004382, 3.31004382, 3.31004382, ..., 0.84441641,\n         0.84441641, 0.84441641],\n        [2.69385652, 2.69385652, 2.69385652, ..., 1.0630722 ,\n         1.0630722 , 1.0630722 ],\n        ...,\n        [3.361489  , 3.361489  , 3.361489  , ..., 1.00885421,\n         1.00885421, 1.00885421],\n        [3.40956827, 3.40956827, 3.40956827, ..., 1.00662329,\n         1.00662329, 1.00662329],\n        [3.40956827, 3.40956827, 3.40956827, ..., 1.00662329,\n         1.00662329, 1.00662329]],\n\n       [[3.10592073, 3.10592073, 3.10592073, ..., 1.05576985,\n         1.05576985, 1.05576985],\n        [3.36085222, 3.36085222, 3.36085222, ..., 0.91125974,\n         0.91125974, 0.91125974],\n        [3.00534019, 3.00534019, 3.00534019, ..., 0.85414828,\n         0.85414828, 0.85414828],\n...\n        [2.86019813, 2.86019813, 2.86019813, ..., 0.6720661 ,\n         0.6720661 , 0.6720661 ],\n        [2.99960294, 2.99960294, 2.99960294, ..., 0.7872776 ,\n         0.7872776 , 0.7872776 ],\n        [2.89937231, 2.89937231, 2.89937231, ..., 0.72575752,\n         0.72575752, 0.72575752]],\n\n       [[2.86208697, 2.86208697, 2.86208697, ..., 0.75190232,\n         0.75190232, 0.75190232],\n        [3.20730475, 3.20730475, 3.20730475, ..., 1.20079714,\n         1.20079714, 1.20079714],\n        [2.95804455, 2.95804455, 2.95804455, ..., 0.77526223,\n         0.77526223, 0.77526223],\n        ...,\n        [3.36485285, 3.36485285, 3.36485285, ..., 0.73696447,\n         0.73696447, 0.73696447],\n        [2.88077941, 2.88077941, 2.88077941, ..., 1.00761759,\n         1.00761759, 1.00761759],\n        [2.94647035, 2.94647035, 2.94647035, ..., 0.88086743,\n         0.88086743, 0.88086743]]])acc(chain, draw, acc_dim_0)int644 5 4 0 1 4 3 4 ... 0 0 1 0 0 1 0 1array([[[4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        ...,\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1]],\n\n       [[4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        ...,\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1]],\n\n       [[4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        ...,\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1]],\n\n       [[4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        ...,\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1]]])Indexes: (5)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))acc_missing_dim_0PandasIndexPandasIndex(Index([0, 1], dtype='int64', name='acc_missing_dim_0'))tasa_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n      dtype='int64', name='tasa_dim_0', length=111))acc_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n      dtype='int64', name='acc_dim_0', length=111))Attributes: (6)created_at :2023-04-20T21:18:39.548868arviz_version :0.15.1inference_library :pymcinference_library_version :5.3.0sampling_time :2.365055799484253tuning_steps :1000\n                      \n                  \n            \n            \n            \n                  \n                  log_likelihood\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset>\nDimensions:             (chain: 4, draw: 1000, acc_observed_dim_0: 109)\nCoordinates:\n  * chain               (chain) int64 0 1 2 3\n  * draw                (draw) int64 0 1 2 3 4 5 6 ... 994 995 996 997 998 999\n  * acc_observed_dim_0  (acc_observed_dim_0) int64 0 1 2 3 4 ... 105 106 107 108\nData variables:\n    acc_observed        (chain, draw, acc_observed_dim_0) float64 -1.708 ... ...\nAttributes:\n    created_at:                 2023-04-20T21:18:39.746180\n    arviz_version:              0.15.1\n    inference_library:          pymc\n    inference_library_version:  5.3.0xarray.DatasetDimensions:chain: 4draw: 1000acc_observed_dim_0: 109Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])acc_observed_dim_0(acc_observed_dim_0)int640 1 2 3 4 5 ... 104 105 106 107 108array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108])Data variables: (1)acc_observed(chain, draw, acc_observed_dim_0)float64-1.708 -2.132 ... -0.8809 -1.008array([[[-1.70822553, -2.131956  , -1.70822553, ..., -1.00886322,\n         -0.87270139, -1.00886322],\n        [-1.70025194, -2.11272842, -1.70025194, ..., -1.01352594,\n         -0.84441641, -1.01352594],\n        [-1.90801508, -2.52647918, -1.90801508, ..., -1.00190918,\n         -1.0630722 , -1.00190918],\n        ...,\n        [-1.69000671, -2.08706059, -1.69000671, ..., -1.00003897,\n         -1.00885421, -1.00003897],\n        [-1.6812794 , -2.06413163, -1.6812794 , ..., -1.00002184,\n         -1.00662329, -1.00002184],\n        [-1.6812794 , -2.06413163, -1.6812794 , ..., -1.00002184,\n         -1.00662329, -1.00002184]],\n\n       [[-1.75073375, -2.22686146, -1.75073375, ..., -1.00149963,\n         -1.05576985, -1.00149963],\n        [-1.69012774, -2.08737107, -1.69012774, ..., -1.00418705,\n         -0.91125974, -1.00418705],\n        [-1.78183094, -2.29087809, -1.78183094, ..., -1.01179875,\n         -0.85414828, -1.01179875],\n...\n        [-1.83468837, -2.39323538, -1.83468837, ..., -1.06946468,\n         -0.6720661 , -1.06946468],\n        [-1.78373707, -2.29469505, -1.78373707, ..., -1.02645196,\n         -0.7872776 , -1.02645196],\n        [-1.81944907, -2.36439271, -1.81944907, ..., -1.04629684,\n         -0.72575752, -1.04629684]],\n\n       [[-1.83393653, -2.39182337, -1.83393653, ..., -1.03705118,\n         -0.75190232, -1.03705118],\n        [-1.72363481, -2.16764178, -1.72363481, ..., -1.01781152,\n         -1.20079714, -1.01781152],\n        [-1.79798468, -2.32289417, -1.79798468, ..., -1.02981618,\n         -0.77526223, -1.02981618],\n        ...,\n        [-1.68936975, -2.08542343, -1.68936975, ..., -1.04218007,\n         -0.73696447, -1.04218007],\n        [-1.8265897 , -2.37796672, -1.8265897 , ..., -1.00002887,\n         -1.00761759, -1.00002887],\n        [-1.80209233, -2.33092228, -1.80209233, ..., -1.00771557,\n         -0.88086743, -1.00771557]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))acc_observed_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n        99, 100, 101, 102, 103, 104, 105, 106, 107, 108],\n      dtype='int64', name='acc_observed_dim_0', length=109))Attributes: (4)created_at :2023-04-20T21:18:39.746180arviz_version :0.15.1inference_library :pymcinference_library_version :5.3.0\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset>\nDimensions:                (chain: 4, draw: 1000, scaling_dim_0: 2,\n                            accept_dim_0: 2, accepted_dim_0: 2)\nCoordinates:\n  * chain                  (chain) int64 0 1 2 3\n  * draw                   (draw) int64 0 1 2 3 4 5 ... 994 995 996 997 998 999\n  * scaling_dim_0          (scaling_dim_0) int64 0 1\n  * accept_dim_0           (accept_dim_0) int64 0 1\n  * accepted_dim_0         (accepted_dim_0) int64 0 1\nData variables: (12/20)\n    scaling                (chain, draw, scaling_dim_0) float64 2.358 ... 2.585\n    reached_max_treedepth  (chain, draw) bool False False False ... False False\n    max_energy_error       (chain, draw) float64 0.265 0.09046 ... 0.4624\n    perf_counter_start     (chain, draw) float64 2.601e+04 ... 2.602e+04\n    energy                 (chain, draw) float64 176.4 176.6 ... 178.5 178.2\n    index_in_trajectory    (chain, draw) int64 -3 1 -2 -1 -2 -1 ... 0 2 2 2 2 -3\n    ...                     ...\n    n_steps                (chain, draw) float64 3.0 1.0 3.0 1.0 ... 3.0 3.0 3.0\n    accept                 (chain, draw, accept_dim_0) float64 0.007396 ... 0...\n    accepted               (chain, draw, accepted_dim_0) float64 0.0 0.0 ... 0.5\n    energy_error           (chain, draw) float64 -0.06509 0.09046 ... -0.104\n    largest_eigval         (chain, draw) float64 nan nan nan nan ... nan nan nan\n    step_size              (chain, draw) float64 0.8418 0.8418 ... 1.204 1.204\nAttributes:\n    created_at:                 2023-04-20T21:18:39.558212\n    arviz_version:              0.15.1\n    inference_library:          pymc\n    inference_library_version:  5.3.0\n    sampling_time:              2.365055799484253\n    tuning_steps:               1000xarray.DatasetDimensions:chain: 4draw: 1000scaling_dim_0: 2accept_dim_0: 2accepted_dim_0: 2Coordinates: (5)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])scaling_dim_0(scaling_dim_0)int640 1array([0, 1])accept_dim_0(accept_dim_0)int640 1array([0, 1])accepted_dim_0(accepted_dim_0)int640 1array([0, 1])Data variables: (20)scaling(chain, draw, scaling_dim_0)float642.358 2.438 2.358 ... 2.144 2.585array([[[2.35794769, 2.43845855],\n        [2.35794769, 2.43845855],\n        [2.35794769, 2.43845855],\n        ...,\n        [2.35794769, 2.43845855],\n        [2.35794769, 2.43845855],\n        [2.35794769, 2.43845855]],\n\n       [[1.9487171 , 2.58486855],\n        [1.9487171 , 2.58486855],\n        [1.9487171 , 2.58486855],\n        ...,\n        [1.9487171 , 2.58486855],\n        [1.9487171 , 2.58486855],\n        [1.9487171 , 2.58486855]],\n\n       [[2.9282    , 2.30535855],\n        [2.9282    , 2.30535855],\n        [2.9282    , 2.30535855],\n        ...,\n        [2.9282    , 2.30535855],\n        [2.9282    , 2.30535855],\n        [2.9282    , 2.30535855]],\n\n       [[2.14358881, 2.58486855],\n        [2.14358881, 2.58486855],\n        [2.14358881, 2.58486855],\n        ...,\n        [2.14358881, 2.58486855],\n        [2.14358881, 2.58486855],\n        [2.14358881, 2.58486855]]])reached_max_treedepth(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])max_energy_error(chain, draw)float640.265 0.09046 ... -0.6745 0.4624array([[ 0.26504584,  0.09046142,  0.46798465, ...,  0.22325168,\n        -0.07519011,  1.3507017 ],\n       [-0.11731527,  0.6444133 ,  0.17705949, ..., -0.4767042 ,\n         0.07733244, -0.50792413],\n       [-0.46983184,  1.33427506,  0.41174189, ...,  1.70651699,\n        -0.76661906, -0.39112682],\n       [ 0.32258973,  0.35653055,  1.51618935, ...,  0.38004319,\n        -0.67445668,  0.46237617]])perf_counter_start(chain, draw)float642.601e+04 2.601e+04 ... 2.602e+04array([[26014.91047292, 26014.91148382, 26014.91232575, ...,\n        26015.87911283, 26015.87987525, 26015.88066041],\n       [26015.06253877, 26015.06348128, 26015.06439578, ...,\n        26016.17831508, 26016.17899803, 26016.17949004],\n       [26014.83830859, 26014.83938188, 26014.84018346, ...,\n        26015.825392  , 26015.826208  , 26015.82687544],\n       [26015.02727908, 26015.02858552, 26015.02973348, ...,\n        26016.12544131, 26016.12618101, 26016.12687694]])energy(chain, draw)float64176.4 176.6 178.5 ... 178.5 178.2array([[176.36555001, 176.6459368 , 178.51243729, ..., 179.84406587,\n        178.07559104, 181.37051764],\n       [178.78937655, 178.97206313, 179.92765349, ..., 178.60148204,\n        180.77395892, 179.25473734],\n       [177.06746079, 180.29252714, 177.8214689 , ..., 182.01800491,\n        179.75269857, 179.16297612],\n       [179.09410751, 178.91538598, 180.7228587 , ..., 178.93246036,\n        178.51951985, 178.20431289]])index_in_trajectory(chain, draw)int64-3 1 -2 -1 -2 -1 0 ... 0 2 2 2 2 -3array([[-3,  1, -2, ...,  2, -1,  0],\n       [-3, -2,  2, ..., -3, -1,  3],\n       [ 2,  0, -3, ..., -3,  1, -1],\n       [-3,  3, -3, ...,  2,  2, -3]])smallest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])lp(chain, draw)float64-175.4 -176.6 ... -176.9 -176.6array([[-175.41139297, -176.57599061, -177.89154262, ..., -179.02823666,\n        -177.99848681, -179.18144757],\n       [-178.65935626, -177.29025153, -179.37600142, ..., -178.44921053,\n        -180.18844401, -178.28848647],\n       [-176.46011085, -177.26077905, -175.90058188, ..., -180.86232685,\n        -177.73456282, -179.01067105],\n       [-177.68364881, -178.00208278, -176.31468939, ..., -178.20585816,\n        -176.94953554, -176.61512549]])step_size_bar(chain, draw)float641.007 1.007 1.007 ... 1.172 1.172array([[1.00729023, 1.00729023, 1.00729023, ..., 1.00729023, 1.00729023,\n        1.00729023],\n       [1.08286555, 1.08286555, 1.08286555, ..., 1.08286555, 1.08286555,\n        1.08286555],\n       [1.05223362, 1.05223362, 1.05223362, ..., 1.05223362, 1.05223362,\n        1.05223362],\n       [1.1719586 , 1.1719586 , 1.1719586 , ..., 1.1719586 , 1.1719586 ,\n        1.1719586 ]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])process_time_diff(chain, draw)float640.0005549 0.0002336 ... 0.0003363array([[0.00055489, 0.00023365, 0.00047276, ..., 0.00038232, 0.0004018 ,\n        0.00020246],\n       [0.00049923, 0.00044608, 0.00043372, ..., 0.00033792, 0.00017472,\n        0.00037314],\n       [0.00054747, 0.00021153, 0.00051525, ..., 0.00040727, 0.00022437,\n        0.00045394],\n       [0.00067074, 0.00051242, 0.00061125, ..., 0.00037821, 0.00034662,\n        0.00033631]])perf_counter_diff(chain, draw)float640.0005654 0.0002338 ... 0.0003364array([[0.00056544, 0.00023377, 0.00047288, ..., 0.0003825 , 0.00040203,\n        0.00020259],\n       [0.0004992 , 0.00044613, 0.00043394, ..., 0.00033805, 0.00017483,\n        0.00037316],\n       [0.00054733, 0.0002119 , 0.00051491, ..., 0.00040753, 0.00022451,\n        0.00045401],\n       [0.00067041, 0.00051257, 0.00061126, ..., 0.00037832, 0.00034671,\n        0.00033643]])acceptance_rate(chain, draw)float640.9064 0.9135 0.7718 ... 1.0 0.8124array([[0.90639157, 0.91350957, 0.77182768, ..., 0.88353586, 0.98583535,\n        0.25905842],\n       [0.98955886, 0.76850148, 0.91835521, ..., 0.98134166, 0.9255821 ,\n        1.        ],\n       [1.        , 0.26334902, 0.82588129, ..., 0.45805148, 1.        ,\n        0.89739528],\n       [0.83775282, 0.81221993, 0.61178363, ..., 0.83165062, 1.        ,\n        0.81235333]])tree_depth(chain, draw)int642 1 2 1 2 2 2 2 ... 2 2 1 2 2 2 2 2array([[2, 1, 2, ..., 2, 2, 1],\n       [2, 2, 2, ..., 2, 1, 2],\n       [2, 1, 2, ..., 2, 1, 2],\n       [2, 2, 2, ..., 2, 2, 2]])n_steps(chain, draw)float643.0 1.0 3.0 1.0 ... 3.0 3.0 3.0 3.0array([[3., 1., 3., ..., 3., 3., 1.],\n       [3., 3., 3., ..., 3., 1., 3.],\n       [3., 1., 3., ..., 3., 1., 3.],\n       [3., 3., 3., ..., 3., 3., 3.]])accept(chain, draw, accept_dim_0)float640.007396 0.0 ... 0.1929 0.732array([[[7.39612819e-03, 0.00000000e+00],\n        [4.81757005e-01, 4.36350696e-01],\n        [1.00000000e+00, 0.00000000e+00],\n        ...,\n        [3.02994122e-02, 5.00000000e-01],\n        [3.15524455e+00, 3.78320328e-01],\n        [3.06370307e-01, 1.47077949e-01]],\n\n       [[3.74914457e-01, 7.26775219e+00],\n        [2.64087657e+00, 5.42411823e-02],\n        [1.01373740e-01, 8.18567118e-02],\n        ...,\n        [1.09606993e+00, 1.23133365e+00],\n        [2.32672273e-01, 5.45267664e-01],\n        [4.14571869e+00, 5.28322671e-01]],\n\n       [[1.00000000e+00, 5.22871476e-01],\n        [8.72268475e-02, 3.25327855e-01],\n        [4.92180078e-01, 2.47982802e+00],\n        ...,\n        [2.13478920e-01, 2.97234574e-01],\n        [6.59186005e-03, 7.33430580e-01],\n        [7.07448678e-04, 4.06632834e-03]],\n\n       [[2.13928968e-01, 1.49531966e+00],\n        [2.16730557e+00, 5.00000000e-01],\n        [1.00000000e+00, 5.00000000e-01],\n        ...,\n        [1.20579091e+00, 6.69148835e-01],\n        [7.47765382e-01, 3.68482237e-01],\n        [1.92939365e-01, 7.32034299e-01]]])accepted(chain, draw, accepted_dim_0)float640.0 0.0 1.0 0.5 ... 1.0 0.5 0.0 0.5array([[[0. , 0. ],\n        [1. , 0.5],\n        [1. , 0. ],\n        ...,\n        [1. , 0.5],\n        [1. , 0. ],\n        [1. , 0. ]],\n\n       [[1. , 1. ],\n        [1. , 0. ],\n        [0. , 0.5],\n        ...,\n        [1. , 0.5],\n        [1. , 0.5],\n        [1. , 0. ]],\n\n       [[1. , 0.5],\n        [0. , 0.5],\n        [0. , 1. ],\n        ...,\n        [0. , 0.5],\n        [0. , 0.5],\n        [0. , 0. ]],\n\n       [[1. , 0.5],\n        [1. , 0.5],\n        [1. , 0.5],\n        ...,\n        [1. , 0.5],\n        [1. , 0.5],\n        [0. , 0.5]]])energy_error(chain, draw)float64-0.06509 0.09046 ... -0.594 -0.104array([[-6.50865282e-02,  9.04614228e-02,  4.67984653e-01, ...,\n        -6.90994557e-02,  4.34232260e-02,  0.00000000e+00],\n       [ 3.18244988e-02, -6.90837604e-02,  3.89116988e-02, ...,\n         5.76026427e-02,  7.73324387e-02, -1.49912676e-01],\n       [-2.39403787e-01,  0.00000000e+00, -1.80410173e-01, ...,\n         1.15200873e+00, -7.66619061e-01,  3.67900783e-01],\n       [ 1.26164191e-01,  3.56530549e-01, -8.28935220e-05, ...,\n         3.80043189e-01, -5.94038760e-01, -1.04008828e-01]])largest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])step_size(chain, draw)float640.8418 0.8418 ... 1.204 1.204array([[0.84177244, 0.84177244, 0.84177244, ..., 0.84177244, 0.84177244,\n        0.84177244],\n       [1.09823017, 1.09823017, 1.09823017, ..., 1.09823017, 1.09823017,\n        1.09823017],\n       [1.09244341, 1.09244341, 1.09244341, ..., 1.09244341, 1.09244341,\n        1.09244341],\n       [1.2040221 , 1.2040221 , 1.2040221 , ..., 1.2040221 , 1.2040221 ,\n        1.2040221 ]])Indexes: (5)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))scaling_dim_0PandasIndexPandasIndex(Index([0, 1], dtype='int64', name='scaling_dim_0'))accept_dim_0PandasIndexPandasIndex(Index([0, 1], dtype='int64', name='accept_dim_0'))accepted_dim_0PandasIndexPandasIndex(Index([0, 1], dtype='int64', name='accepted_dim_0'))Attributes: (6)created_at :2023-04-20T21:18:39.558212arviz_version :0.15.1inference_library :pymcinference_library_version :5.3.0sampling_time :2.365055799484253tuning_steps :1000\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset>\nDimensions:             (acc_observed_dim_0: 109)\nCoordinates:\n  * acc_observed_dim_0  (acc_observed_dim_0) int64 0 1 2 3 4 ... 105 106 107 108\nData variables:\n    acc_observed        (acc_observed_dim_0) int64 4 5 4 0 1 4 3 ... 1 0 0 1 0 1\nAttributes:\n    created_at:                 2023-04-20T21:18:39.562843\n    arviz_version:              0.15.1\n    inference_library:          pymc\n    inference_library_version:  5.3.0xarray.DatasetDimensions:acc_observed_dim_0: 109Coordinates: (1)acc_observed_dim_0(acc_observed_dim_0)int640 1 2 3 4 5 ... 104 105 106 107 108array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108])Data variables: (1)acc_observed(acc_observed_dim_0)int644 5 4 0 1 4 3 4 ... 0 0 1 0 0 1 0 1array([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5, 4, 5, 3,\n       1, 4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 1, 1, 1, 1,\n       3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1, 0, 1, 0,\n       1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 2, 1, 1, 1, 1, 2,\n       4, 2, 0, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])Indexes: (1)acc_observed_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n        99, 100, 101, 102, 103, 104, 105, 106, 107, 108],\n      dtype='int64', name='acc_observed_dim_0', length=109))Attributes: (4)created_at :2023-04-20T21:18:39.562843arviz_version :0.15.1inference_library :pymcinference_library_version :5.3.0\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\nax = az.plot_posterior(idata_cat, var_names=[\"~tasa\", \"~acc\"], figsize=(12, 6));\n\n\n\n\n\naz.summary(idata_cat, var_names=[\"~tasa\", \"~acc\"])\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      pc\n      1889.971\n      2.430\n      1885.000\n      1894.000\n      0.168\n      0.119\n      224.0\n      232.0\n      1.01\n    \n    \n      acc_missing[0]\n      2.379\n      1.879\n      0.000\n      6.000\n      0.097\n      0.069\n      364.0\n      467.0\n      1.01\n    \n    \n      acc_missing[1]\n      0.931\n      0.983\n      0.000\n      3.000\n      0.038\n      0.028\n      704.0\n      827.0\n      1.00\n    \n    \n      t_0\n      3.080\n      0.286\n      2.558\n      3.625\n      0.006\n      0.004\n      2130.0\n      2528.0\n      1.00\n    \n    \n      t_1\n      0.929\n      0.118\n      0.712\n      1.151\n      0.002\n      0.002\n      3090.0\n      2802.0\n      1.00\n    \n  \n\n\n\n\n\ntasa_mean = idata_cat.posterior[\"tasa\"].mean((\"chain\", \"draw\"))\ntasa_hdi = az.hdi(idata_cat.posterior[\"tasa\"].values)\npc_hdi = az.hdi(idata_cat.posterior[\"pc\"])[\"pc\"]\n\n_, ax = plt.subplots(figsize=(10, 5), sharey=True)\nax.plot(a√±os, accidentes, \".\")\n\nax.set_ylabel(\"N√∫mero de accidentes\")\nax.set_xlabel(\"A√±o\")\n\nax.vlines(\n    idata_cat.posterior[\"pc\"].mean((\"chain\", \"draw\")),\n    accidentes.min(),\n    accidentes.max(),\n    color=\"C1\",\n    lw=2,\n)\n\n\nax.fill_betweenx(\n    [accidentes.min(), accidentes.max()], pc_hdi[0], pc_hdi[1], alpha=0.3, color=\"C1\"\n)\nax.plot(a√±os, tasa_mean, \"k\", lw=2)\nax.fill_between(a√±os, tasa_hdi[:, 0], tasa_hdi[:, 1], alpha=0.3, color=\"k\")\n\nfaltante0 = (\n    idata_cat.posterior[\"acc_missing\"].sel(acc_missing_dim_0=0).mean((\"chain\", \"draw\"))\n)\nfaltante1 = (\n    idata_cat.posterior[\"acc_missing\"].sel(acc_missing_dim_0=1).mean((\"chain\", \"draw\"))\n)\n\nax.plot(a√±os[np.isnan(accidentes)], [faltante0, faltante1], \"C2s\");"
  },
  {
    "objectID": "02_Programaci√≥n_probabil√≠stica.html#pruebas-predictivas-a-posteriori",
    "href": "02_Programaci√≥n_probabil√≠stica.html#pruebas-predictivas-a-posteriori",
    "title": "3¬† Programaci√≥n probabilista",
    "section": "3.4 Pruebas predictivas a posteriori",
    "text": "3.4 Pruebas predictivas a posteriori\nLa prueba consiste en comparar los datos observados con los datos predichos a partir del a posteriori.\nLas pruebas predictivas a posteriori son pruebas de auto-consistencia. Este ejercicio nos permite evaluar si el modelo es razonable, la idea general no es determinar si un modelo es correcto o no ya que como dijo George Box ‚Äútodos los modelos est√°n equivocados, pero algunos son √∫tiles‚Äù. El grado de confianza en la verosimilitud de los modelos ciertamente es distinta entre practicantes de distintas disciplinas cient√≠ficas, en disciplinas como f√≠sica cuando se estudian sistemas relativamente simples bajo condiciones experimentales extremadamente controladas y haciendo uso de teor√≠as fuertes, es probable que se le asigne un alto grado de confianza a ciertos modelos. Pero esto no suele ser cierto en disciplinas como ciencias sociales o biolog√≠a (aunque sospecho que la variabilidad encontrada en biolog√≠a ¬°es muy alta!). En el caso de contar con a prioris muy informativos la evaluaci√≥n de un modelo tambi√©n puede ser usado para evaluar si los propios datos son razonables, indicando que tal vez sea necesario conseguir nuevos datos o revisar como se obtuvieron los datos o como se procesaron.\nEn definitiva la principal utilidad de las pruebas predictivas a posteriori deber√≠a ser el permitirnos dar una segunda mirada, cr√≠tica, al modelo y tratar de entender la raz√≥n de discrepancias sistem√°ticas (si las hubiera), estas discrepancias nos pueden llevar a entender mejor los l√≠mites del modelo, abandonar el modelo por completo o tal vez mejorarlo.\nSi bien se han desarrollado m√©todos formales o cuantitativos para realizar pruebas predictivas a posteriori, una aproximaci√≥n que suele ser m√°s informativa y simple de interpretar es realizar gr√°ficas, como veremos a continuaci√≥n.\nUsando PyMC podemos calcular la distribuci√≥n predictiva a posteriori de la siguiente forma\n\nidata_cat.extend(\n    pm.sample_posterior_predictive(idata_cat, model=modelo_cat, random_seed=1791)\n)\n\nSampling: [acc_observed]\n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00<00:00]\n    \n    \n\n\nSi bien es posible construir nuestras propias pruebas predictivas a posteriori, a continuaci√≥n usaremos dos funciones de ArviZ.\n\n_, ax = plt.subplots(1, 2, figsize=(12, 4))\naz.plot_ppc(idata_cat, ax=ax[0])\nax[0].set_xlabel(\"acc\")\naz.plot_loo_pit(idata_cat, \"acc_observed\", ax=ax[1], use_hdi=True)\nax[1].set_yticks([]);\n\n\n\n\n\naz.plot_ppc: Por defecto esta funci√≥n representa los datos observados, varias muestras de la distribuci√≥n predictiva a posteriori (predicciones) y la distribuci√≥n media de estas muestras. Si los datos son discretos se usan histogramas, si los datos son continuos KDEs.\naz.plot_loo_pit: Muestra la diferencia entre datos observados y predichos (linea azul), de tal forma que si no hubiera diferencia obtendr√≠amos una distribui√≥n uniforme (linea blanca). En el eje x est√°n los cuantiles de la distribuci√≥n. Por lo que si hubiera diferencia alrededor de 0.5 esto implica diferencia alrededor de la mediana, si en cambio la diferencia estuviera entre 0 y 0.2 esto implicar√≠a diferencias en la cola izquierda (primer 20% de la masa total de la distribuci√≥n), etc. Si la curva est√° por encima de la linea blanca esto quiere decir que hay m√°s observaciones que predicciones en esa regi√≥n, y si la curva est√° por debajo lo contrario. El grafico muestra un banda, que indica las desviaciones esperadas respecto de la distribuci√≥n uniforme para el tama√±o de muestra dado. Cualquier diferencia dentro de esa banda es ‚Äúesperable‚Äù."
  },
  {
    "objectID": "02_Programaci√≥n_probabil√≠stica.html#pruebas-predictivas-a-priori",
    "href": "02_Programaci√≥n_probabil√≠stica.html#pruebas-predictivas-a-priori",
    "title": "3¬† Programaci√≥n probabilista",
    "section": "3.5 Pruebas predictivas a priori",
    "text": "3.5 Pruebas predictivas a priori\nLas pruebas predictivas a prior son una forma de evaluar el modelo. Una vez definido un modelo Bayesiano se generan muestras a partir del mismo, pero sin condicionar en los datos \\(\\tilde{y}\\), es decir se calcula la distribuci√≥n posible de datos (sint√©ticos) sin haber visto los datos reales.\n\\[\np(y^\\ast) =  \\int_{\\Theta} p(y^\\ast \\mid \\theta) \\; p(\\theta) \\; d\\theta\n\\]\nLos datos generados son predictivos ya que son los datos que el modelo esperara ver, es decir son datos no observados pero potencialmente observables. La prueba consiste en comparar los datos observados con el conocimiento previo que tenemos sobre el problema, ojo que NO se trata de comparar con los datos observados!\nLas pruebas predictivas a priori son pruebas de consistencia con nuestro conocimiento previo. Este ejercicio nos permite evaluar si el modelo es razonable, en el sentido de si es capaz de generar datos que concuerdan con lo que sabemos de un problema. Por ejemplo un modelo del tama√±o de planetas no es muy razonable si predice planetas de escala nanom√©trica o incluso de unos pocos kil√≥metros. Es importante destacar que dado suficiente cantidad y calidad de datos un modelo de este tipo podr√≠a dar resultados razonables, una vez condicionado a esos datos. Es decir el posterior podr√≠a no incluir, o asignar probabilidades despreciables a nanoplanetas.\nEn definitiva la principal utilidad de las pruebas predictivas a prior es la de permitirnos inspecticionar cr√≠ticamente un modelo y tratar de entender el comportamiento del modelo las discrepancias con el conocimiento previo nos pueden llevarnos a entender mejor los l√≠mites del modelo, abandonar el modelo por completo o tal vez mejorarlo por ejemplo usando priors m√°s angostos u otros likelihoods.\nUsando PyMC podemos calcular la distribuci√≥n predictiva a priori de la siguiente forma\n\nidata_cat.extend(pm.sample_prior_predictive(model=modelo_cat, random_seed=1791))\n\nSampling: [acc_missing, acc_observed, pc, t_0, t_1]\n\n\n\n_, ax = plt.subplots(2, 2, figsize=(10, 6), sharey=\"row\", sharex=\"col\")\n\nax[0, 0].plot(\n    a√±os[np.isfinite(accidentes)],\n    idata_cat.prior_predictive[\"acc_observed\"].sel(draw=50).squeeze(\"chain\").T,\n    \".\",\n)\na_sample = idata_cat.prior.sel(draw=50)\ncoco = np.full_like(a√±os, a_sample[\"t_1\"].item(), dtype=float)\ncoco[a_sample[\"pc\"] >= a√±os] = a_sample[\"t_0\"].item()\nax[0, 0].step(a√±os, coco)\nax[0, 0].set_ylabel(\"n√∫mero de accidentes\")\n\naz.plot_dist(\n    idata_cat.prior_predictive[\"acc_observed\"].sel(draw=50), ax=ax[0, 1], rotated=True\n)\n\n\nax[1, 0].plot(\n    a√±os[np.isfinite(accidentes)],\n    idata_cat.prior_predictive[\"acc_observed\"].squeeze(\"chain\").T,\n    \"C0.\",\n    alpha=0.05,\n)\nax[1, 0].set_ylabel(\"n√∫mero de accidentes\")\nax[1, 0].set_xlabel(\"a√±os\")\n\naz.plot_dist(idata_cat.prior_predictive[\"acc_observed\"], ax=ax[1, 1], rotated=True)\nax[1, 1].set_xlabel(\"probabilidad\");\n\n\n\n\nLa primer fila de la figura anterior muestra una muestra de la distribuci√≥n predictiva a priori. A la izquierda el n√∫mero de accidentes por a√±o (puntos azules). Y la tasa media en turquesa mostrando un valor de \\(\\approx 0.3\\) antes de 1880 y 1.3 con posterioridad a esa fecha. A la derecha un histograma de la cantidad de accidentes.\nLa segunda fila muestra lo mismo pero agregado para las 500 muestras que le pedimos a PyMC. Se ve una distribuci√≥n de accidentes uniforme a lo largo de los a√±os, esto es esperable dado que hemos definido el mismo prior para ambas tasas. Adem√°s, podemos ver que nuestro modelo favorece valores relativamente bajos de accidentes por a√±o con el 85% de la masa para valores iguales o menores a 3."
  },
  {
    "objectID": "02_Programaci√≥n_probabil√≠stica.html#comparando-grupos",
    "href": "02_Programaci√≥n_probabil√≠stica.html#comparando-grupos",
    "title": "3¬† Programaci√≥n probabilista",
    "section": "3.6 Comparando grupos",
    "text": "3.6 Comparando grupos\nUna tarea com√∫n al analizar datos es comparar grupos. Podr√≠amos estar interesados en analizar los resultados de un ensayo cl√≠nico donde se busca medir la efectividad de una droga, o la reducci√≥n de la cantidad de accidentes de tr√°nsito al introducir un cambio en las regulaciones de tr√°nsito, o el desempe√±o de estudiantes bajo diferentes aproximaciones pedag√≥gicas, etc. Este tipo de preguntas se suele resolver en el marco de lo que se conoce como pruebas de hip√≥tesis que busca declarar si una observaci√≥n es estad√≠sticamente significativa o no. Nosotros tomaremos una ruta alternativa.\nAl comparar grupos debemos decidir que caracter√≠stica(s) vamos a usar. Una caracter√≠stica com√∫n es la media de cada grupo. En ese caso podemos calcular la distribuci√≥n a posteriori de la diferencia entre medias. Para ayudarnos a entender este posterior usaremos 3 herramientas:\n\nUn posteriorplot con un valor de referencia\nUna medida llamada d de Cohen\nLa probabilidad de superioridad\n\nEn el cap√≠tulo anterior ya vimos un ejemplo de c√≥mo usar posteriorplot con un valor de referencia, pronto veremos otro ejemplo. Las novedades aqu√≠ son el d de Cohen y la probabilidad de superioridad, dos maneras populares de expresar el tama√±o del efecto.\n\n3.6.1 d de Cohen\nUna medida muy com√∫n, al menos en ciertas disciplinas, para cuantificar el tama√±o del efecto es el d de Cohen\n\\[\n\\frac{\\mu_2 - \\mu_1}{\\sqrt{\\frac{\\sigma_2^2 + \\sigma_1^2}{2}}}\n\\]\nDe acuerdo con esta expresi√≥n, el tama√±o del efecto es la diferencia de las medias con respecto a la desviaci√≥n est√°ndar combinada de ambos grupos. Ya que es posible obtener una distribuci√≥n a posteriori de medias y de desviaciones est√°ndar, tambi√©n es posible calcular una distribuci√≥n a posteriori de los valores d de Cohen. Por supuesto, si s√≥lo necesitamos o queremos una estimaci√≥n puntual, podr√≠amos calcular la media de esa distribuci√≥n a posteriori. En general, al calcular una desviaci√≥n est√°ndar combinada, se toma en cuenta el tama√±o de la muestra de cada grupo expl√≠citamente, pero la ecuaci√≥n de d de Cohen omite el tama√±o de la muestra, la raz√≥n es que tomamos estos valores del posterior (por lo que ya estamos considerando la incertidumbre de las desviaciones est√°ndar).\n\nUn d de Cohen es una forma de medir el tama√±o del efecto donde la diferencia de las medias se estandariza al considerar las desviaciones est√°ndar de ambos grupos.\n\nCohen introduce la variabilidad de cada grupo al usar sus desviaciones est√°ndar. Esto es realmente importante, una diferencia de 1 cuando la desviaci√≥n est√°ndar es de 0.1 es muy grande en comparaci√≥n con la misma diferencia cuando la desviaci√≥n est√°ndar es 10. Adem√°s, un cambio de x unidades de un grupo respecto del otro podr√≠a explicarse por cada punto desplazandose exactamente x unidades o la mitad de los puntos sin cambiar mientras la otra mitad cambia 2x unidades, y as√≠ con otras combinaciones. Por lo tanto, incluir las variaciones intr√≠nsecas de los grupos es una forma de poner las diferencias en contexto. Re-escalar (estandarizar) las diferencias nos ayuda a dar sentido a la diferencia entre grupos y facilita evaluar si el cambio es importante, incluso cuando no estamos muy familiarizados con la escala utilizada para las mediciones.\nUn d de Cohen se puede interpretar como un Z-score. Un Z-score es la cantidad de desviaciones est√°ndar que un valor difiere del valor medio de lo que se est√° observando o midiendo, puede ser positivo o negativo dependiendo de si la diferencia es por exceso o por defecto. Por lo tanto, un d de Cohen de -1.2, indica que la media de un grupo est√° 1.2 desviaci√≥n est√°ndar por debajo de la media del otro grupo.\nIncluso con las diferencias de medias estandarizadas, puede ser necesario tener que calibrarnos en funci√≥n del contexto de un problema determinado para poder decir si un valor de d de Cohen es grande, peque√±o, mediano, importante, despreciable, etc. Afortunadamente, esta calibraci√≥n se puede adquirir con la pr√°ctica, a modo de ejemplo si estamos acostumbrados a realizar varios an√°lisis para m√°s o menos el mismo tipo de problemas, podemos acostumbrarnos a un d de Cohen de entre 0.8 y 1.2, de modo que si obtenemos un valor de 2 podr√≠a ser que estamos frente a algo importante, inusual (¬°o un error!). Una alternativa es consultar con expertos en el tema.\nUna muy buena p√°gina web para explorar c√≥mo se ven los diferentes valores de Cohen‚Äôs es http://rpsychologist.com/d3/cohend. En esa p√°gina, tambi√©n encontrar√°n otras formas de expresar el tama√±o del efecto; algunas de ellos podr√≠an ser m√°s intuitivas, como la probabilidad de superioridad que analizaremos a continuaci√≥n.\n\n\n3.6.2 Probabilidad de superioridad\nEsta es otra forma de informar el tama√±o del efecto y se define como la probabilidad que un dato tomado al azar de un grupo tenga un valor mayor que un punto tomado al azar del otro grupo. Si suponemos que los datos que estamos utilizando se distribuyen de forma Gaussiana, podemos calcular la probabilidad de superioridad a partir de la d de Cohen usando la expresi√≥n:\n\\[\\begin{equation} \\label{eq_ps}\nps = \\Phi \\left ( \\frac{\\delta}{\\sqrt{2}} \\right)\n\\end{equation}\\]\nDonde \\(\\Phi\\) es la distribuci√≥n normal acumulada y \\(\\delta\\) es el d de Cohen. Podemos calcular una estimaci√≥n puntual de la probabilidad de superioridad (lo que generalmente se informa) o podemos calcular la distribuci√≥n a posteriori. Si no estamos de acuerdo con la suposici√≥n de normalidad, podemos descartar esta f√≥rmula y calcularla directamente a partir del posterior sin necesidad de asumir ninguna distribuci√≥n. Esta es una de las ventajas de usar m√©todos de muestreo para estimar el a posteriori, una vez obtenidas las muestras lo que podemos hacer con ellas es muy flexible.\n\n\n3.6.3 El conjunto de datos tips\nPara explorar el tema de esta secci√≥n, vamos a usar el conjunto de datos tips (propinas). Estos datos fueron informados por primera vez por Bryant, P. G. and Smith, M (1995) Practical Data Analysis: Case Studies in Business Statistics.\nQueremos estudiar el efecto del d√≠a de la semana sobre la cantidad de propinas en un restaurante. Para este ejemplo, los diferentes grupos son los d√≠as. Comencemos el an√°lisis cargando el conjunto de datos como un DataFrame de Pandas usando solo una l√≠nea de c√≥digo. Si no est√° familiarizado con Pandas, el comando tail se usa para mostrar las √∫ltimas filas de un DataFrame:\n\ntips = pd.read_csv(\"datos/propinas.csv\")\ntips.tail()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      239\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n    \n    \n      240\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n    \n  \n\n\n\n\nPara este ejemplo solo vamos a usar las columnas day y tip y vamos a usar la funci√≥n plot_forest de ArviZ. A√∫n cuando ArviZ est√° pensado para an√°lisis de modelos Bayesianos algunos de sus funciones pueden ser √∫tiles para analizar datos.\n\naz.plot_forest(\n    tips.pivot(columns=\"day\", values=\"tip\").to_dict(\"list\"),\n    kind=\"ridgeplot\",\n    hdi_prob=1,\n    figsize=(12, 4),\n);\n\n\n\n\nA fin de simplificar el an√°lisis vamos a crear 2 variables: * La variable categories contiene los nombres de los d√≠as (abreviados y en ingl√©s) * La variable idx codifica los d√≠as de la semana como enteros entre 0 y 3.\n\ncategories = np.array([\"Thur\", \"Fri\", \"Sat\", \"Sun\"])\n\ntip = tips[\"tip\"].values\nidx = pd.Categorical(tips[\"day\"], categories=categories).codes\n\nEl modelo para este problema es basicamente igual a model_g, con la diferencia que \\(\\mu\\) y \\(\\sigma\\) ahora ser√°n vectores en vez de escalares. La sint√°xis de PyMC es super-√∫til para estos caso, en vez de usar for loops escribimos el modelo de forma vectorizada, para ello especificamos el argumento shape para los priors \\(\\mu\\) y \\(\\sigma\\) y para el likelihood usamos la variable idx para indexar de forma adecuada \\(\\mu\\) y \\(\\sigma\\) para asegurar que usamos los par√°metros correctos para cada grupo. En este ejemplo un \\(\\mu\\) para jueves, otra para viernes, otra para s√°bado y una cuarta para domingo, y lo mismo para \\(\\sigma\\).\n    with pm.Model() as comparing_groups:\n        Œº = pm.Normal('Œº', mu=0, sigma=10, shape=4)\n        œÉ = pm.HalfNormal('œÉ', sigma=10, shape=4)\n\n        y = pm.Normal('y', mu=Œº[idx], sigma=œÉ[idx], observed=tip)\nPyMC provee una sintaxis alternativa, la cual consisten en especificar coordenadas y dimensiones. La ventaja de esta alternativa es que permite una mejor integraci√≥n con ArviZ.\nVeamos, en este ejemplo tenemos 4 valores para las medias y 4 para las desviaciones estandard, y por eso usamos shape=4. El InferenceData tendr√° 4 indices 0, 1, 2, 3 correspondientes a cada uno de los 4 d√≠as. Pero es trabajo del usuario asociaer esos indices n√∫mericos con los d√≠as.\nAl usar coordendas y dimensiones nosotros podremos usar los r√≥tulos 'Thur', 'Fri', 'Sat', 'Sun' para referirnos a los par√°metros relacionados con cada uno de estos d√≠as. ArviZ tambi√©n podr√° hacer uso de estos r√≥tulos. Vamos a especificar dos coordenadas days con las dimensiones 'Thur', 'Fri', 'Sat', 'Sun' y ‚Äúdays_flat‚Äù que contendr√° los mismo r√≥tulos pero repetidos seg√∫n el √≥rden y longitud que corresponda con cada observaci√≥n. Esto √∫ltimo ser√° √∫til para poder obtener pruebas predictivas a posteriori para cada d√≠a.\n\ncoords = {\"days\": categories, \"days_flat\": categories[idx]}\n\nwith pm.Model(coords=coords) as comparing_groups:\n    Œº = pm.HalfNormal(\"Œº\", sigma=5, dims=\"days\")\n    œÉ = pm.HalfNormal(\"œÉ\", sigma=1, dims=\"days\")\n\n    y = pm.Gamma(\"y\", mu=Œº[idx], sigma=œÉ[idx], observed=tip, dims=\"days_flat\")\n\n    idata_cg = pm.sample()\n    idata_cg.extend(pm.sample_posterior_predictive(idata_cg))\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œº, œÉ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\nSampling: [y]\n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00<00:00]\n    \n    \n\n\nUna vez obtenido un a posteriori podemos hacer todos los an√°lisis que creamos pertinentes con el. Primero hagamos una prueba predictiva a posteriori. Vemos que en general somos capaces de capturar la forma general de las distribuciones, pero hay detalles que se nos escapan. Esto puede deberse al tama√±o relativamente peque√±o de la muestra, a que hay otros factores adem√°s del d√≠a que tienen influencia en las propinas o una combinaci√≥n de ambas. Por ahora seguiremos con el an√°lisis considerando que el modelo es lo suficientemente bueno\n\n_, axes = plt.subplots(2, 2)\naz.plot_ppc(\n    idata_cg,\n    num_pp_samples=100,\n    coords={\"days_flat\": [categories]},\n    flatten=[],\n    ax=axes,\n);\n\n\n\n\nPodemos ver la distribuci√≥n de cada uno de los par√°metros haciendo\n\naz.plot_posterior(idata_cg, var_names=\"Œº\", figsize=(12, 3));\n\n\n\n\nLa figura anterior es bastante informativa, por ejemplo vemos que los valores medios de las propinas difieren en solo unos pocos centavos y que para los domingos el valor es ligeramente m√°s alto que para el resto de los d√≠as analizados.\nPero quiz√° consideramos que puede ser mejor mostrar los datos de otra forma. Por ejemplo podemos calcular todas las diferencias de medias a posteriori entre si. Adem√°s podr√≠amos quere usar alguna medida del tama√±o del efecto que sea popular entre nuestra audiencia, como podr√≠an ser la probabilidad de superioridad o d de Cohen.\nCohen‚Äôs d\n\\[\n\\frac{\\mu_2 - \\mu_1}{\\sqrt{\\frac{\\sigma_1^2 + \\sigma_2^2}{2}}}\n\\]\n\nSe puede interpretar como un z-score. Cu√°ntas desviaciones est√°ndar una media de un grupo est√° por encima (o por debajo) de la media del otro grupo\nEjemplo interactivo\n\nProbabilidad de superioridad\n\nLa probabilidad que un dato tomado de un grupo sea mayor que la de un dato tomado del otro grupo.\nSi suponemos que los datos se distribuyen normalmente, entonces:\n\n\\[\n\\text{ps} = \\Phi \\left ( \\frac{\\delta}{\\sqrt{2}} \\right)\n\\]\n\\(\\Phi\\) es la cdf de una distribuci√≥n normal \\(\\delta\\) es el valor del Cohen‚Äôs d.\nCon el siguiente c√≥digo usamos plot_posterior para graficar todas las diferencias no triviales o redundantes. Es decir evitamos las diferencias de un d√≠a con sigo mismo y evitamos calcular ‚ÄòFri - Thur‚Äô si ya hemos calculado ‚ÄòThur- Fri‚Äô. Si lo vieramos como una matriz de diferencias solo estar√≠amos calculando la porci√≥n triangular superior.\n\ncg_posterior = az.extract(idata_cg)\n\ndist = pz.Normal(0, 1)\n\ncomparisons = [(categories[i], categories[j]) for i in range(4) for j in range(i+1, 4)]\n\n_, axes = plt.subplots(3, 2, figsize=(13, 9), sharex=True)\n\nfor (i, j), ax in zip(comparisons, axes.ravel()):\n    means_diff = cg_posterior[\"Œº\"].sel(days=i) - cg_posterior['Œº'].sel(days=j)\n    \n    d_cohen = (means_diff /\n               np.sqrt((cg_posterior[\"œÉ\"].sel(days=i)**2 + \n                        cg_posterior[\"œÉ\"].sel(days=j)**2) / 2)\n              ).mean().item()\n    \n    ps = dist.cdf(d_cohen/(2**0.5))\n    az.plot_posterior(means_diff.values, ref_val=0, ax=ax)\n    ax.set_title(f\"{i} - {j}\")\n    ax.plot(0, label=f\"Cohen's d = {d_cohen:.2f}\\nProb sup = {ps:.2f}\", alpha=0)\n    ax.legend(loc=1)\n\n\n\n\nUna forma de interpretar estos resultados es comparando el valor de referencia con el intervalo HDI. De acuerdo con la figura anterior, tenemos solo un caso cuando el 94% HDI excluye el valor de referencia de cero, la diferencia en las propinas entre el jueves y el domingo. Para todos los dem√°s ejemplos, no podemos descartar una diferencia de cero (de acuerdo con los criterios de superposici√≥n de valores de referencia de HDI). Pero incluso para ese caso, ¬øes una diferencia promedio de ‚âà0.5 d√≥lares lo suficientemente grande? ¬øEs suficiente esa diferencia para aceptar trabajar el domingo y perder la oportunidad de pasar tiempo con familiares o amigos? ¬øEs suficiente esa diferencia para justificar promediar las propinas durante los cuatro d√≠as y dar a cada mozo/a la misma cantidad de dinero de propina? Este tipo de preguntas es crucial para interpretar los datos y/o tomar decisiones, pero las respuestas no las puede ofrecer la estad√≠stica de forma autom√°tica (ni ning√∫n otro procedimiento). La estad√≠stica solo pueden ayudar en la interpretaci√≥n y/o toma de decisiones.\nNota: Dependiendo del p√∫blico el gr√°fico anterior puede que est√© demasiado ‚Äúcargado‚Äù, quiz√° es √∫til para una discusi√≥n dentro del equipo de trabajo, pero para un p√∫blico en general quiz√° convenga sacar elementos o repartir la informaci√≥n entre una figura y una tabla o dos figuras."
  },
  {
    "objectID": "02_Programaci√≥n_probabil√≠stica.html#resumen",
    "href": "02_Programaci√≥n_probabil√≠stica.html#resumen",
    "title": "3¬† Programaci√≥n probabilista",
    "section": "3.7 Resumen",
    "text": "3.7 Resumen\nAunque la estad√≠stica Bayesiana es conceptualmente simple, los modelos probabil√≠sticos a menudo conducen a expresiones anal√≠ticamente intratables. Durante muchos a√±os, esta fue una gran barrera que obstaculiz√≥ la adopci√≥n amplia de m√©todos Bayesianos. Afortunadamente, la matem√°tica, la f√≠sica y la inform√°tica vinieron al rescate en forma de m√©todos num√©ricos capaces, al menos en principio, de resolver cualquier inferencia. La posibilidad de automatizar el proceso de inferencia ha llevado al desarrollo de los lenguajes de programaci√≥n probabilista que permiten una clara separaci√≥n entre la definici√≥n del modelo y la inferencia.\nPyMC es una librer√≠a de Python para programaci√≥n probabil√≠stica con una sintaxis simple, intuitiva y f√°cil de leer que tambi√©n est√° muy cerca de la sintaxis estad√≠stica utilizada para describir modelos probabil√≠sticos. En este cap√≠tulo introducimos PyMC revisando el problema de la moneda que vimos en el cap√≠tulo anterior. La diferencia es que no tuvimos que derivar anal√≠ticamente la distribuci√≥n a posteriori. Los modelos en PyMC se definen dentro de un bloque with; para agregar una distribuci√≥n de probabilidad a un modelo, solo necesitamos escribir una l√≠nea de c√≥digo. Las distribuciones se pueden combinar y se pueden usar como priors (variables no observadas) o likelihoods (variables observadas). En la sintaxis de PyMC la √∫nica diferencia entre ambas es que para esta √∫ltima debemos pasar los datos usando el argumento observed. Si todo va bien las muestras generadas por PyMC ser√°n representativas de la distribuci√≥n a posteriori y por lo tanto ser√°n una representaci√≥n de las consecuencias l√≥gicas del modelo y los datos.\nArviZ es una librer√≠a que nos ayuda a explorar los modelos definidos por PyMC (u otroas librer√≠as como PyStan, TFP, BeanMachine, etc). Una forma de usar el posterior para ayudarnos a tomar decisiones es comparando la ROPE con el intervalo HDI. Tambi√©n mencionamos brevemente la noci√≥n de funciones de p√©rdida, una aproximaci√≥n formal para cuantificar los costos y beneficios asociados a la toma de decisiones. Aprendimos que las funciones de p√©rdida y las estimaciones puntuales est√°n √≠ntimamente asociadas.\nHasta este momento todos los ejemplos estuvieron basado en modelos con un solo par√°metro. Sin embargo PyMC permite, en principiop, usar un n√∫mero arbitrario de par√°metros, esto lo ejemplificamos con un modelo Gaussiano y luego una generalizaci√≥n de este, el modelo t de Student. La distribuci√≥n t de Student suele usarse como alternativa a la Gaussiana cuando queremos hacer inferencias robustas a valores aberrantes. Pronto veremos c√≥mo se puede usar estos modelos como para construir regresi√≥nes lineales.\nFinalizamos comparanod medias entre grupos, una tarea com√∫n en an√°lisis de datos. Si bien esto a veces se enmarca en el contexto de las pruebas de hip√≥tesis, tomamos otra ruta y trabajamos este problema como una inferencia del tama√±o del efecto."
  },
  {
    "objectID": "02_Programaci√≥n_probabil√≠stica.html#para-seguir-leyendo",
    "href": "02_Programaci√≥n_probabil√≠stica.html#para-seguir-leyendo",
    "title": "3¬† Programaci√≥n probabilista",
    "section": "3.8 Para seguir leyendo",
    "text": "3.8 Para seguir leyendo\n\nLa documentaci√≥n de PyMC tiene varios ejemplos de como usar este librer√≠a y modelos de distinto tipo.\nProbabilistic Programming and Bayesian Methods for Hackers de Cameron Davidson-Pilon y varios otros contribuidores. Originalmente escrito en PyMC2 ha sido portado a PyMC\nWhile My MCMC Gently Samples. Un blog de Thomas Wiecki, desarrollador de PyMC.\nStatistical Rethinking by Richard McElreath es probablemente el mejor libro introductorio de estad√≠stica Bayesiana. El libro usa R/Stan. Pero varias personas hemos contribuido para portar el c√≥digo a Python/PyMC\nDoing Bayesian Data Analysis de John K. Kruschke es otro libro introductorio bastante accesible. La mayor√≠a de los ejemplos de la primer edici√≥n est√°n disponibles en Python/PyMC y de la segunda edici√≥n ac√°."
  },
  {
    "objectID": "02_Programaci√≥n_probabil√≠stica.html#ejercicios",
    "href": "02_Programaci√≥n_probabil√≠stica.html#ejercicios",
    "title": "3¬† Programaci√≥n probabilista",
    "section": "3.9 Ejercicios",
    "text": "3.9 Ejercicios\n\nUsando PyMC reproduc√≠ los resultados del primer cap√≠tulo para el problema de la moneda (use los 3 priors usados en ese cap√≠tulo).\nReemplaz√° la distribuci√≥n beta por una uniforme en el intervalo [0, 1] ¬øC√≥mo cambia la velocidad del muestreo? ¬øY si se usas un intervalo m√°s √°mplio, como [-3, 3]?\nPara el modelo_g. Us√° una Gaussiana para la media, centrada en la media emp√≠rica. Prob√° modificar la desviaci√≥n est√°ndard de ese prior ¬øCu√°n robusto/sensible son los resultados a la elecci√≥n del prior?\nLa Gaussiana es una distribuci√≥n sin l√≠mites es decir es v√°lida en el intervalo \\([-\\infty, \\infty]\\), en el ejemplo anterior la usamos para modelar datos que sabemos tienen l√≠mites ¬øQu√© opinas de esta elecci√≥n?\nUsando los datos de la velocidad de la luz, calcul√° la media y desviaci√≥n est√°ndar con y sin los outilers, compar√° esos valores con los obtenidos con el modelo_g y con el modelo_t.\nModific√° el modelo de las propinas para usar una distribuci√≥n t de Student, prob√° usando un solo \\(\\nu\\) para los cuatro grupos y tambi√©n usando un valor de \\(\\nu\\) por grupo.\nCalcul√° la probabilidad de superioridad a partir de las muestras del posterior (sin usar la formula de probabilidad de superioridad a partir de la d de Cohen). Comparar los resultados con los valores obtenidos a anal√≠ticamente.\nAplica al menos uno de los modelos visto en este cap√≠tulo a datos propios o de tu inter√©s."
  },
  {
    "objectID": "03_Modelos_jer√°rquicos.html#modelos-jer√°rquicos",
    "href": "03_Modelos_jer√°rquicos.html#modelos-jer√°rquicos",
    "title": "4¬† Modelado Jer√°rquico",
    "section": "4.1 Modelos Jer√°rquicos",
    "text": "4.1 Modelos Jer√°rquicos\nEl siguiente ejemplo est√° tomado del cap√≠tulo 9 del libro ‚ÄúDoing Bayesian Data Analysis‚Äù de John K. Kruschke. Supongamos que en vez de 1 moneda tenemos 3, supongamos adem√°s que sabemos que las tres monedas fueron echas con la misma matriz (en la misma f√°brica). Para estimar el valor de \\(\\theta\\) tenemos dos opciones:\n\nestimar un valor de \\(\\theta\\) para cada moneda por separado.\njuntar las tres monedas en un mismo conjunto de datos y calcular un solo valor de \\(\\theta\\)\n\nLa ventaja de la opci√≥n 1 es que las monedas podr√≠an diferir entre s√≠ por lo que calcular 3 valores de \\(\\theta\\) podr√≠a ser muy informativo. La desventaja de este modelo es que hace caso omiso a la informaci√≥n que indica que las 3 monedas tienen un origen com√∫n, por lo que es probable que compartan caracter√≠sticas.\nLa ventaja de la opci√≥n 2 es que la cantidad de datos por par√°metro aument√≥, lo que reduce la incerteza. El problema es que pasamos a asumir que las 3 monedas son en realidad una, lo cual no ser√≠a problem√°tico si las tres monedas fueran muy similares entre s√≠, pero esto podr√≠a no ser una buena aproximaci√≥n.\nUna tercera opci√≥n es hacer algo a mitad de camino entre 1 y 2. Esto se consigue construyendo un modelo jer√°rquico o modelo multinivel. Este tipo de modelo nos permitir√° estimar un valor de \\(\\theta\\) para cada moneda de forma tal que la estimaci√≥n de cada valor de \\(\\theta\\) influencie al resto.\nEn estad√≠stica Bayesiana construir modelos jer√°rquicos es sencillo. A continuaci√≥n veremos que un modelo jer√°rquico para las 3 monedas es muy similar al usado para el caso de 1 sola moneda, solo que ahora colocamos un a priori ¬°sobre el a priori!\nRecordemos, el modelo del cap√≠tulo anterior era:\n\\[\\begin{align}\n\\theta &\\sim \\operatorname{Beta}(\\alpha, \\beta) \\\\\ny &\\sim \\operatorname{Bin}(n=1, p=\\theta)\n\\end{align}\\]\nEn un modelo jer√°rquico los argumentos de la distribuci√≥n Beta (\\(\\alpha\\) y \\(\\beta\\)) no son constantes si no que son valores que proviene de alguna otra distribuci√≥n. En nuestro modelo tendremos que:\n\\[\\begin{align}\n\\mu &\\sim \\operatorname{Beta}(\\alpha, \\beta) \\\\\n\\nu &\\sim \\operatorname{Gamma}(s, r) \\\\\n\\theta &\\sim \\operatorname{Beta}(\\alpha=\\mu, \\beta=\\nu \\\\\ny &\\sim \\operatorname{Bin}(n=1, p=\\theta)\n\\end{align}\\]\nGr√°ficamente, tenemos:\n\nEn los modelos jer√°rquicos a los par√°metros \\(\\mu\\) y a \\(\\kappa\\) se los llama hiper a prioris o hiperpar√°metros ya que son ellos quienes determinan el valor del a priori. La diferencia entre el modelo del cap√≠tulo anterior y el del presente es que ahora los valores que puede tomar \\(\\theta\\) dependen no ya de una distribuci√≥n fija (\\(\\alpha=1\\) y \\(\\beta=1\\)) si no de una distribuci√≥n que depende de los valores de \\(\\mu\\) y \\(\\kappa\\), y que estimaremos a partir de los datos. Es decir es posible estimar el a priori a partir de los datos, pero solo por que hemos introducido hiper a prioris.\nRecordar√°n que la distribuci√≥n Beta se pod√≠a parametrizar en t√©rminos de \\(\\alpha\\) y \\(\\beta\\), pero tambi√©n de \\(\\mu\\) y \\(\\kappa\\), donde \\(\\mu\\) es la media y \\(\\kappa\\) es la concentraci√≥n (la inversa de la dispersi√≥n). Tenemos entonces que \\(\\mu\\) reflejar√° el valor promedio de 3 valores de \\(\\theta\\) y que si la proporci√≥n de caras en las tres monedas es similar entre si \\(\\kappa\\) tomara un valor m√°s alto; mientras que si las monedas son diferentes entre si \\(\\kappa\\) tomar√° un valor m√°s bajo.\n\n4.1.1 ¬øPor qu√© la elecci√≥n de los hiper a prioris?\nBueno dado que \\(\\mu\\) es la media del vector \\(\\theta\\) (y que \\(\\theta\\) solo puede tomar valores entre 0 y 1), \\(\\mu\\) queda restringida a valores entre 0 y 1 (al igual que una distribuci√≥n beta), siguiendo el mismo razonamiento \\(\\kappa\\) va entre \\([0, \\infty]\\) al igual que la distribuci√≥n gamma. Otras distribuciones igualmente razonables podr√≠an haber sido:\n\n$ U(0, 1)$\n$ ()$\n\nPrimero que nada generemos algunos datos sint√©ticos y los pondremos de una forma que sea m√°s simple pas√°rselos al modelo, esto quedar√° un poco m√°s claro al la especificaci√≥n del modelo.\nVamos a suponer que con cada una de las 3 monedas hicimos 10 experimentos de Bernoulli (las arrojamos al aire) y obtuvimos como resultado, para cada caso, 5 caras.\n\nN =  np.array([10, 10, 10])  # N√∫mero de experimentos por moneda\nz =  np.array([5, 5, 5]) # np.array([1, 5, 9])  # N√∫mero de caras en los Ni experimentos.\n\n# vector conteniendo los √≠ndices para cada moneda (desde 0 al n√∫mero de monedas)\nmonedas = np.repeat(np.arange(len(N)), N)\n# vector con 1 para caras y 0 para cecas\ndatos = np.hstack([np.repeat([1, 0], [z[i], N[i]-z[i]]) for i in range(len(N))])\n\nComo no sabemos demasiado sobre \\(\\mu\\) y \\(\\kappa\\), vamos a elegir $ (, )$, lo que equivale a una distribuci√≥n centrada en 0.5, pero que casi asigna la misma probabilidad a todos los valores entre 0 y 1. Y $ = (, )$, lo que equivale a una exponencial con media y desviaci√≥n est√°ndar de 10.\nLa especificaci√≥n del modelo es igual a lo que hemos venido haciendo, la √∫nica diferencia es que en la linea 8 podemos observar que hay un argumento llamando shape. Esto nos permite especificar las dimensiones de (en este caso) \\(\\theta\\). PyMC permite escribir modelos vectorizados ahorr√°ndonos el tener que escribir for loops. Esa es la raz√≥n por la cual en la celda superior creamos un vector monedas que usamos en la linea 10 (de la especificaci√≥n del modelo) para indexar \\(\\theta\\).\n\nwith pm.Model() as modelo_j:\n    # definimos los hiperpar√°metros\n    Œº = pm.Beta('Œº', alpha=2, beta=2)\n    Œ∫ = pm.Gamma('Œ∫', alpha=1, beta=0.1)\n    #Œ∫ = pm.Gamma('Œ∫', mu=10, sd=10)\n    \n    # definimos el a priori\n    Œ∏ = pm.Beta('Œ∏', alpha=Œº * Œ∫, beta=(1 - Œº) * Œ∫, shape=len(N))\n\n    # definimos el likelihood\n    y = pm.Bernoulli('y', p=Œ∏[monedas], observed=datos)\n\n    # muestreamos\n    idata_j = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œº, Œ∫, Œ∏]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:04<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 5 seconds.\n\n\n\naz.plot_posterior(idata_j, figsize=(12, 5));\n\n\n\n\n\naz.summary(idata_j, kind=\"stats\")\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n    \n  \n  \n    \n      Œº\n      0.501\n      0.106\n      0.302\n      0.697\n    \n    \n      Œ∫\n      15.969\n      11.649\n      0.798\n      36.936\n    \n    \n      Œ∏[0]\n      0.500\n      0.117\n      0.285\n      0.718\n    \n    \n      Œ∏[1]\n      0.502\n      0.117\n      0.295\n      0.735\n    \n    \n      Œ∏[2]\n      0.503\n      0.119\n      0.280\n      0.723\n    \n  \n\n\n\n\nPodemos observar que el valor de \\(\\kappa\\) del a posteriori es mayor que del a priori. Esto es razonable ya que los experimentos con las 3 monedas han resultado id√©nticos, indicando que la matriz tiene un efecto importante sobre el resultado de \\(\\theta\\) para cada moneda.\n¬øQu√© distribuci√≥n hubi√©ramos obtenido para \\(\\kappa\\) si las monedas hubieran mostrado distintos resultados? Probemos que hubiera pasado si:\nz = [1, 5, 9]\n\n\n4.1.2 Mirando el a posteriori desde varios lados\nEl a posteriori contiene toda la informaci√≥n que resulta de un an√°lisis Bayesiano. Por lo que puede ser muy informativo analizarlo desde varios lados. Adem√°s de los gr√°ficos que provee ArviZ como el siguiente:\n\naz.plot_pair(idata_j, marginals=True, figsize=(10, 8), kind=(\"scatter\", \"kde\"),\n             scatter_kwargs={\"alpha\":0.25},\n             point_estimate=\"median\",\n             point_estimate_kwargs={\"color\":\"gray\"},\n             point_estimate_marker_kwargs={\"color\":\"gray\"});\n\n\n\n\nPodemos analizar el a posteriori usando nuestras propias gr√°ficas, como la siguiente.\n\n# Creamos arreglos tomando muestras del posterior\nposterior = az.extract(idata_j)\ntheta1_pos = posterior['Œ∏'][0].values\ntheta2_pos = posterior['Œ∏'][1].values\ntheta3_pos = posterior['Œ∏'][2].values\nmu_pos = posterior['Œº'].values\nkappa_pos = posterior['Œ∫'].values\n\n_, ax = plt.subplots(4, 3, figsize=(12, 12))\n\n# Gr√°ficos de dispersi√≥n de los hiper-par√°metros\nax[0, 0].scatter(mu_pos, kappa_pos, marker='o', alpha=0.01)\nax[0, 0].set_xlim(0,1)\nax[0, 0].set_xlabel(r'$\\mu$')\nax[0, 0].set_ylabel(r'$\\kappa$')\n\naz.plot_posterior(mu_pos, ax=ax[0, 1], round_to=1)\nax[0, 1].set_xlabel(r'$\\mu$')\nax[0, 1].set_xlim(0,1)\n\naz.plot_posterior(kappa_pos, ax=ax[0, 2], round_to=1)\nax[0, 2].set_xlabel(r'$\\kappa$')\ncount = 1\nfor i, j in (theta1_pos, 'theta1'), (theta2_pos, 'theta2'), (theta3_pos, 'theta3'):\n    az.plot_posterior(i, ax=ax[count, 0], round_to=1)\n    ax[count, 0].set_xlabel('$\\{}$'.format(j))\n    ax[count, 0].set_xlim(0,1)\n    countb = 1\n    for k, l in (mu_pos, 'mu'), (kappa_pos, 'kappa'):\n        ax[count, countb].scatter(k, i, marker='o', alpha=0.1)\n        ax[count, countb].set_xlabel('$\\{}$'.format(l))\n        ax[count, countb].set_ylabel('$\\{}$'.format(j), rotation=0)\n        ax[count, countb].set_xlim(0)\n        ax[count, countb].set_ylim(0,1)\n        countb += 1\n    count += 1\n\n\n\n\n\n\n4.1.3 Contracci√≥n (shrinking)\nProbemos ahora con otros ejemplos (puede ser conveniente guardar las figuras obtenidas con distintos nombres).\n\nz = [1,1,1]\nz = [9,9,9]\nz = [9,1,9]\n\n¬øCu√°les son los valores de \\(\\theta\\) obtenidos en cada caso? Es lo mismo el valor estimado de \\(\\theta\\) para una moneda cuando cae 1 de 10 veces caras (y las otras dos tambi√©n), que cuando una moneda cae 1 de 10 veces caras y las otras dos caen 9 de 10 veces cara?\nComo podr√°n ver si hacen el ejercicio ¬°el valor estimado \\(\\theta\\) no es el mismo! ¬øPor qu√© sucede esto?\nPorque el modelo especifica que las monedas NO son independientes. El modelo asume que las 3 monedas provienen de una misma matriz, por lo tanto la estimaci√≥n de \\(\\theta\\) para una moneda es afectada por las otras y al mismo tiempo afecta a las otras. Este fen√≥meno se llama contracci√≥n, la raz√≥n del nombre es que las estimaciones individuales tienden a contraerse alrededor del valor promedio de las 3 estimaciones (en nuestro modelo \\(\\mu\\)) esto se hace mas evidente para los valores aberrantes. Si todas las monedas menos una indican un valor de \\(\\theta\\) m√°s o menos similar la que posee el valor distinto tendr√° un \\(\\theta\\) mucho m√°s cercano al valor de las dem√°s que si la hubi√©ramos estimado de forma individual.\nEsto quiz√° pueda parecerles problem√°tico, pero no es m√°s que un reflejo de lo que asumimos al crear el modelo. La matriz con la que fueron echas las monedas influencia el sesgo de las mismas. Entonces, la estimaci√≥n de cada elemento del vector \\(\\theta\\) debe influenciar y ser influenciado por las estimaciones de los dem√°s elementos de \\(\\theta\\). Esto es una forma de regularizaci√≥n que los m√©todos frecuentistas deben introducir ad-hoc, pero que sin embargo ya viene incluido en un an√°lisis Bayesiano.\nEntonces el modelo jer√°rquico Bayesiano que hemos construido nos dice, no solo los valores de \\(\\theta\\), sino lo valores de \\(\\mu\\) (el sesgo promedio) introducido por la matriz y los valores de \\(\\kappa\\) (cuan fuerte es el efecto de la matriz sobre los sesgos individuales de \\(\\theta\\)).\n\n\n4.1.4 Veamos otro ejemplo\nLas prote√≠nas son mol√©culas formadas por 20 unidas, llamadas amino √°cidos, cada amino √°cido puede aparecer en una prote√≠na 0 o m√°s veces. As√≠ como una melod√≠a est√° definida por una sucesi√≥n de notas musicales, una prote√≠na est√° definida por una sucesi√≥n de amino √°cidos. Algunas variaciones de notas pueden dar como resultados peque√±as variaciones sobre la misma melod√≠a, otras variaciones pueden resultar en melod√≠as completamente distintas, algo similar sucede con las prote√≠nas. Una forma de estudiar prote√≠nas es usando resonancia magn√©tica nuclear (la misma t√©cnica usada para im√°genes m√©dicas). Esta t√©cnica permite medir diversos observables, uno de ellos se llama desplazamiento qu√≠mico y para simplificar diremos que podemos medir tantos desplazamientos qu√≠micos como amino √°cidos tenga una prote√≠na. Los amino√°cidos son una familia de compuestos qu√≠micos por lo que tendr√≠a sentido tratarlos a todos de igual forma, pero al mismo tiempo tienen diferentes propiedades qu√≠micas, las cuales de hecho son relevantes para comprender como funcionan las prote√≠nas! Por lo que tambi√©n tiene sentido tratarlos por separado. Como ya vimos una alternativa es construir un modelo jer√°rquico y hacer algo a mitad de camino.\nEl siguiente conjunto de datos contiene valores de desplazamientos qu√≠micos para un conjunto de prote√≠nas. Si inspeccionan el DataFrame cs_data ver√°n que tiene 4 columnas:\n\nLa primera es un c√≥digo que identifica a la prote√≠na (pueden obtener much√≠sima informaci√≥n sobre esa prote√≠na ingresando ese c√≥digo en https://www.rcsb.org/.).\nLa segunda columna tiene el nombre del amino √°cido (pueden corroborar que hay tan solo 20 nombres √∫nicos).\nLa tercera contiene valores t√©oricos de desplazamientos qu√≠micos (calculados usando m√©todos cu√°nticos).\nLa cuarta tiene valores experimentales.\n\nLa motivaci√≥n de este ejemplo es comparar las diferencias entre valores te√≥ricos y experimentales, entre otras razones para evaluar la capacidad de los m√©todos cu√°nticos para reproducir valores experimentales.\n\ncs_data = pd.read_csv('datos/chemical_shifts_theo_exp.csv')\ndiff = cs_data.theo - cs_data.exp\ncat_encode = pd.Categorical(cs_data['aa'])\nidx = cat_encode.codes\ncoords = {\"aa\": cat_encode.categories}\n\nPara resaltar la diferencia entre un modelo jer√°rquico y uno no-jer√°rquico vamos a construir ambos. Primero el no-jer√°rquico.\n\nwith pm.Model(coords=coords) as cs_nh:         \n    Œº = pm.Normal('Œº', mu=0, sigma=10, dims=\"aa\") \n    œÉ = pm.HalfNormal('œÉ', sigma=10, dims=\"aa\") \n \n    y = pm.Normal('y', mu=Œº[idx], sigma=œÉ[idx], observed=diff) \n     \n    idata_cs_nh = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œº, œÉ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\nY ahora el jer√°rquico.\nEste modelo tiene un hyper-prior para la media de \\(\\mu\\) y otro para la desviaci√≥n est√°ndar de \\(\\mu\\). Para \\(\\sigma\\) no usamos un hyper-prior, es decir asumimos valores independientes. Esta es una decisi√≥n que tom√© para simplificar el modelo, en principio no habr√≠a problema con usar un hyper-prior tambi√©n para \\(\\sigma\\) o incluso estimar un solo valor, compartido, de \\(\\sigma\\).\n\nwith pm.Model(coords=coords) as cs_h:\n    # hyper_priors\n    Œº_mu = pm.Normal('Œº_mu', mu=0, sigma=10)\n    Œº_sd = pm.HalfNormal('Œº_sd', 10)\n\n    # priors\n    Œº = pm.Normal('Œº', mu=Œº_mu, sigma=Œº_sd, dims=\"aa\") \n    œÉ = pm.HalfNormal('œÉ', sigma=10, dims=\"aa\") \n\n    y = pm.Normal('y', mu=Œº[idx], sigma=œÉ[idx], observed=diff) \n\n    idata_cs_h = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œº_mu, Œº_sd, Œº, œÉ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\nVamos a comparar los resultados usando un plot_forest. ArviZ permite pasar m√°s de un modelo. Esto es √∫til cuando queremos comparar los valores de par√°metros equivalentes entre modelos como en el presente ejemplo. Noten que estamos pasando varios argumentos para obtener el gr√°fico, como por ejemplo combined=True que combina los resultados de todas las cadenas. Los invito a explorar el significado del resto de los par√°metros.\n\naxes = az.plot_forest([idata_cs_nh, idata_cs_h], model_names=['no_jer√°rquico', 'jer√°rquico'],\n                      var_names='Œº', combined=True, r_hat=False, ess=False, figsize=(10, 7),\n                      colors='cycle')\ny_lims = axes[0].get_ylim()\naxes[0].vlines(idata_cs_h.posterior['Œº_mu'].mean(), *y_lims, color=\"k\", ls=\":\");\n\n\n\n\nBien, tenemos un gr√°fico para 40 valores medios estimados, uno por amino√°cido (20) y esto duplicado ya que tenemos dos modelos. Tambi√©n tenemos los intervalos de credibilidad del 94% y el rango intercuartil (el intervalo que contiene el 50% central de la distribuci√≥n). La l√≠nea vertical es la media parcialmente agrupada, es decir la media seg√∫n el modelo jer√°rquico. El valor es cercano a cero, esto es parte de lo que esperar√≠amos ver si los valores te√≥ricos son buenos reproduciendo los valores experimentales.\nLa parte m√°s relevante de este gr√°fico es que las estimaciones del modelo jer√°rquico son atraidas hacia la media parcialmente agrupada o, de forma equivalente, se contraen con respecto a las estimaciones no agrupadas. Este efecto es m√°s notorio para los grupos m√°s alejados de la media (como 13), adem√°s la incertidumbre es igual o menor que la del modelo no jer√°rquico. Decimos que las estimaciones est√°n parcialmente agrupadas porque tenemos una estimaci√≥n para cada grupo, pero las estimaciones para cada grupos se restringen mutuamente mediante el hiper prior. Por lo tanto, se obtiene una situaci√≥n intermedia entre tener un solo grupo, todos los amino√°cidos juntos, y tener 20 grupos separados, uno por amino√°cido.\nParafraseando el Zen de Python, podemos decir: hierarchical models are one honking great idea - let‚Äôs do more of those!.\nEn los pr√≥ximos cap√≠tulos, seguiremos construyendo modelos jer√°rquicos y aprendiendo c√≥mo usarlos para construir mejores modelos. Tambi√©n discutiremos c√≥mo se relacionan los modelos jer√°rquicos con uno de los problemas m√°s comunes en estad√≠stica, ciencia de datos y Machine learning el problema del overfitting/underfitting."
  },
  {
    "objectID": "03_Modelos_jer√°rquicos.html#resumen",
    "href": "03_Modelos_jer√°rquicos.html#resumen",
    "title": "4¬† Modelado Jer√°rquico",
    "section": "4.2 Resumen",
    "text": "4.2 Resumen\nEste es un cap√≠tulo muy breve pero describe uno de los conceptos m√°s importantes de este curso: los modelos jer√°rquicos. Podemos construir modelos jer√°rquicos cada vez que podamos identificar subgrupos en nuestros datos. En tales casos, en lugar de tratar los subgrupos como entidades separadas o ignorar los subgrupos y tratarlos como un solo gran-grupo, podemos construir un modelo para agrupar-parcialmente la informaci√≥n entre los grupos.\nEl principal efecto de este agrupamiento-parcial es que las estimaciones de cada subgrupo estar√°n sesgadas por las estimaciones del resto de los subgrupos. Este efecto se conoce como contracci√≥n y, en general, es un truco muy √∫til que ayuda a mejorar las inferencias haci√©ndolas m√°s conservadoras (ya que cada subgrupo informa a los dem√°s acercando el resto de las estimaciones hacia √©l) y m√°s informativas, obtenemos estimaciones a nivel de subgrupo y el nivel del grupo."
  },
  {
    "objectID": "03_Modelos_jer√°rquicos.html#ejercicios",
    "href": "03_Modelos_jer√°rquicos.html#ejercicios",
    "title": "4¬† Modelado Jer√°rquico",
    "section": "4.3 Ejercicios",
    "text": "4.3 Ejercicios\n\nRepet√≠ el ejercicio que hicimos con el model_j, pero sin la estructura jer√°rquica. Compar√° los resultados con los obtenidos de forma jer√°rquica.\nCrea una versi√≥n jer√°rquica para el ejemplo de las propinas agrupando parcialmente los d√≠as de la semana.\nAplica al menos uno de los modelos visto en este cap√≠tulo a datos propios o de tu inter√©s."
  },
  {
    "objectID": "04_Diagn√≥stico_MCMC.html#revisitando-el-teorema-de-bayes",
    "href": "04_Diagn√≥stico_MCMC.html#revisitando-el-teorema-de-bayes",
    "title": "5¬† Diagn√≥stico del muestreo",
    "section": "5.1 Revisitando el teorema de Bayes",
    "text": "5.1 Revisitando el teorema de Bayes\nEl teorema de Bayes, tiene una formulaci√≥n que a primera vista parece muy inocente. Tan solo cuatro t√©rminos relacionados por una multiplicaci√≥n y una divisi√≥n.\n\\[\n\\underbrace{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})}_{\\text{posterior}} = \\frac{\\overbrace{p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})}^{\\text{likelihood}}\\; \\overbrace{p(\\boldsymbol{\\theta})}^{\\text{prior}}}{\\underbrace{{p(\\boldsymbol{Y})}}_{\\text{marginal likelihood}}}\n\\]\nPareciera que no sirve de mucho y que es f√°cil de calcular. Sin embargo, ambas apreciaciones son incorrectas. El resto de los cap√≠tulos se centran en mostrar contra ejemplos a la primera aseveraci√≥n, as√≠ que veamos por que a veces su c√°lculo puede ser dif√≠cil y se requieren m√©todos num√©ricos.\nLa raz√≥n est√° en el c√°lculo del likelihood marginal. El cual toma la forma de una integral.\n\\[\n{p(\\boldsymbol{Y}) = \\int_{\\boldsymbol{\\Theta}} p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta}}\n\\]\nEsta integral suele ser dif√≠cil de resolver. Veamos, esta expresi√≥n nos dice que debemos evaluar el likelihood para cada uno de los posibles valores del prior \\(\\theta\\). En la pr√°ctica esa tarea no siempre es sencilla o barata de realizar. Si \\(\\theta\\) representa un solo par√°metro desconocido (como en el modelo beta-binomial) entonces solo hay que resolver una integral, pero si \\(\\theta\\) representa dos par√°metros (como en el modelo Gaussiano) entonces la integral ser√° doble. En definitiva la integral tendr√° tantas dimensiones como par√°metros el modelo. En general las integrales en grandes dimensiones no son simples de resolver.\nAlgo que puede ser poco intuitivo es que esto se contrapone con el c√°lculo de la distribuci√≥n a posteriori. Para obtener una buena aproximaci√≥n a la distribuci√≥n a posteriori bastar√≠a con concentrarse en las regiones donde tanto la contribuci√≥n del prior como del likelihood son relativamente grandes (√°rea gris en la siguiente figura), en general esto es lo que hacen la mayor√≠a de los m√©todos num√©ricos. En cambio esta misma aproximaci√≥n puede conducir a errores en el c√°lculo del likelihood marginal\n\n\n\nPara algunos problemas es posible calcular la distribuci√≥n a posteriori de forma anal√≠tica. Esto ya lo vimos para el modelo beta-binomial donde la posterior es:\n\\[\np(\\theta \\mid y) \\propto \\operatorname{Beta}(\\alpha_{a priori} + y, \\beta_{a priori} + N - y)\n\\]\nPara esos casos suele ser posible tambi√©n calcular el marginal likelihood de forma anal√≠tica.\nPero en general no tenemos expresiones anal√≠ticas y entonces debemos confiar en m√©todos num√©ricos."
  },
  {
    "objectID": "04_Diagn√≥stico_MCMC.html#calculando-la-distribuci√≥n-a-posteriori",
    "href": "04_Diagn√≥stico_MCMC.html#calculando-la-distribuci√≥n-a-posteriori",
    "title": "5¬† Diagn√≥stico del muestreo",
    "section": "5.2 Calculando la distribuci√≥n a posteriori",
    "text": "5.2 Calculando la distribuci√≥n a posteriori\nHay muchas formas de calcular la distribuci√≥n a posteriori\n\n Conjugaci√≥n \n M√©todo de Laplace \n Aproximaci√≥n de Laplace Anidada Integrada (INLA) \n Inferencia Variacional (VI) \nMarkov Chain Monte Carlo (MCMC)\n Sequential Monte Carlo \n‚Ä¶\n\nPor ahora solo hablaremos de los m√©todos MCMC ya que, por el momento, son los m√©todos m√°s generales. Pero para entender de forma m√°s simple que es lo que hacen estos m√©todos conviene empezar desde otro m√©todo, conocido como m√©todo de la grilla.\n\n5.2.1 M√©todo de la grilla\nEl m√©todo de grilla es un enfoque simple de fuerza bruta. La idea central es que incluso si no somos capaces de calcular todo la distribuci√≥n a posteriori, en general si somos capaces de evaluar el a priori y el likelihood punto-a-punto.\nPara un modelo con un solo par√°metro el m√©todo de la grilla se puede resumir de la siguiente forma:\n\nEncuentre un intervalo razonable para el par√°metro (el prior debe dar algunas pistas).\nDefina una grilla de puntos (generalmente equidistantes) en ese intervalo.\nPara cada punto de la grilla, eval√∫e el prior y el likelihood en ese punto y multiplique\n\nLa siguiente figura ilustra este m√©todo\n\n\n\nEl siguiente bloque de c√≥digo (que ya usamos antes) implementa un m√©todo de la grilla interactivo\n\ndef a_posteriori_grilla(grilla=10, a=1, b=1, caras=6, tiradas=9):\n    grid = np.linspace(0, 1, grilla)\n    prior = pz.Beta(a, b).rv_frozen.pdf(grid)\n    likelihood = pz.Binomial(n=tiradas, p=grid).rv_frozen.pmf(caras)\n    posterior = likelihood * prior\n    posterior /= posterior.sum()\n    _, ax = plt.subplots(1, 3, sharex=True, figsize=(12, 3))\n    ax[0].set_title('caras = {}\\ntiradas = {}'.format(caras, tiradas))\n    for i, (e, e_n) in enumerate(zip([prior, likelihood, posterior], ['a priori', 'likelihood', 'a posteriori'])):\n        ax[i].set_yticks([])\n        ax[i].plot(grid, e, 'o-', label=e_n)\n        ax[i].legend()\n\n\ninteract(a_posteriori_grilla, grilla=ipyw.IntSlider(min=2, max=100, step=1, value=15), a=ipyw.FloatSlider(min=1, max=7, step=1, value=1), b=ipyw.FloatSlider(\n    min=1, max=7, step=1, value=1), caras=ipyw.IntSlider(min=0, max=20, step=1, value=6), tiradas=ipyw.IntSlider(min=0, max=20, step=1, value=9));\n\n\n\n\n\n\n\nUtilizando la funci√≥n a_posteriori_grilla podemos comprobar que para obtener una mejor aproximaci√≥n se puede aumentar el n√∫mero de puntos de la cuadr√≠cula. Esta estrategia puede ser √∫til en unas pocas dimensiones (par√°metros). Pero no escala. En la siguiente figura vemos que si necesitamos 4 puntos en 1D, para mantener ese mismo grado de precisi√≥n necesitaremos 16 puntos en 2D y 64 en 3D. La velocidad con la que crecen la cantidad de evaluaciones necesarias crece demasiado r√°pido, una grilla de 100 en 10 dimensiones requerir√≠a de 1e+20 puntos!\n\n\n\nComo si eso no fuera poco, la cosa es m√°s complicada. En espacios de alta dimensi√≥n se dan una serie de fen√≥memos conocidos como concentraci√≥n de la medida o en versi√≥n marketinera la maldici√≥n de la dimensionalidad üëª. Por ejemplo:\n\nEn una hiper-esfera casi todo el volumen est√° en la superficie. Es decir, si uno pelara una hiper-naranja se quedar√≠a con hambre!\nEn un hiper-cubo la masa se concentra en las esquinas\nEn una Gaussiana hiper-dimensional casi toda la masa est√° lejos de la moda\n\nLa idea de estimar la distribuci√≥n a posteriori evaluando, punto a punto, likelihood y prior es muy buena, pero la idea de construir una grilla predefinida solo funciona en muy bajas dimensiones.\nPero no todo est√° perdido, que tal si mantenemos la idea de la evaluaci√≥n puntual, pero nos concentramos en las regiones que importan?\n\n\n5.2.2 Markov Chain Monte Carlo (MCMC)\nEsta es una familia muy extensa de m√©todos utilizados para resolver muchos problemas, entre los que se encuentra el c√°lculo de la distribuci√≥n a posteriori. Conceptualmente se puede pensar a estos m√©todos como generalizaciones del m√©todo de la grilla, ya que tambi√©n se basan en la posibilidad de realizar evaluaciones punto a punto del prior y likelihood. La diferencia crucial es que en vez de utilizar una grilla predefinida el m√©todo realiza evaluaciones que progresivamente se concentran en regiones de alta probabilidad. No solo eso si no que eventualmente el m√©todo devolver√° muestras de forma proporcional a la probabilidad a posteriori. Es decir si una regi√≥n es 3 veces m√°s probable que otra obtendremos 3 veces m√°s muestras de esa regi√≥n que de la otra.\nA muy grandes rasgos, y dado un punto inicial arbitrario, los m√©todos MCMC, constan de dos pasos.\n\nGenerar un nuevo punto a partir de perturbar uno preexistente.\nAceptar o rechazar ese nuevo punto de forma probabilista y comparando la probabilidad del punto preexistente y del nuevo punto.\n\nEsta es esencialmente la receta, la forma exacta en que hacemos cada uno de estos pasos define los distintos m√©todos dentro de la familia MCMC. Veamos uno de los m√°s sencillos de entender y de implementar.\n\n\n5.2.3 Metropolis-Hastings\nMetropolis-Hastings no es un algoritmo muy moderno o particularmente eficiente, pero Metropolis-Hastings es simple de entender y tambi√©n proporciona una base para comprender m√©todos m√°s sofisticados y poderosos.\nEl algoritmo Metropolis-Hasting se define de la siguiente manera:\n\nInicialice el valor del par√°metro \\(\\boldsymbol{X}\\) en \\(x_i\\)\nUtilice una distribuci√≥n de propuesta \\(q(x_{i + 1} \\mid x_i)\\) para generar un nuevo valor \\(x_{i + 1}\\)\nCalcule la probabilidad de aceptar el nuevo valor como:\n\n\\[\np_a (x_{i + 1} \\mid x_i) = \\min \\left (1, \\frac{p(x_{i + 1}) \\;\nq(x_i \\mid x_{i + 1})} {p(x_i) \\; q (x_{i + 1} \\mid x_i)} \\right)\n\\label{acceptance_prob}\n\\]\n\nSi \\(p_a > R\\) donde \\(R \\sim \\mathcal{U}(0, 1)\\), guarde el nuevo valor; de lo contrario, guarde el anterior.\nIterar de 2 a 4 hasta que se haya generado una muestra suficientemente grande\n\nEl algoritmo Metropolis es muy general y se puede usar en aplicaciones no Bayesianas, pero para la presente discusi√≥n, \\(p(x_i)\\) es la densidad del posterior evaluada en el valor del par√°metro \\(x_i\\). Una forma de simplificar un poco el m√©todo es notar que si \\(q\\) es una distribuci√≥n sim√©trica, los t√©rminos \\(q(x_i \\mid x_{i + 1})\\) y \\(q(x_{i + 1} \\mid x_i)\\) se cancelar√°n (conceptualmente significa que es igualmente probable que vayamos de \\(x_{i+1}\\) a \\(x_i\\) o de \\(x_{i}\\) a \\(x_{i+1}\\)), dejando solo un cociente entre el posterior evaluado en dos puntos. Este algoritmo siempre aceptar√° moverse de una regi√≥n de baja probabilidad a una m√°s alta y aceptar√° probabil√≠sticamente moverse de una regi√≥n de alta a una baja probabilidad.\n¬°Otra observaci√≥n importante es que el algoritmo Metropolis-Hastings no es un m√©todo de optimizaci√≥n! No nos importa encontrar el valor del par√°metro con la m√°xima probabilidad, queremos explorar la distribuci√≥n \\(p\\). Es decir a√∫n si el m√©todo encuentra un m√°ximo a√∫n puede moverse a regiones de probabilidades m√°s bajas.\nPara hacer las cosas m√°s concretas, intentemos resolver el modelo Beta-Binomial.\n\\[\\begin{align}\n\\begin{split}\n    \\theta \\sim &\\; \\text{Beta}(\\alpha, \\beta) \\\\\n    Y \\sim &\\; \\text{Bin}(n=1, p=\\theta)\n\\label{eq:beta_binomial}\n\\end{split}\n\\end{align}\\]\nEste modelo tiene una soluci√≥n anal√≠tica. Pero supongamos que no sabemos c√≥mo calcular el posterior y, por lo tanto, implementaremos el algoritmo Metropolis-Hastings usando Python.\n\ndef post(Œ∏, Y, Œ±=1, Œ≤=1):\n    if 0 <= Œ∏ <= 1:\n        prior = stats.beta(Œ±, Œ≤).pdf(Œ∏)\n        like  = stats.bernoulli(Œ∏).pmf(Y).prod()\n        prob = like * prior\n    else:\n        prob = -np.inf\n    return prob\n\nTambi√©n necesitamos datos, por lo que generaremos algunos datos falsos aleatorios para este prop√≥sito.\n\nY = stats.bernoulli(0.7).rvs(20)\n\nY finalmente ejecutamos nuestra implementaci√≥n del algoritmo Metropolis-Hastings:\n\nn_iters = 1000\ncan_sd = 0.05\nŒ± = Œ≤ =  1\nŒ∏ = 0.5 \ntrace = {\"Œ∏\":np.zeros(n_iters)}\np2 = post(Œ∏, Y, Œ±, Œ≤)\n\nfor iter in range(n_iters):\n    Œ∏_can = stats.norm(Œ∏, can_sd).rvs(1)\n    p1 = post(Œ∏_can, Y, Œ±, Œ≤)  \n    pa = p1 / p2\n\n    if pa > stats.uniform(0, 1).rvs(1):\n        Œ∏ = Œ∏_can\n        p2 = p1\n\n    trace[\"Œ∏\"][iter] = Œ∏\n\nEn la l√≠nea 9 del bloque de c√≥digo anterior generamos una propuesta muestreando una distribuci√≥n Normal con desviaci√≥n est√°ndar can_sd. En la l√≠nea 10 evaluamos el posterior en el nuevo valor generado Œ∏_can y en la l√≠nea 11 calculamos la probabilidad de aceptaci√≥n. En la l√≠nea 20 guardamos un valor de Œ∏ en el array trace. Dependiendo del resultado de la comparaci√≥n en la l√≠nea 13, el valor guardado ser√° nuevo o repetiremos el anterior.\nEl primer panel de la siguiente figura muestra cada valor muestreado en cada paso, y el panel de la derecha el histograma de esos valores. El resultado parece razonable. Nada mal para unas pocas lineas de c√≥digo!\n\n_, axes = plt.subplots(1,2, sharey=True)\naxes[0].plot(trace['Œ∏'])\naxes[0].set_ylabel('Œ∏', rotation=0, labelpad=15)\naxes[1].hist(trace['Œ∏'], orientation=\"horizontal\", density=True)\naxes[1].set_xticks([]);\n\n\n\n\nAc√° pueden ver una versi√≥n interactiva de un Metropolis-Hastings\n\n\n5.2.4 MH adaptativo\nEn teor√≠a, y si tomaramos infinitas muestras, cualquier distribuci√≥n de propuesta ser√≠a √∫til. Sin embargo, en la pr√°ctica la eficiencia cambia dr√°sticamente de acuerdoa la distribuci√≥n de propuesta que utilicemos. Es por ello que para obtener un MH realmente eficiente es necesario ajustar hiperpar√°metros como la distribuci√≥n de propuesta para cada problema. Esto se puede hacer dedicando una cierta cantidad de pasos (tuning), estos pasos luego se descartan\n\nA√∫n el RWMH adaptativo puede tener problemas para ciertas problemas\n\nPar√°metros muy correlacionados\nAlta dimensi√≥n (muchos par√°metros)\nGeometr√≠as complejas\n\n\nExisten otras formas de generar a√∫n mejores propuestas\n\n\n5.2.5 Montecarlo Hamiltoniano (HMC)\nEn vez de proponer nuevos puntos al azar podemos usar una analog√≠a f√≠sica. Simulamos una particula sin fricci√≥n que se mueve por la distribuci√≥n a posteriori. Esto se puede hacer si conocemos el Hamiltoniano del sistema. En t√©rminos simples, un hamiltoniano es una descripci√≥n de la energ√≠a total de un sistema f√≠sico.\n\\[\n\\underbrace{H(\\overbrace{\\mathbf{q}}^{\\text{posici√≥n}}, \\overbrace{\\mathbf{p}}^{\\text{momemtum}})}_{\\text{Hamiltoniano}}  = \\underbrace{K(\\mathbf{p}, \\mathbf{q})}_{\\text{Energ√≠a cin√©tica}} + \\underbrace{V(\\mathbf{q})}_{\\text{Energ√≠a potencial}}\n\\]\nLa posici√≥n \\(q\\) se corresponde con los valores que puedan tomar los par√°metros del modelo probabilista y la energ√≠a potencial es la probabilidad a posteriori de esos valores. El momentum, en cambio, lo sacamos de la galera. Es simplemente una variable auxiliar que nos permite calcular el hamiltoniano y ‚Äúmover‚Äù el sistema.\nEntonces, a grandes rasgos un HMC tiene dos pasos que se repiten hasta obtener la cantidad de muestras necesarias:\n\nGenerar un nuevo punto a partir del hamiltoniano\nAceptar o rechazar ese nuevo punto de forma probabilista y comparando la probabilidad del punto preexistente y del nuevo punto.\n\nPor qu√© es buena idea usar el hamiltoniano? En un MH la propuesta es aleatoria, es como querer encontrar algo en una habitaci√≥n desconocida a oscuras, hay que ir a tientas. Mientras que con el Hamiltoniano es como tener una linterna, ahora podemos ver que hay en la habitaci√≥n, al menos localmente a donde apuntemos con la linterna. Veamos, una explicaci√≥n un poco m√°s matem√°tica. Resolver el hamiltoniano implica calcular derivadas, las derivadas nos dan informaci√≥n sobre la curvatura de una funci√≥n, por ejemplo el c√°lculo de la primer derivada en un punto nos dice hacia donde (de)crece una funci√≥n. Si siquieramos la derivada buscando, hacia donde crece la funci√≥n, eventualmente llegariamos a un m√°ximo (asumiendo que este existe). Esto se llama maximizar una funci√≥n. Al agregar el momemtum podemos hacer algo m√°s interesante, podemos simular un trayectoria que explore la distribuci√≥n a posteriori. Esto es importante en estad√≠stica Bayesiana, ya que no solo queremos el m√°ximo, si no una descripci√≥n de toda la distribuci√≥n a posteriori.\n\n\n\nUn HMC tiene varios hipepar√°metros, por ejemplo para simular una trayectoria tenemos que hacerlo de a pasos discretos, mientras m√°s peque√±os los pasos m√°s fidedigna la simulaci√≥n, pero tambi√©n m√°s costosa. Otro hiperpar√°metro es la longitud de cada simulaci√≥n si esta es muy corta demoraremos mucho tiempo en explorar la distribuci√≥n a posteriori, pero si est√° es muy larga corremos el riesgo de volver al mismo lugar.\nEn la siguiente figura se muestran tres ejemplos. A la izquierda el paso es muy corto, por lo que la exploraci√≥n no es eficiente, en el centro el paso es correcto pero la simulaci√≥n demasiado larga, tanto que volvemos al punto de partida, a la derecha tanto el paso como el tiempo de simulaci√≥n son adecuamos y la propuesta genera un punto alejado en el espacio de los par√°metros, pero con alta probabilidad de aceptaci√≥n. De hecho en este ejemplo la probabilidad de aceptaci√≥n es 1, ya que la pdf es la misma para el punto de partida que para el punto final.\n\n\n\nEste es otro ejemplo, en cada caso se muestra una densidad de probabilidad que va de m√°s probable (amarillo) a menos probable (violeta), las flechas naranjas indican la trayectoria calculada de a pasos. En en el primero caso vemos una trayectoria el√≠ptica tan larga que vuelve al punto de partida. En el segundo ejemplo vemos que el paso no es adecuado, esto produce una simulaci√≥n inestable que se manifiesta en divergencias de la trayectoria correcta. En este √∫ltimo caso, y como en el ejemplo anterior, vemos que tanto el paso como el tiempo de simulaci√≥n son adecuamos y la propuesta genera un punto alejado en el espacio de los par√°metros, pero con alta probabilidad de aceptaci√≥n (1 en este caso).\n\n\n\nCuando los hiper-par√°metros de un HMC son adecuados, el muestreo es muy eficiente, mucho m√°s eficiente que un MH. Los valores de los hiper-par√°metros dependen esencialmente de la geometr√≠a de la distribuci√≥n a posteriori, por lo que no existe un solo conjunto de hiper-par√°metros mejor que los dem√°s. Es por ello que en la pr√°ctica estos se calculan de forma adaptativa corriendo una cantidad de pasos de HMC los cuales se utilizan para ajustar eso hiper-par√°metros autom√°ticamente y luego se descartan. NUTS (No U-Turn sampler), el sampler por defecto en PyMC es un HMC din√°mico y adaptativo. El nombre proviene de una rutina del m√©todo que evita que las trayectorias den vueltas en U."
  },
  {
    "objectID": "04_Diagn√≥stico_MCMC.html#diagn√≥sticos-generales",
    "href": "04_Diagn√≥stico_MCMC.html#diagn√≥sticos-generales",
    "title": "5¬† Diagn√≥stico del muestreo",
    "section": "5.3 Diagn√≥sticos generales",
    "text": "5.3 Diagn√≥sticos generales\nAsint√≥ticamente los MCMC ofrencen la respuesta correcta, el problema es que asint√≥ticamente estamos todos muertos! En la pr√°ctica sea hace necesario contar con m√©todos de diagn√≥stico que permitan evaluar si el muestreo es correcto para muestras finitas. Si nos ponemos en pesimistas este es un problema sin soluci√≥n, ya que es imposible demostrar que una muestra es correcta, solo podemos probar que NO lo es. Entonces lo que buscamos es poder recolectar evidencia a favor de la ausencia de problemas. Esto nos va a conducir a establecer algunos valores umbrales, es decir si el diagnositico \\(D\\) da un valor superior a \\(m\\), tenemos un problema con nuestra muestra. Esto tambi√©n es problem√°tico, ya que establecer umbrales estrictos es en general arbitrario, salvo para casos triviales. Supongamos que yo me invento un diagn√≥stico para la calvice. El m√©todo es simple, hay que contar pelos. Es claro que 0 pelos corresponde a un pelado y 150.000 no, ya que esto se estima como la cantidad de pelos promedio en una cabeza promedio (sea lo que eso sea). Pero que pasa si alguien tiene 122 o 4126 pelos? A continuaci√≥n veremos algunos valores umbrales, es importante entonces tomarlos con pinzas.\n\n5.3.1 En la teor√≠a confiamos\nLa teor√≠a describe cierto comportamiento de los MCMC, muchos diagn√≥sticos est√°n basados en evaluar si los resultados te√≥ricos se verifican emp√≠ricamente. Por ejmplo, la teor√≠a de MCMC dice que:\n\nEl valor inicial es irrelevante, siempre debemos llegar al mismo resultado\nLas muestras no son realmente independientes, pero el valor de un punto solo depende del punto anterior, no hay correlaciones de largo alcance.\nSi miramos la muestra como una secuencia no deber√≠amos ser capaces de encontrar patr√≥n alguno\n\nPor ej, para una muestra lo suficientemente larga, la primera porci√≥n debe ser indistinguible de la √∫ltima (y la mismo cualquier otra combinaci√≥n de regiones).\n\nPara un mismo problema cada muestra generada va a ser diferente de las otras, pero a los fines pr√°cticos las muestras deber√≠an ser indistinguibles unas de otros\n\n\n\n5.3.2 Trace plots\nEste es un gr√°fico muy com√∫n. Para cada par√°metro graficamos su valor (eje-y) en cada iteraci√≥n (eje-x). Lo esperable es no ver ning√∫n patr√≥n, solo ruido como en primer panel de la siguiente figura (marco turquesa).\n\n\n\nEn cambio los otros tres paneles (marco magenta) muestran problemas. De izquierda a derecha y arriba a abajo:\n\nEl segundo panel muestra que el muestreo es ‚Äúpegajoso‚Äù, le toma muchos pasos a la cadena moverse de valores altos a valores bajos, es dif√≠cil predecir que suceder√≠a si sequimos corriendo, la cadena se mover√≠a hacia arriba nuevamente, se estabilizar√≠a en valos bajos, continuar√≠a bajando a√∫n m√°s?\nEl tercer panel muestra una cadena menos ‚Äúpegajosa‚Äù, pero tambi√©n dar√≠a la impresi√≥n que a√∫n no ha terminado de estabilizarse\nEl √∫ltimo panel, en cambio, muestra que hay una regi√≥n donde el sampler se mueve bien, pero cada tanto ‚Äúsalta‚Äù a estados donde se queda atascado. Quiz√° esto se deba a una distribuci√≥n a posteriori multimodal o dificultades en el sampler para explorar regiones con distinta curvatura.\n\nComo ya vimos por defecto PyMC corre m√°s de una cadena, por lo que un traceplot ideal deber√≠a verse como esto:\n\n\n\nArviZ permite graficar trace-plots usando la funci√≥n az.plot_trace(). Por defecto obtenemos el trace a la derecha y un KDE (para variables continuas) y un histograma (para discretas) a la izquierda\n\n\n\n\n\n5.3.3 Rank plots\nLos trace plots son muy comunes, pero existe una alternativa m√°s moderna llamada rank plots. La idea b√°sica es la siguiente. Para un par√°metro tomamos todas las cadenas y ordenamos los valores de menor a mayor y les asignamos un rango es decir al valor m√°s bajo le ponemos 1, al que sigue 0 y as√≠ hasta llegar a un n√∫mero que ser√° igual a la candidad de muestras totales (cantidad de cadenas multiplicado por la cantidad de muestras por cadena). Luego reagrupamos los rankings seg√∫n las cadenas que les dieron origen y para cada cadena hacemos un histograma. Si las cadenas fuesen indistinguibles esperariamos que los histogramas sean uniformes. Ya que no hay raz√≥n para que una cadena tenga m√°s rankings bajos (o medios o altos) que el resto.\nLa siguiente figura muestra 4 ejemplos, donde solo uno (marco cyan) no muestra problemas\n\n\n\nEn ArviZ los rank plots se pueden obtener con la funci√≥n az.plot_rank o pasando un argumento a plot_trace az.plot_trace(‚ãÖ, kind=\"rank_bars\")\n\n\n5.3.4 \\(\\hat R\\) (R sombrero)\nLos gr√°ficos suelen ser √∫tiles para descrubir patrones, pero aveces queremos n√∫meros, por ejmplo al evaluar r√°pidamente mucho par√°metros. \\(\\hat R\\) es la respuesta a la pregunta. Lograron las cadenas mezclarse adecuadamente? Pero tambi√©n me gusta pensalo como el jurado en un concurso de trace (o rank) plots. La versi√≥n implementada en ArviZ hace varias cosas debajo del capot, pero la idea central es que compara la varianza entre cadenas con la varianza dentro de cada cadena.\n\n\n\nIdealmente $R =$1, en la pr√°ctica \\(\\hat R \\lessapprox 1.01\\) son considerados seguros y en la primer fase de modelado valores m√°s altos como \\(\\hat R \\approx 1.1\\) pueden est√°r bien.\nUsando ArviZ podemos obtener \\(\\hat R\\) usando az.rhat(‚ãÖ), az.summary(‚ãÖ) y `az.plot_forest(‚ãÖ, r_hat=True)``\n\n\n5.3.5 Gr√°fico de autocorrelaci√≥n\nIdealmente, una muestra debe ser independiente e id√©nticamente distribuida (iid). Por definici√≥n, las muestras MCMC est√°n correlacionadas. En la pr√°ctica, queremos muestras con baja autocorrelaci√≥n. En ArviZ obtenemos este gr√°fico con la funci√≥n az.plot_autocorr()\n\ncadenas_defectuosas = {\"cadenas_defectuosas\": np.linspace(0, 1, 1000).reshape(2, -1)}\naz.plot_autocorr(cadenas_defectuosas);\n\n\n\n\n\ncadenas_defectuosas = {\"cadenas_defectuosas\": np.linspace(0, 1, 1000).reshape(2, -1)}\naz.plot_autocorr(cadenas_defectuosas);\n\n\n\n\n\ncadenas_adecuadas = {\"cadena_adecuadas\": pz.Uniform(0, 1).rvs(size=(2, 500))}\naz.plot_autocorr(cadenas_adecuadas);\n\n\n\n\n\n\n5.3.6 Tama√±o de muestra efectivo (ESS)\nComo las muestras de un MCMC est√°n correlacionadas la cantidad de informaci√≥n ‚Äú√∫til‚Äù es menor que una muestra del mismo tama√±o pero iid.\n \n\n\n\nPodemos estimar el tama√±o de muestra efectivo (ESS), es decir, el tama√±o de una muestra con la cantidad equivalente de informaci√≥n pero sin autocorrelaci√≥n. Esto es √∫til para determinar si la muestra que tenemos es lo suficientemente grande. Se recomienta que el ESS sea superior a 100 por cadena. Es decir para para 4 cadenas queremos un m√≠nimo de 400.\nCon ArviZ podemos obtenerlo az.ess(‚ãÖ), az.summary(‚ãÖ) y `az.plot_forest(‚ãÖ, ess=True)``\n\npd.concat((az.ess(cadenas_defectuosas).to_pandas(),\n           az.ess(cadenas_adecuadas).to_pandas()))\n\ncadenas_defectuosas      2.282878\ncadena_adecuadas       910.058723\ndtype: float64\n\n\nVemos que az.summary(‚ãÖ) devuelve dos valores de ESS, ess_bulk y ess_tail. Esto se debe a que, distintas regiones del espacio de los par√°metros pueden tener distinto valor de ESS, ya que no todas las regiones son muestreadas con la misma eficiencia. Intuitivamente uno puede pensar que al muestrear una distribuci√≥n como una Gaussiana es m√°s f√°cil obtener mejor calidad de muestra alrededor de la media que de las colas, simplemente por que tenemos m√°s muestras de esa regi√≥n.\n\npd.concat([az.summary(cadenas_adecuadas, kind=\"diagnostics\"),\n           az.summary(cadenas_defectuosas, kind=\"diagnostics\")])\n\n\n\n\n\n  \n    \n      \n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      cadena_adecuadas\n      0.010\n      0.007\n      910.0\n      988.0\n      1.00\n    \n    \n      cadenas_defectuosas\n      0.198\n      0.165\n      2.0\n      11.0\n      3.05\n    \n  \n\n\n\n\nSi las muestras de MCMC las vamos a usar para calcular valores centrales como medias o medianas entonces tenemos que asegurarnos que el ess_bulk sea lo suficientemente algo, en cambio, si queremos calcular intervalos como un HDI 95% hay que asegurarse que ess_tail sea adecuado.\nArviZ ofrece varias funciones vinculadas al ESS. Por ejemplo si queremos evaluar el desempe√±o del sampler para varias regiones al mismo tiempo podemos usar az.plot_ess.\n\n_, axes = plt.subplots(1, 2, figsize=(10,4), sharey=True)\naz.plot_ess(cadenas_adecuadas, ax=axes[0])\naz.plot_ess(cadenas_defectuosas, ax=axes[1]);\n\n\n\n\nUna forma simple de aumentar el ESS es aumentar la cantidad de muestras, pero podr√≠a darse el caso que el ESS crezca muy lento con el n√∫mero de muestras, por lo que a√∫n si aumentaramos 10 veces la cantidad de muestras estar√≠amos por debajo de lo requerido. Una forma de estimar ‚Äúcuanto nos falta‚Äù es usar az.plot_ess(‚ãÖ, kind=\"evolution\"). Este gr√°fico nos muestra como fue cambiando el ESS en muestra muestra, lo que nos permite hacer proyecciones. En el siguiente ejemplo vemos que para cadenas_adecuadas el ESS crece lineamente con el n√∫mero de muestras mientras que para cadenas_defectuosas no crece para nada. Este √∫ltimo caso no hay esperanzas de mejorar el ESS simplemente aumentando la cantidad de muestras.\n\n_, axes = plt.subplots(1, 2, figsize=(10,4), sharey=True)\naz.plot_ess(cadenas_adecuadas, kind=\"evolution\", ax=axes[0])\naz.plot_ess(cadenas_defectuosas,  kind=\"evolution\", ax=axes[1]);\n\n\n\n\n\n\n5.3.7 Error est√°ndard del Monte Carlo (MCSE)\nUna ventaja del ESS es que no tiene escala, da igual si un par√°metro var√≠a entre 0.1 y 0.2 y otro entre -2000 y 5000, un ESS de 400 tiene el mismo significado en ambos casos. En modelos con muchos par√°metros r√°pidamente podemos indentificar cuales par√°metros son m√°s problem√°ticos. Sin embargo, a la hora de reportar resultados no es muy informativo saber si el ESS fue de 1372 o 1501. En cambio nos gustar√≠a saber el orden del error que estamos cometiendo al aproximar la distribuci√≥n a posterori. Esa informaci√≥n la da el error est√°ndard del Monte Carlo (MCSE). Al igual que el ESS, el MCSE tiene en cuenta la autocorrelaci√≥n de las muestras. Este error debe estar por debajo de la precisi√≥n deseada en nuestros resultados. Es decir si para un par√°metro el MCSE es 0.1, no tiene sentido reportar que la media de ese par√°metro es 3.15. Ya que tranquilamente el valor correcto podr√≠a estar entre 3.4 y 2.8.\nUna de las cantidades devueltas por summary es mc_error."
  },
  {
    "objectID": "04_Diagn√≥stico_MCMC.html#diagn√≥stico-de-algoritmos-basados-en-gradiente",
    "href": "04_Diagn√≥stico_MCMC.html#diagn√≥stico-de-algoritmos-basados-en-gradiente",
    "title": "5¬† Diagn√≥stico del muestreo",
    "section": "5.4 Diagn√≥stico de algoritmos basados en gradiente",
    "text": "5.4 Diagn√≥stico de algoritmos basados en gradiente\nDebido a su funcionamiento interno, algoritmos como NUTS ofrecen algunas pruebas espec√≠ficas que no est√°n disponibles para otros m√©todos. Generalmente estas pruebas son muy sensibles\nPara ejemplificar esto vamos a cargar dos InferenceData de modelos pre-calculados. Los detalles de como se generaron estos idata no es relevante por el momento. Solo diremos que son dos modelos que son matem√°ticamente equivalente pero parametrizados de formas distintas. En este caso la parametrizaci√≥n afecta la eficiencia del sampler. El modelo centrado es muestreado de forma m√°s eficiente que el modelo no centrado.\n\nidata_cm = az.load_arviz_data(\"centered_eight\")\nidata_ncm = az.load_arviz_data(\"non_centered_eight\")\n\n\n5.4.1 Energ√≠a de transici√≥n vs energ√≠a marginal\nPodemos pensar en un Monte Carlo Hamiltoniano como un proceso de dos pasos * Un muestreo determinista (siguiendo el hamiltoniano) * Una caminata aleatorio en el espacio del momentum\nSi la distribuci√≥n de la energ√≠a de transici√≥n es similar a la distribuci√≥n de la energ√≠a marginal, entonces NUTS es capaz de generar muestras de la distribuci√≥n marginal de la energ√≠a que sean casi independientes entre transiciones. Esto lo podemos evaluar visualmente y num√©ricamente (Bayesian Fraction of Missing Information)\n\n_, axes = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(12, 4), constrained_layout=True)\n\nfor ax, idata, nombre in zip(axes.ravel(), (idata_cm, idata_ncm), (\"centrado\", \"no centrado\")):\n    az.plot_energy(idata, ax=ax)\n    ax.set_title(nombre)\n\n\n\n\n\n\n5.4.2 Divergencias\nUna ventaja de NUTS es que falla con el estilo. Esto sucede por ejemplo al intentar pasar de regiones de baja curvatura a regiones de alta curvatura. En estos casos las trayectorias num√©ricas pueden divergir. En esencia esto sucede por que en esos casos no existe un √∫nico conjunto de hiper-par√°metros que permita el muestreo eficiente de ambas regiones. Por lo que una de la regiones es muestreada adecuandamente y cuando el sampler se mueve hacia la otra regi√≥n falla. Las trayectorias num√©ricas divergentes son identificadores extremadamente sensibles de vecindarios patol√≥gicos.\nEl siguiente ejemplo muestra dos cosas el modelo no centrado muestra varias divergencias (c√≠rculos turquesas) agrupados en una regi√≥n. En el modelo centrado, que no tiene divergencias, se puede ver que alrededor de esa misma regi√≥n hay muestras para valores m√°s peque√±os de tau. Es decir el modelo no centrado falla en muestrear una regi√≥n, pero al menos avisa que est√° teniendo problemas en muestrear esa regi√≥n!\n\n_, axes = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(10, 5), constrained_layout=True)\n\n\nfor ax, idata, nombre in zip(axes.ravel(), (idata_cm, idata_ncm), (\"centrado\", \"no_centrado\")):\n    az.plot_pair(idata, var_names=['theta', 'tau'], coords={'school':\"Choate\"}, kind='scatter',\n                 divergences=True, divergences_kwargs={'color':'C1'},\n                 ax=ax)\n    ax.set_title(nombre)\n\n\n\n\n\naz.plot_parallel(idata_cm, figsize=(12, 4));"
  },
  {
    "objectID": "04_Diagn√≥stico_MCMC.html#qu√©-hacer-cuando-los-diagn√≥sticos-no-dan-bien",
    "href": "04_Diagn√≥stico_MCMC.html#qu√©-hacer-cuando-los-diagn√≥sticos-no-dan-bien",
    "title": "5¬† Diagn√≥stico del muestreo",
    "section": "5.5 Qu√© hacer cuando los diagn√≥sticos no dan bien?",
    "text": "5.5 Qu√© hacer cuando los diagn√≥sticos no dan bien?\n\n\n M√°s muestras o m√°s pasos de tuning (aunque es dificil llegar lejos con esto) \n Burn-in \n Cambiar el m√©todo de muestreo! \nReparametrizar el modelo\n Mejorar los priors \n\nEl teorema popular de la estad√≠stica computacional: Cuando tienes problemas computacionales, a menudo hay un problema con tu modelo.\n\nEn el caso de las divergencias, estan pueden eliminarse aumentando la tasa de aceptaci√≥n (pm.sample(..., target_accept=x) x>0.8)\nLeer los mensajes de advertencia y sugerencias de PyMC! ;-)"
  },
  {
    "objectID": "04_Diagn√≥stico_MCMC.html#para-seguir-leyendo",
    "href": "04_Diagn√≥stico_MCMC.html#para-seguir-leyendo",
    "title": "5¬† Diagn√≥stico del muestreo",
    "section": "5.6 Para seguir leyendo",
    "text": "5.6 Para seguir leyendo\nExploratory Analysis of Bayesian Models Trabajo en Progreso!\nA Conceptual Introduction to Hamiltonian Monte Carlo\nRank-normalization, folding, and localization\nComputing Bayes: Bayesian Computation from 1763 to the 21st Century."
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html",
    "href": "05_Regresi√≥n_lineal.html",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "",
    "text": "7 Regresi√≥n lineal\nSupongamos que tenemos una variable \\(X\\), y a partir de esta queremos predecir o modelar una variable \\(Y\\). Adem√°s, est√°s variables se encuentran apareadas ${(x_1,y_1), (x_2,y_2),(x_n,y_n)} $. En el caso m√°s simple \\(X\\) e \\(Y\\) son variables aleatorias continuas y unidimensionales, usando Python las representar√≠amos usando arrays de dimensi√≥n 1 de tipo flotante.\nLas variable \\(Y\\) suele recibir distintos nombres como variable dependiente, predicha o respuesta, mientras que \\(X\\) recibe nombres como variable independiente, predictora o de entrada. En Machine learning es com√∫n hablar de features en vez de variables y es com√∫n pensar que una regresi√≥n lineal es un ejemplo de aprendizaje supervisado.\nCuando tenemos m√°s de una variable independiente es com√∫n representarla como una matriz \\(\\boldsymbol{X}\\) (usualmente llamada matriz de dise√±o), donde por lo general las columnas representan distintos tipos de variables (o features) y las filas distintas observaciones, instancias , sujetos, etc. Este tipo de modelo se llama regresi√≥n lineal m√∫ltiple o regresi√≥n lineal multivariable y es quiz√° el caso m√°s com√∫n de regresi√≥n lineal. El nombre regresi√≥n lineal multivariada deber√≠a reservarse a casos en que tenemos m√°s de una variable respuesta, aunque es muy com√∫n en literatura que estos t√©rminos se usen de forma intercambiable.\nAlgunos ejemplos donde se pueden usar modelos de regresi√≥n lineal:\nHabiendo ya discutido algunas ideas generales sobre regresi√≥n lineal veamos c√≥mo es que este modelo se construye. Podemos describir una relaci√≥n lineal usando la siguiente expresi√≥n:\n\\[y_i = \\alpha + x_i \\beta  \\tag{3.1}\\]\nSeg√∫n esta expresi√≥n cada observaci√≥n \\(y_i\\) se obtiene a partir de multiplicar \\(x_i\\) por un coeficiente \\(\\beta\\) y luego se le suma el coeficiente \\(\\alpha\\).\nEl par√°metro \\(\\beta\\) controla la pendiente en la relaci√≥n lineal, podemos interpretarlo como el cambio en la variable \\(Y\\) por cambio de unidad en la variable \\(X\\). El par√°metro \\(\\alpha\\) se conoce como intercepto u ordenada al origen, y podemos interpretarlo como el valor de \\(y_i\\) cuando \\(x_i = 0\\). Gr√°ficamente, \\(\\alpha\\) indica el valor de \\(y_i\\) donde la l√≠nea intercepta el eje y.\nUn m√©todo muy popular para encontrar los par√°metros para un modelo lineal se conoce como ajuste por m√≠nimos cuadrados. Este m√©todo devuelve un valor para \\(\\alpha\\) y uno para \\(\\beta\\) de tal forma que esos valores sean los que minimizan el error cuadr√°tico medio entre los \\(y\\) observados y predichos. Es decir obtenemos una sola linea recta, la ‚Äúmejor‚Äù seg√∫n este criterio (hay otros).\nNosotros vamos a seguir una ruta diferente, para ello vamos a reformular la expresi√≥n 3.1 en t√©rminos probabil√≠stas:\n\\[Y \\sim \\mathcal{N}(\\mu=\\alpha + X \\beta, \\epsilon) \\tag{3.2}\\]\nEs decir \\(Y\\) es una variable aleatoria distribuida seg√∫n una Gaussiana con media \\(\\alpha + X \\beta\\) desviaci√≥n est√°ndar \\(\\epsilon\\). Desde esta perspectiva una regresi√≥n lineal es una extensi√≥n de un modelo Gaussiano donde en vez de estimar la media de forma directa la calculamos como una una funci√≥n lineal de las variables predictoras.\nComo desconocemos los valores de los par√°metros \\(\\alpha\\), \\(\\beta\\) y \\(\\epsilon\\) debemos asignarles distribuciones a priori. Si us√°ramos a prioris planos entonces el valor m√°ximo a posteriori (la moda del posterior) ser√≠a el mismo que el encontrado usando m√≠nimos cuadrados y el mismo que usando maximum likelihood. En general es posible hacer algo mejor que esto. Una elecci√≥n razonable y gen√©rica para los a prioris ser√≠a:\n\\[\n\\alpha \\sim \\mathcal{N}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n\\beta \\sim \\mathcal{N}(\\mu_\\beta, \\sigma_\\beta) \\\\\n\\epsilon \\sim \\mathcal{HN}(\\sigma_\\epsilon) \\tag{3.3}\n\\]\nSi no tenemos una idea muy clara sobre qu√© valores deber√≠an tener los a prioris podemos fijar los valores de \\(\\sigma_{\\alpha}\\), \\(\\sigma_{\\beta}\\) o \\(\\sigma_{\\epsilon}\\) de forma tal que sean grandes dada la escala de los datos. En general es m√°s f√°cil tener una idea de los valores que \\(\\beta\\) puede tomar por sobre los de \\(\\alpha\\), por ejemplo solemos saber si la pendiente es positiva o negativa. Usar datos estandarizados suele ser √∫til para elegir a prioris ligeramente informativos que funciona para un amplio rango de problemas.\nPara par√°metros como \\(\\epsilon\\), que est√°n restringidos a los positivos, es com√∫n el uso de a prioris como la media Gaussiana (como en 3.3), algunas alternativas son la distribuci√≥n uniforme y la media-Cauchy, mientras que la media-gaussiana y la media-Cauchy funcionan bien como a prioris generales, la distribuci√≥n uniforme no suele ser buena idea, en general no es buena idea usar distribuciones restringidas a un rango salvo que sepamos que los par√°metros realmente est√°n restringidos a ese rango. La distribuci√≥n gamma se puede usar para definir a prioris m√°s informativos para \\(\\epsilon\\), especialmente si la definimos usando la media y desviaci√≥n est√°ndar, PyMC permite definir una distribuci√≥n Gamma usando dos parametrizaciones alternativas.\nUsando diagramas de Krusche podemos representar una regresi√≥n lineal de la siguiente forma:\n\\(\\mu\\) est√° definida usando el s√≠mbolo \\(=\\), en vez de \\(\\sim\\), esto se debe a que una vez conocidos \\(\\alpha\\) y \\(\\beta\\) el valor de \\(\\mu\\) queda completamente determinado. Llamamos a este tipo de variables deterministas.\nAhora necesitamos los datos para alimentar el modelo. Una vez m√°s, vamos a confiar en un conjunto de datos sint√©ticos. Una ventaja de un conjunto de datos sint√©tico es que conocemos los valores correctos de los par√°metros y, por lo tanto, podemos verificar si podemos recuperarlos con nuestros modelos.\nEscribir este modelo en PyMC es bastante directo, la √∫nica diferencia con los modelos anteriores es que ahora hemos especificado a la variable \\(\\mu\\) como una variable determinista. Una variable determinista tendr√° una distribuci√≥n a posteriori ya que es funci√≥n de al menos una variable estoc√°stica. Si en PyMC especificamos un variable como determinista esta ser√° incluida en el idata. Alternativamente podr√≠amos haber escrito:\nEsto es igualmente v√°lido, la √∫nica diferencia es que en este caso la variable \\(\\mu\\) no estar√≠a incluida en el trace\n\\[\ny_i \\sim Normal(\\mu, \\sigma) \\\\\n\\mu \\sim Normal(0, 10) \\\\\n\\sigma \\sim HalfNormal(25)\n\\]\n\\[\ny \\sim Normal(\\mu, \\epsilon) \\\\\n\\mu = \\alpha + \\beta x \\\\\n\\alpha \\sim Normal(0, 10) \\\\\n\\beta \\sim Normal(0, 1) \\\\\n\\epsilon \\sim HalfNormal(25) \\\\\n\\]\nCompare los resultados usando funciones de ArviZ como plot_trace y plot_pairs. Centre la variable \\(x\\) y repita el ejercicio ¬øQu√© opina?"
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html#modelos-lineales-y-autocorrelaci√≥n",
    "href": "05_Regresi√≥n_lineal.html#modelos-lineales-y-autocorrelaci√≥n",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "7.1 Modelos lineales y autocorrelaci√≥n",
    "text": "7.1 Modelos lineales y autocorrelaci√≥n\nEn un modelo lineal los par√°metros \\(\\alpha\\) y \\(\\beta\\) est√°n correlacionados. Esto se puede ver en la siguiente figura:\n\naz.plot_pair(idata_g, var_names='~Œº', scatter_kwargs={'alpha':0.5});\n\n\n\n\nEsta correlaci√≥n es una consecuencia directa de nuestras suposiciones. En general al hacer una regresi√≥n lineal Bayesiana las lineas que ajustan los datos pasan aproximadamente por la media de \\(X\\) y la media de \\(Y\\), adem√°s el aumento en la pendiente significa la disminuci√≥n de la ordenada al origen y viceversa. Esto provoca que el posterior para \\(\\alpha\\) y \\(\\beta\\) sea un espacio muy diagonal. Esto puede ser problem√°tico para m√©todos como Metropolis-Hastings y, en menor medida para NUTS.\nUn m√©todo simple para eliminar la correlaci√≥n entre \\(\\alpha\\) y \\(\\beta\\) consiste en centrar la variable \\(X\\), para esto calculamos su media y se la restamos a cada valor, obteniendo as√≠ \\(x'\\). Como resultado la media de \\(x'\\) ser√° 0, si usamos \\(x'\\) como variable dependiente \\(\\alpha\\) deber√° estar alrededor de 0 y adem√°s las lineas que sean soluci√≥n al problema pivotear√°n alrededor de 0 por lo que los cambios de \\(\\beta\\) tendr√°n poco efecto en los valores de \\(\\alpha\\) esto provoca que el posterior para \\(\\alpha\\) y \\(\\beta\\) sea m√°s circular y menos correlacionado. Esto lo pueden comprobar ustedes mismos si vuelven a correr el modelo anterior, pero esta vez centrando los datos.\nCentrar datos no es solo un truco computacional, tambi√©n puede ser un truco estad√≠stico que ayuda a interpretar los resultados. \\(\\alpha\\) es el valor de $y_i $ cuando \\(x_i = 0\\). Para muchos problemas, esta interpretaci√≥n no tiene ning√∫n sentido. Por ejemplo, para cantidades tales como la altura o el peso, los valores de cero no tienen sentido. En cambio, al centrar las variables, \\(\\alpha\\) se convierte en el valor de \\(y_i\\) para el valor medio de \\(x\\). Para algunos problemas, puede ser √∫til estimar \\(\\alpha\\) precisamente porque no es factible medir experimentalmente el valor de \\(x_i = 0\\) y, por lo tanto, \\(\\alpha\\) puede proporcionarnos informaci√≥n valiosa, pero las extrapolaciones tienen sus advertencias, as√≠ que ¬°tene cuidado cuando haces esto!\nEs posible que deseemos informar los par√°metros estimados en t√©rminos de los datos centrados o en t√©rminos de datos descentrados, la decisi√≥n depender√° del problema y de la audiencia. Si necesitamos informar los par√°metros como si hubiesen sido determinados en la escala original, podemos hacer lo siguiente para devolverlos a esa escala:\n\\[\\alpha = \\alpha' - \\beta' \\bar x \\tag{3.5}\\]\nEsta correcci√≥n es el resultado del siguiente razonamiento algebraico:\n\\[\ny =\\alpha' + \\beta'x' + \\epsilon \\\\\ny =\\alpha' + \\beta'(x - \\bar x) + \\epsilon \\\\\ny =\\alpha' - \\beta' \\bar x + \\beta'  x + \\epsilon \\\\ \\tag{3.6}\n\\]\nLuego se deduce que la ecuaci√≥n 3.5 es verdadera y tambi√©n:\n\\[\\beta = \\beta' \\tag{3.7}\\]\nOtra transformaci√≥n que puede ser √∫til es estandarizar los datos. Esta transformaci√≥n es una pr√°ctica com√∫n para los modelos de regresi√≥n lineal tanto en estad√≠stica y machine learning, ya que muchos algoritmos se comportan mejor cuando los datos est√°n estandarizados. Esta transformaci√≥n se logra al centrar los datos y dividirlos por la desviaci√≥n est√°ndar. Matem√°ticamente tenemos:\n\\[\nx' = \\frac{x - \\bar x}{x_{sd}} \\\\\ny' = \\frac{y - \\bar y}{y_{sd}} \\tag{3.8}\n\\]\nUna ventaja de la estandarizaci√≥n de los datos es que siempre podemos usar los mismos priors d√©bilmente informativos, sin tener que pensar en la escala de los datos. Para datos estandarizados, la intersecci√≥n siempre ser√° alrededor de 0 y la pendiente estar√° restringida al intervalo [-1, 1]. Estandarizar los datos nos permite hablar en t√©rminos de Z-score, es decir, en unidades de desviaciones est√°ndar. Si alguien dice que el valor de un par√°metro es -1.3 unidades de Z-score, sabemos autom√°ticamente que el valor en cuesti√≥n es 1.3 desviaciones est√°ndar por debajo del valor de la media (a√∫n cuando no sepamos cual es el valor de la media). Un cambio en una unidad Z-score es un cambio en una desviaci√≥n est√°ndar cualquiera sea la escala original de los datos. Los Z-zcore tambi√©n son muy √∫tiles cuando se trabaja con muchas variables; ya que tener todas las variables en una misma escala puede simplificar la interpretaci√≥n de los datos."
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html#interpretando-y-visualizando-el-posterior",
    "href": "05_Regresi√≥n_lineal.html#interpretando-y-visualizando-el-posterior",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "7.2 Interpretando y visualizando el posterior",
    "text": "7.2 Interpretando y visualizando el posterior\nComo ya hemos visto, podemos explorar el posterior usando funciones de ArviZ como plot_trace y summary, o podemos usar nuestras propias funciones. Para una regresi√≥n lineal, podr√≠a ser √∫til dibujar la l√≠nea promedio que ajusta los datos junto con los valores promedio de \\(\\alpha\\) y \\(\\beta\\). Para reflejar la incertidumbre contenida en la distribuci√≥n a posteriori, podemos usar l√≠neas semitransparentes muestreadas de esta distribuci√≥n:\n\nplt.plot(x, y, 'C0.')\n\n\nŒ±_m = idata_g.posterior['Œ±'].mean((\"chain\", \"draw\")).item()\nŒ≤_m = idata_g.posterior['Œ≤'].mean((\"chain\", \"draw\")).item()\n\nfew_samples = az.extract(idata_g, num_samples=50)\nplt.plot(x, few_samples['Œ±'].values + few_samples['Œ≤'].values *  x[:,np.newaxis], c='C1', alpha=0.25);\n\nplt.plot(x, Œ±_m + Œ≤_m * x, c='k',\n         label=f'y = {Œ±_m:.2f} + {Œ≤_m:.2f} * x')\n\nplt.xlabel('x')\nplt.ylabel('y', rotation=0, labelpad=10)\nplt.legend();\n\n\n\n\nEn la figura anterior se puede ver que la incertidumbre es menor en el medio, aunque no se reduce a un solo punto, es decir, la distribuci√≥n a posteriori es compatible con las l√≠neas que no pasan exactamente por la media de los datos, como ya hemos mencionado.\nUna alternativa a muestrear lineas de la distribuci√≥n a posteriori es dibujar una banda semitransparente que represente un intervalo HDI de \\(\\mu\\). Al haber definido la variable \\(\\mu\\) como determinista en el modelo, podemos hacer esto de forma sencilla:\n\nplt.plot(x, y, 'C0.')\n\nplt.plot(x, Œ±_m + Œ≤_m * x, c='k',\n         label='y = {:.2f} + {:.2f} * x'.format(Œ±_m, Œ≤_m))\n\naz.plot_hdi(x, idata_g.posterior['Œº'], color='C1')\n\nplt.xlabel('x')\nplt.ylabel('y', rotation=0, labelpad=10);\n\n\n\n\nUna tercera opci√≥n es representar el HDI de la distribuci√≥n predictiva a posteriori, es decir la distribuci√≥n de datos predichos. En la siguiente figura sea usa un gris m√°s oscuro para el HDI 50% y un gris m√°s claro para el HDI 94%. Para poder hacer el siguiente gr√°fico necesitamos, primero, obtener las muestras predictivas posteriores. Lo cual es f√°cil usando PyMC con la funci√≥n sample_ppc:\n\nidata_g.extend(pm.sample_posterior_predictive(idata_g, model=model_g))\n\nSampling: [y_pred]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00<00:00]\n    \n    \n\n\nY ahora si la figura\n\nplt.plot(x, y, 'b.')\nplt.plot(x, Œ±_m + Œ≤_m * x, c='k', label='y = {:.2f} + {:.2f} * x'.format(Œ±_m, Œ≤_m))\n\naz.plot_hdi(x, idata_g.posterior_predictive['y_pred'], color='C1')\naz.plot_hdi(x, idata_g.posterior_predictive['y_pred'], hdi_prob=0.5, color='C1')\n\nplt.xlabel('x')\nplt.ylabel('y', rotation=0);"
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html#regresi√≥n-lineal-robusta",
    "href": "05_Regresi√≥n_lineal.html#regresi√≥n-lineal-robusta",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "7.3 Regresi√≥n lineal robusta",
    "text": "7.3 Regresi√≥n lineal robusta\nAsumir que los datos siguen una distribuci√≥n gaussiana es perfectamente razonable en muchas situaciones. Al asumir Gaussianidad, no necesariamente estamos aceptando que los datos son gaussianos; en cambio, estamos diciendo que es una aproximaci√≥n razonable para un problema determinado. Como vimos en el cap√≠tulo anterior, a veces esta suposici√≥n gaussiana falla, por ejemplo, en presencia de valores aberrantes. Aprendimos que el uso de la distribuci√≥n t de Student es una forma de tratar de manera efectiva con valores at√≠picos y obtener una inferencia m√°s robusta. La misma idea se puede aplicar a la regresi√≥n lineal y para ejemplificarla vamos a utilizar un conjunto de datos muy simple: el tercer grupo de datos del cuarteto de Anscombe\n\nans = pd.read_csv('datos/anscombe.csv')\nx_3 = ans[ans.group == 'III']['x'].values\ny_3 = ans[ans.group == 'III']['y'].values\nx_3 = x_3 - x_3.mean()\n\nY ahora veamos c√≥mo luce este peque√±o conjunto de datos:\n\n_, ax = plt.subplots(1,2, figsize=(10,5), sharey=True)\n\nax[0].plot(x_3, y_3, 'C0o')\nax[0].set_xlabel('x')\nax[0].set_ylabel('y', rotation=0, labelpad=15)\nax[1].set_xticks([])\naz.plot_kde(y_3, ax=ax[1], rug=True, rotated=True);\n\n\n\n\nAhora vamos a reescribir el modelo_g esta vez usando una distribuci√≥n t de Student en lugar de una Gaussiana. Este cambio tambi√©n introduce la necesidad de especificar el valor de \\(\\nu\\), el par√°metro de normalidad. Si no recuerdas la funci√≥n de este par√°metro, consult√° el cap√≠tulo anterior antes de continuar.\nEn el siguiente modelo estamos usando una distribuci√≥n exponencial desplazada, para evitar valores de \\(\\nu\\) cercanos a cero. La exponencial no desplazada pone demasiado peso en valores cercanos a cero y esto puede traer algunos problemas. En el casos del tercer conjunto de datos de Anscombe lo problem√°tico deriva de que es posible ajustar una recta de forma perfecta (si obviamos el dato aberrante). Como regla general los priors usados en este curso suelen ser buenos valores por defecto, pero nada m√°s que eso. Otra distribuci√≥n a priori comunmente usada para \\(\\nu\\) es gamma(2, 0.1) o gamma(mu=20, sd=15).\n\nwith pm.Model() as model_t:\n    Œ± = pm.Normal('Œ±', y_3.mean(), 1)\n    Œ≤ = pm.Normal('Œ≤', 0, 1)\n    œµ = pm.HalfNormal('œµ', 5)\n    ŒΩ_ = pm.Exponential('ŒΩ_', 1/29)\n    ŒΩ = pm.Deterministic('ŒΩ', ŒΩ_ + 1)\n    \n    y_pred = pm.StudentT('y_pred', mu=Œ± + Œ≤ * x_3,\n                         sigma=œµ, nu=ŒΩ, observed=y_3)\n    \n    idata_t = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤, œµ, ŒΩ_]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:05<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 6 seconds.\n\n\n\nvar_names = ['~ŒΩ_']\naz.plot_trace(idata_t, var_names=var_names, kind=\"rank_vlines\", combined=True);\n\n\n\n\nEn la siguiente gr√°fica podemos ver el ajuste robusto, seg√∫n model_t, y el ajuste no robusto de acuerdo con la funci√≥n linregress de SciPy (esta funci√≥n realiza una regresi√≥n por m√≠nimos cuadrados). Como ejercicio, puede intentar agregar a esta gr√°fica la mejor l√≠nea obtenida usando model_g.\n\nbeta_c, alpha_c = stats.linregress(x_3, y_3)[:2]\n\nplt.plot(x_3, (alpha_c + beta_c * x_3), label='no-robusto')\nplt.plot(x_3, y_3, 'ko')\nalpha_m = idata_t.posterior['Œ±'].mean().item()\nbeta_m = idata_t.posterior['Œ≤'].mean().item()\nplt.plot(x_3, alpha_m + beta_m * x_3, label='robusto')\n\nplt.xlabel('x')\nplt.ylabel('y', rotation=0, labelpad=15)\nplt.legend(loc=2);\n\n\n\n\nLa figura anterior se puede explicar porque una distribuci√≥n de t, con sus colas m√°s pesadas, es capaz de dar menos importancia a los puntos que est√°n alejados del grupo principal de datos. En cambio el ajuste no robusto se esfuerza por incluir a todos los puntos. SI bien este es un conjunto muy particular de datos el mensaje es v√°lido para datos m√°s complejos y reales\nAntes de continuar t√≥mese un momento para contemplar los valores de los par√°metros (estoy omitiendo los par√°metros intermedios ya que no es de inter√©s directo).\nAntes de continuar t√≥memonos un momento para contemplar los valores de los par√°metros seg√∫n la distribuci√≥n a posteriori.\n\naz.summary(idata_t, var_names)\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      Œ±\n      7.114\n      0.001\n      7.112\n      7.117\n      0.000\n      0.000\n      5019.0\n      4365.0\n      1.0\n    \n    \n      Œ≤\n      0.345\n      0.000\n      0.345\n      0.346\n      0.000\n      0.000\n      4709.0\n      3331.0\n      1.0\n    \n    \n      œµ\n      0.003\n      0.002\n      0.001\n      0.006\n      0.000\n      0.000\n      1527.0\n      581.0\n      1.0\n    \n    \n      ŒΩ\n      1.205\n      0.199\n      1.000\n      1.581\n      0.003\n      0.002\n      1752.0\n      614.0\n      1.0\n    \n  \n\n\n\n\nComo pueden ver, los valores de \\(\\alpha\\), \\(\\beta\\) y \\(\\epsilon\\) practicamente no tienen variaci√≥n (sd=0), incluso \\(\\epsilon\\) es pr√°cticamente 0. Esto es totalmente razonable dado que estamos ajustando una l√≠nea recta a un perfecto conjunto alineado de puntos (si ignoramos el punto at√≠pico)."
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html#regresi√≥n-lineal-jer√°rquica",
    "href": "05_Regresi√≥n_lineal.html#regresi√≥n-lineal-jer√°rquica",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "7.4 Regresi√≥n lineal jer√°rquica",
    "text": "7.4 Regresi√≥n lineal jer√°rquica\nEn el cap√≠tulo anterior, aprendimos los rudimentos de los modelos jer√°rquicos. Este mismo concepto se puede aplicar a las regresiones lineales. Esto permite que los modelos realicen inferencias a nivel de subgrupo y a nivel global. Como ya vimos, esto se hace incluyendo hiperpriors.\nVamos a crear ocho grupos de datos relacionados, incluido uno con un solo dato\n\nN = 20\nM = 8\nidx = np.repeat(range(M-1), N)\nidx = np.append(idx, 7)\nnp.random.seed(314)\n\nalfa_real = np.random.normal(2.5, 0.5, size=M)\nbeta_real = np.random.beta(6, 1, size=M)\neps_real = np.random.normal(0, 0.5, size=len(idx))\n\ny_m = np.zeros(len(idx))\nx_m = np.random.normal(10, 1, len(idx))\ny_m = alfa_real[idx] + beta_real[idx] * x_m  + eps_real\n\n_, ax = plt.subplots(2, 4, figsize=(10,5), sharex=True, sharey=True)\nax = np.ravel(ax)\nj, k = 0, N\nfor i in range(M):\n    ax[i].scatter(x_m[j:k], y_m[j:k])\n    ax[i].set_xlabel('$x_{}$'.format(i))\n    ax[i].set_ylabel('$y_{}$'.format(i), rotation=0, labelpad=15)\n    ax[i].set_xlim(6, 15)\n    ax[i].set_ylim(7, 17)\n    j += N\n    k += N\n\n\n\n\nVamos a centrar los datos antes de pas√°rselos al modelo.\n\nx_centered = x_m - x_m.mean()\n\n\nwith pm.Model() as hierarchical_model:\n    # hyper-priors\n    Œ±_Œº_tmp = pm.Normal('Œ±_Œº_tmp', mu=0, sigma=10)\n    Œ±_œÉ_tmp = pm.HalfNormal('Œ±_œÉ_tmp', 10)\n    Œ≤_Œº = pm.Normal('Œ≤_Œº', mu=0, sigma=10)\n    Œ≤_œÉ = pm.HalfNormal('Œ≤_œÉ', sigma=10)\n\n    # priors\n    Œ±_tmp = pm.Normal('Œ±_tmp', mu=Œ±_Œº_tmp, sigma=Œ±_œÉ_tmp, shape=M)\n    Œ≤ = pm.Normal('Œ≤', mu=Œ≤_Œº, sigma=Œ≤_œÉ, shape=M)\n    œµ = pm.HalfCauchy('œµ', 5)\n    ŒΩ = pm.Exponential('ŒΩ', 1/30)\n\n    y_pred = pm.StudentT('y_pred', mu=Œ±_tmp[idx] + Œ≤[idx] * x_centered, sigma=œµ, nu=ŒΩ, observed=y_m)\n\n    Œ± = pm.Deterministic('Œ±', Œ±_tmp - Œ≤ * x_m.mean()) \n\n    idata_hm = pm.sample(1000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±_Œº_tmp, Œ±_œÉ_tmp, Œ≤_Œº, Œ≤_œÉ, Œ±_tmp, Œ≤, œµ, ŒΩ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:08<00:00 Sampling 4 chains, 127 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.\n\n\n\naz.plot_forest(idata_hm, var_names=['Œ±', 'Œ≤'], figsize=(10, 4), combined=True, r_hat=False, ess=False);\n\n\n\n\nDibujemos las l√≠neas ajustadas, para cada uno de los ocho grupos.\n\n_, ax = plt.subplots(2, 4, figsize=(12, 4), sharex=True, sharey=True)\nax = np.ravel(ax)\nj, k = 0, N\nx_range = np.linspace(x_m.min(), x_m.max(), 10)\nposterior = az.extract(idata_hm)\n\nfor i in range(M):\n    ax[i].scatter(x_m[j:k], y_m[j:k])\n    ax[i].set_xlabel('$x_{}$'.format(i))\n    ax[i].set_ylabel('$y_{}$'.format(i), labelpad=10, rotation=0)\n    alfas = posterior['Œ±'].sel(Œ±_dim_0=i)\n    betas = posterior['Œ≤'].sel(Œ≤_dim_0=i)\n    alfa_m = alfas.mean(\"sample\").item()\n    beta_m = betas.mean(\"sample\").item()\n    ax[i].plot(x_range, alfa_m + beta_m * x_range, c='k')\n    az.plot_hdi(x_range, alfas + betas * xr.DataArray(x_range).transpose(), ax=ax[i])\n    plt.xlim(x_m.min()-1, x_m.max()+1)\n    plt.ylim(y_m.min()-1, y_m.max()+1)\n    j += N\n    k += N"
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html#regresi√≥n-lineal-multiple",
    "href": "05_Regresi√≥n_lineal.html#regresi√≥n-lineal-multiple",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "7.5 Regresi√≥n lineal Multiple",
    "text": "7.5 Regresi√≥n lineal Multiple\nHasta ahora hemos estado trabajando con una variable dependiente y una variable independiente, sin embargo no es inusual tener varias variables independientes que queremos incluir en nuestro modelo. Algunos ejemplos podr√≠an ser:\n\nCalidad percibida del vino (dependiente) y acidez, densidad, nivel de alcohol, az√∫car residual y contenido de sulfatos (variables independientes)\nCalificaciones promedio de los estudiantes (dependientes) e ingresos familiares, distancia de la casa a la escuela y educaci√≥n de la madre (variable categ√≥rica)\n\nPodemos extender f√°cilmente el modelo de regresi√≥n lineal simple para tratar con m√°s de una variable independiente. Llamamos a este modelo regresi√≥n lineal m√∫ltiple, que no debe confundirse con la regresi√≥n lineal multivariada, que corresponde con el caso de m√∫ltiples variables dependientes.\nEn una regresi√≥n lineal m√∫ltiple modelamos la media de la variable dependiente como:\n\\[\\mu = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 \\dots + \\beta_m x_m \\tag{3.15}\\]\nLa expresi√≥n 3.15 se parece a una regresi√≥n polinomial (ecuaci√≥n 3.12), pero no es exactamente lo mismo. Para la regresi√≥n lineal m√∫ltiple tenemos diferentes variables independientes en lugar de potencias sucesivas de la misma variable independiente. Desde el punto de vista de la regresi√≥n lineal m√∫ltiple, podemos decir que una regresi√≥n polinomial es como una regresi√≥n lineal m√∫ltiple pero con variables inventadas.\nUsando la notaci√≥n de √°lgebra lineal, podemos escribir una versi√≥n m√°s corta:\n\\[\\mu = \\alpha + X \\beta \\tag{3.16}\\]\nDonde \\(\\beta\\) es un vector de coeficientes de longitud \\(m\\), es decir, el n√∫mero de variables dependientes. La variable \\(X\\) es una matriz de tama√±o \\(m \\times n\\) si \\(n\\) es el n√∫mero de observaciones y \\(m\\) es el n√∫mero de variables independientes. Si est√°s un poco oxidado con el √°lgebra lineal, puedes consultar el art√≠culo de Wikipedia sobre el producto escalar entre dos vectores y su generalizaci√≥n a la multiplicaci√≥n de matrices. B√°sicamente lo que necesitamos saber por el momento es que estamos usando una forma m√°s corta y conveniente de escribir nuestro modelo:\n\\[X \\beta = \\sum_{i=1}^n \\beta_ix_i = \\beta_1 x_1 + \\beta_2 x_2 \\dots + \\beta_m x_m \\tag{3.17} \\]\nUsando el modelo de regresi√≥n lineal simple, encontramos una l√≠nea recta que (con suerte) explica nuestros datos. Bajo el modelo de regresi√≥n lineal m√∫ltiple, encontramos, en cambio, un hiperplano de dimensi√≥n \\(m\\). Por lo tanto, el modelo de regresi√≥n lineal m√∫ltiple es esencialmente el mismo modelo de regresi√≥n lineal simple, la √∫nica diferencia es que ahora $$ es un vector y \\(X\\) es una matriz.\nVamos a definir nuestros datos:\n\nnp.random.seed(314)\nN = 100\nalpha_real = 2.5\nbeta_real = [0.9, 1.5]\neps_real = np.random.normal(0, 0.5, size=N)\n\nX = np.array([np.random.normal(i, j, N) for i,j in zip([10, 2], [1, 1.5])]).T\nX_mean = X.mean(axis=0, keepdims=True)\nX_centered = X - X_mean\ny = alpha_real + np.dot(X, beta_real) + eps_real\n\nA continuaci√≥n vamos a definir una funci√≥n que realiza tres gr√°ficos de dispersi√≥n, dos entre cada variable independiente y la variable dependiente y el √∫ltimo entre ambas variables dependientes. Usaremos esta funci√≥n para ayudarnos durante el resto del cap√≠tulo:\n\ndef scatter_plot(x, y):\n    plt.figure(figsize=(10, 10))\n    for idx, x_i in enumerate(x.T):\n        plt.subplot(2, 2, idx+1)\n        plt.scatter(x_i, y)\n        plt.xlabel('x_{}'.format(idx+1))\n        plt.ylabel('y', rotation=0)\n\n    plt.subplot(2, 2, idx+2)\n    plt.scatter(x[:,0], x[:,1])\n    plt.xlabel('x_{}'.format(idx))\n    plt.ylabel('x_{}'.format(idx+1), rotation=0)\n\nscatter_plot(X_centered, y);\n\n\n\n\nAhora s√≠ vamos a definir, en PyMC3, un modelo adecuado para la regresi√≥n lineal m√∫ltiple. Como es de esperar el c√≥digo luce muy similar al modelo de regresi√≥n lineal simple. Las principales diferencias son:\n\nLa variable \\(\\beta\\) es Gaussiana con shape = 2, es decir una pendiente por cada variable independiente.\nLa variable \\(\\mu\\) la definimos usando la funci√≥n pm.math.dot()\n\nSi est√°s familiarizado con NumPy, probablemente sepas que NumPy tambi√©n incluye una funci√≥n para multiplicar matrices np.dot y desde Python 3.5 (y desde NumPy 1.10) existe un nuevo operador para multiplicar matrices @. Sin embargo, aqu√≠ usamos la funci√≥n de PyMC3, que no es m√°s que un alias para el operador de multiplicaci√≥n de matrices de Theano. Necesitamos hacer esto porque la variable \\(\\beta\\) es un tensor de Theano y no un array de NumPy.\n\nwith pm.Model() as model_mlr:\n    Œ±_tmp = pm.Normal('Œ±_tmp', mu=0, sigma=10)\n    Œ≤ = pm.Normal('Œ≤', mu=0, sigma=1, shape=2)\n    œµ = pm.HalfCauchy('œµ', 5)\n\n    Œº = Œ±_tmp + pm.math.dot(X_centered, Œ≤)\n\n    Œ± = pm.Deterministic('Œ±', Œ±_tmp - pm.math.dot(X_mean, Œ≤)) \n\n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y)\n\n    trace_mlr = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±_tmp, Œ≤, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:02<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 3 seconds.\n\n\n\nvar_names = ['Œ±', 'Œ≤','œµ']\naz.plot_trace(trace_mlr, var_names);\n\n\n\n\n\naz.summary(trace_mlr, var_names)\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      Œ±[0]\n      1.850\n      0.452\n      1.013\n      2.704\n      0.004\n      0.003\n      10727.0\n      6419.0\n      1.0\n    \n    \n      Œ≤[0]\n      0.969\n      0.044\n      0.884\n      1.047\n      0.000\n      0.000\n      11149.0\n      6629.0\n      1.0\n    \n    \n      Œ≤[1]\n      1.470\n      0.032\n      1.414\n      1.533\n      0.000\n      0.000\n      12941.0\n      6680.0\n      1.0\n    \n    \n      œµ\n      0.474\n      0.034\n      0.412\n      0.537\n      0.000\n      0.000\n      10672.0\n      6604.0\n      1.0\n    \n  \n\n\n\n\nComo podemos ver, nuestro modelo es capaz de recuperar los valores correctos (verificalo comparando contra los valores utilizados para generar los datos sint√©ticos).\nEn las siguientes secciones, nos centraremos en algunas precauciones que debemos tomar al analizar los resultados de un modelo de regresi√≥n m√∫ltiple, especialmente la interpretaci√≥n de las pendientes. El principal mensaje de la siguiente secci√≥n es que en una regresi√≥n lineal m√∫ltiple, cada uno de los par√°metros solo tiene sentido en el contexto del resto de los par√°metros."
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html#variables-de-confusi√≥n-y-variables-redundantes",
    "href": "05_Regresi√≥n_lineal.html#variables-de-confusi√≥n-y-variables-redundantes",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "7.6 Variables de confusi√≥n y variables redundantes",
    "text": "7.6 Variables de confusi√≥n y variables redundantes\nImagina la siguiente situaci√≥n. Tenemos una variable \\(z\\) correlacionada con la variable predictora \\(x\\) y, al mismo tiempo, con la variable dependiente \\(y\\). Supongamos que la variable \\(z\\) es la responsable de causar \\(x\\) e \\(y\\). Por ejemplo, \\(z\\) podr√≠a ser la revoluci√≥n industrial (¬°una variable realmente compleja!), \\(x\\) el n√∫mero de piratas, e \\(y\\) la concentraci√≥n de \\(CO_2\\). Este ejemplo deber√≠a ser muy familiar para lectores Pastafariano. Si omitimos \\(z\\) de nuestro an√°lisis, podr√≠amos terminar con una buena relaci√≥n lineal entre \\(x\\) e \\(y\\), incluso podr√≠amos predecir \\(x\\) a partir de \\(y\\). Sin embargo, si nuestro inter√©s radica en minimizar el calentamiento global, podr√≠amos pasar por alto lo que realmente est√° sucediendo con el mecanismo subyacente que relaciona estas variables.\nLo que intento decir es la conocida expresi√≥n correlaci√≥n no implica causalidad. Una raz√≥n por la que esto no es necesariamente cierto es que podemos estar omitiendo la variable \\(z\\) de nuestro an√°lisis. Cuando esto sucede, llamamos a \\(z\\) variable de confusi√≥n o factor de confusi√≥n. En muchos escenarios reales \\(z\\) es f√°cil de perder de vista. Tal vez no la medimos o no estaba presente en el conjunto de datos que nos enviaron, o ni siquiera pensamos que \\(z\\) podr√≠a estar relacionado con nuestro problema. No tomar en cuenta las variables de confusi√≥n en un an√°lisis podr√≠a llevarnos a establecer correlaciones falsas. Esto siempre es un problema cuando tratamos de explicar algo y tambi√©n puede ser problem√°tico cuando tratamos de predecir algo sin preocuparnos por comprender el mecanismo subyacente. Comprender el mecanismo nos ayuda a traducir lo que hemos aprendido a situaciones nuevas; las predicciones ciegas no siempre tienen buena transferibilidad. Por ejemplo, la cantidad de zapatillas producidas en Argentina podr√≠a utilizarse como un indicador simple para estimar la fortaleza de su econom√≠a, pero podr√≠a ser un p√©simo predictor para otros pa√≠ses con una matriz de producci√≥n o un contexto cultural diferente.\nA continuaci√≥n vamos a usar datos sint√©ticos para explorar un poco el concepto de variable de confusi√≥n. El siguiente c√≥digo simula una variable de confusi√≥n como \\(x_1\\). Esta variable tiene influencia tanto en \\(x_2\\) como en \\(y\\):\n\nnp.random.seed(42)\nN = 100\nx_1 = np.random.normal(size=N)\nx_2 = x_1 + np.random.normal(size=N, scale=1)\n#x_2 = x_1 + np.random.normal(size=N, scale=0.01)  \ny = x_1 + np.random.normal(size=N)\nX = np.vstack((x_1, x_2)).T\n\nDebido a como generamos los datos estos ya est√°n centrados como se puede ver en la siguiente figura:\n\nscatter_plot(X, y);\n\n\n\n\nAhora vamos a construir tres modelos relacionados, el primero m_x1x2, es un modelo de regresi√≥n lineal con dos variables independientes \\(x_1\\) y \\(x_2\\) (apilados en la variable \\(X\\)). El segundo modelo, m_x1, es una regresi√≥n lineal simple para y el tercero, m_x2, una regresi√≥n de l√≠nea simple para \\(x_2\\):\n\nwith pm.Model() as m_x1x2:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=10)\n    Œ≤1 = pm.Normal('Œ≤1', mu=0, sigma=10)\n    Œ≤2 = pm.Normal('Œ≤2', mu=0, sigma=10)\n    œµ = pm.HalfCauchy('œµ', 5)\n\n    Œº = Œ± + Œ≤1 * X[:,0] + Œ≤2 * X[:,1] \n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y)\n \n    idata_x1x2 = pm.sample(2000)\n    \n    \nwith pm.Model() as m_x1:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=10)\n    Œ≤1 = pm.Normal('Œ≤1', mu=0, sigma=10)\n    œµ = pm.HalfCauchy('œµ', 5)\n\n    Œº = Œ± + Œ≤1 * X[:,0]\n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y)\n \n    idata_x1 = pm.sample(2000)\n    \nwith pm.Model() as m_x2:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=10)\n    Œ≤2 = pm.Normal('Œ≤2', mu=0, sigma=10)\n    œµ = pm.HalfCauchy('œµ', 5)\n\n    Œº = Œ± + Œ≤2 * X[:,1]\n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y)\n \n    idata_x2 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤1, Œ≤2, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:02<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 3 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤1, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:02<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 2 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤2, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:02<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 2 seconds.\n\n\nA continuaci√≥n usamos un forestplot a fin de comparar los valores de \\(\\beta\\) para estos 3 modelos.\n\nax = az.plot_forest([idata_x1x2, idata_x1, idata_x2], model_names=['m_x1x2', 'm_x1', 'm_x2'], var_names=['Œ≤1', 'Œ≤2'],\n                    r_hat=False, ess=False, combined=True, colors='cycle',\n                    kind=\"ridgeplot\",\n                    figsize=(9, 4));\n\n\n\n\nComo podemos ver \\(\\beta_2\\) para el modelo m_x1x2 es alrededor de cero, lo que indica una contribuci√≥n casi nula de la variable \\(x_2\\) para explicar \\(y\\). Esto es interesante porque ya sabemos que la variable realmente importante es \\(x_1\\) (como se puede verificar en la generaci√≥n de datos sint√©ticos). Tambi√©n hay que notar, y esto es realmente importante, \\(\\beta_2\\) para el modelo m_x2 es alrededor de 0.55, es decir es m√°s grande que para el modelo m_x1x2. En otras palabras el poder de \\(x_2\\) para predecir \\(y\\) se reduce cuando tenemos en cuenta \\(x_1\\), ya que la informaci√≥n en \\(x_1\\) es redundante dado \\(x_2\\)."
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html#multicolinearidad-o-cuando-la-correlaci√≥n-es-demasiado-alta",
    "href": "05_Regresi√≥n_lineal.html#multicolinearidad-o-cuando-la-correlaci√≥n-es-demasiado-alta",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "7.7 Multicolinearidad o cuando la correlaci√≥n es demasiado alta",
    "text": "7.7 Multicolinearidad o cuando la correlaci√≥n es demasiado alta\nLlevemos el ejemplo anterior a un extremo y veamos qu√© sucede cuando dos variables est√°n altamente correlacionadas. Para estudiar este problema y sus consecuencias para la inferencia, utilizaremos los mismos datos y modelos sint√©ticos que antes, pero ahora aumentaremos el grado de correlaci√≥n entre \\(x_1\\) y \\(x_2\\) al reducir la cantidad de ruido Gaussiano que agregamos a \\(x_1\\) para obtener \\(x_2\\).\n\n# Este es el mismo c√≥digo de una celdas antes pero con una valor m√°s bajo de `scale`\nnp.random.seed(42)\nN = 100\nx_1 = np.random.normal(size=N)\nx_2 = x_1 + np.random.normal(size=N, scale=0.01)  \ny = x_1 + np.random.normal(size=N)\nX = np.vstack((x_1, x_2)).T\n\nEl cambio en la generaci√≥n de datos, de la celda anterior, pr√°cticamente equivale a sumar 0 a \\(x_1\\), por lo tanto ambas variables son iguales para todo prop√≥sito pr√°ctico. A continuaci√≥n, pueden intentar variar los valores de la desviaci√≥n est√°ndar y usar valores menos extremos, pero por ahora queremos que el efecto sea bien claro. En el siguiente gr√°fico se puede ver que ahora el diagrama de dispersi√≥n para \\(x_1\\) y \\(x_2\\) es pr√°cticamente una l√≠nea recta con una pendiente alrededor de 1:\n\nscatter_plot(X, y)\n\n\n\n\nEjecutamos una regresi√≥n lineal m√∫ltiple:\n\nwith pm.Model() as model_red :\n    Œ± = pm.Normal('Œ±', mu=0, sigma=10)\n    Œ≤ = pm.Normal('Œ≤', mu=0, sigma=10, shape=2)\n    œµ = pm.HalfCauchy('œµ', 5)\n\n    Œº = Œ± + pm.math.dot(X, Œ≤)\n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y)\n \n    idata_red = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 01:03<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 63 seconds.\n\n\nY verificamos los resultados de los par√°metros con un forestplot:\n\naz.plot_forest(idata_red, var_names=['Œ≤'], r_hat=0, ess=0, combined=1, figsize=(8, 2));\n\n\n\n\nLos valores de los HDI para \\(\\beta\\) son sospechosamente amplios, podemos obtener una idea de lo que est√° sucediendo con un diagrama de dispersi√≥n de los coeficientes \\(\\beta\\)\n\naz.plot_pair(idata_red, var_names=['Œ≤'], scatter_kwargs={'alpha':0.05});\n\n\n\n\nLa distribuci√≥n de los coeficientes \\(\\beta\\) es una diagonal realmente estrecha. Cuando un coeficiente \\(\\beta\\) sube, el otro debe bajar. Ambos est√°n efectivamente correlacionados. Esto es solo una consecuencia del modelo y los datos. Seg√∫n nuestro modelo, la media \\(\\mu\\) es:\n\\[ \\mu = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 \\tag{3.19} \\]\nSi suponemos que \\(x_1\\) y \\(x_2\\) no son pr√°cticamente equivalentes, sino matem√°ticamente id√©nticos, podemos volver a escribir el modelo como:\n\\[ \\mu = \\alpha + (\\beta_1 + \\beta_2) x \\tag{3.20} \\]\nResulta que es la suma \\(\\beta_1 + \\beta_2\\) y no sus valores separados, lo que afecta \\(\\mu\\). Podemos hacer que \\(\\beta_1\\) sea m√°s peque√±o y m√°s peque√±o siempre que hagamos que \\(\\beta_2\\) sea m√°s y m√°s grande. Los resultados nos est√°n diciendo que como pr√°cticamente NO tenemos dos variables \\(x\\), pr√°cticamente NO tenemos dos par√°metros \\(\\beta\\). Decimos entonces que el modelo est√° indeterminado (o de forma equivalente, los datos no pueden restringir los par√°metros en el modelo). En nuestro ejemplo, hay dos razones por las cuales \\(\\beta\\) no se mueve libremente en el intervalo \\((-\\infty, \\infty)\\). Primero, ambas variables son casi las mismas, pero no son exactamente iguales, en segundo lugar, y lo m√°s importante, los a prioris actuan como restricciones de los valores plausibles que \\(\\beta\\) puede tomar.\nHay un par de cosas que notar de este ejemplo. En primer lugar, el a posteriori es tan solo la consecuencia l√≥gica de los datos y el modelo, por lo tanto no hay nada de malo en obtener distribuciones tan amplias para \\(\\beta\\), C‚Äôest la vie. En segundo lugar, podemos confiar en este modelo para hacer predicciones ya que los valores predichos por el modelo est√°n de acuerdo con los datos, es decir el modelo captura los datos muy bien. En tercer lugar, este puede no ser un modelo muy bueno para comprender nuestro problema. Puede ser m√°s inteligente simplemente eliminar una de las variables del modelo. Terminaremos teniendo un modelo que predice los datos igual que antes, pero con una interpretaci√≥n m√°s simple.\nEn cualquier conjunto de datos real, van a existir variables (parcialmente) correlacionadas. Esto sucede por al menos dos razones: la existencia de correlaciones espurias y quiz√° lo m√°s relevante; al estudiar un problema tendemos a recolectar informaci√≥n que consideramos relevante pero que puede ser parcialmente redundante. Por ejemplo, la cantidad de radiaci√≥n solar, la temperatura y las precipitaciones son factores que influyen para predecir el rinde de un cultivo, y son variables que tienen a estar correlacionadas por ejemplo si el verano es la temporada de mayores lluvias.\n¬øQu√© tan fuerte deben correlacionarse dos o m√°s variables para convertirse en un problema? Bueno se suele considerar que a partir de 0.9845. No, mentira! Desafortunadamente, la estad√≠stica es una disciplina con muy pocos n√∫meros m√°gicos. Siempre es posible hacer una matriz de correlaci√≥n antes de ejecutar cualquier modelo y verificar las variables con una alta correlaci√≥n de, digamos por encima de 0.9 o m√°s. Sin embargo, el problema con este enfoque es que lo que realmente importa no son las correlaciones por pares que podemos observar en una matriz de correlaci√≥n, sino la correlaci√≥n de las variables dentro de un modelo, y como ya vimos, las variables se comportan de forma diferente cuando est√°n aisladas que cuando se relacionan dentro de un modelo. Dos o m√°s variables pueden aumentar o disminuir su correlaci√≥n cuando se colocan en el contexto de otras variables en un modelo de regresi√≥n m√∫ltiple. Como siempre, una inspecci√≥n cuidadosa de la distribuci√≥n a posteriori junto con una aproximaci√≥n iterativa y cr√≠tica del modelado, son muy recomendables y pueden ayudarnos a detectar problemas y comprender los datos y los modelos.\nSolo como una gu√≠a r√°pida (a tomar con pinzas). ¬øQu√© deber√≠amos hacer si encontramos variables altamente correlacionadas?\n\nSi la correlaci√≥n es realmente alta, podemos eliminar una de las variables del an√°lisis; dado que ambas variables tienen informaci√≥n similar, cual eliminamos suele ser a menudo irrelevante. Podemos eliminar variables basadas en nuestra conveniencia, por ejemplo eliminar variables menos conocidas o m√°s dif√≠ciles de interpretar o las m√°s costosas de medir.\nOtra posibilidad es crear una nueva variable promediando las variables redundantes. Una versi√≥n m√°s sofisticada es usar un algoritmo de reducci√≥n de variables como un an√°lisis de componentes principales (PCA). El problema con PCA es que las variables resultantes son combinaciones lineales de las originales que ofuscan, en general, la interpretabilidad de los resultados.\nOtra soluci√≥n es utilizar a prioris m√°s fuertes para restringir los valores plausibles que puede adoptar el coeficiente, en este contexto los a prioris se usan como regularizadores de la inferencia (algo que discutiremos m√°s adelante)."
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html#variables-de-efecto-de-enmascaramiento",
    "href": "05_Regresi√≥n_lineal.html#variables-de-efecto-de-enmascaramiento",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "7.8 Variables de efecto de enmascaramiento",
    "text": "7.8 Variables de efecto de enmascaramiento\nOtro ejemplo de c√≥mo las variables contribuyen a un resultado es el caso de las variables que enmascaran. Vamos a crear dos variables independientes (\\(x_1\\) y \\(x_2\\)), las cuales est√°n positivamente correlacionadas entre s√≠ y est√°n correlacionadas con \\(y\\), pero en direcciones opuestas \\(x_1\\) est√° correlacionada positivamente y \\(x_2\\) correlacionada negativamente.\n\nnp.random.seed(42)\nN = 126\nr = 0.8\nx_1 = np.random.normal(size=N)\nx_2 = np.random.normal(x_1, scale=(1 - r ** 2) ** 0.5)\ny = np.random.normal(x_1 - x_2)\nX = np.vstack((x_1, x_2)).T\n\n\nscatter_plot(X, y);\n\n\n\n\nComo hicimos antes, vamos a construir 3 modelos relacionados, el primero m_x1x2, es un modelo de regresi√≥n lineal con dos variables independientes \\(x_1\\) y \\(x_2\\) (apilados en la variable X). El segundo modelo, m_x1, es una regresi√≥n lineal simple para \\(x_1\\) y el tercero, m_x2, una regresi√≥n lineal simple para \\(x_2\\).\n\nwith pm.Model() as m_x1x2:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=10)\n    Œ≤1 = pm.Normal('Œ≤1', mu=0, sigma=10)\n    Œ≤2 = pm.Normal('Œ≤2', mu=0, sigma=10)\n    œµ = pm.HalfCauchy('œµ', 5)\n\n    Œº = Œ± + Œ≤1 * X[:,0] + Œ≤2 * X[:,1] \n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y)\n \n    trace_x1x2 = pm.sample(1000)\n    \n    \nwith pm.Model() as m_x1:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=10)\n    Œ≤1 = pm.Normal('Œ≤1', mu=0, sigma=10)\n    œµ = pm.HalfCauchy('œµ', 5)\n\n    Œº = Œ± + Œ≤1 * X[:,0]\n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y)\n \n    trace_x1 = pm.sample(1000)\n    \nwith pm.Model() as m_x2:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=10)\n    Œ≤2 = pm.Normal('Œ≤2', mu=0, sigma=10)\n    œµ = pm.HalfCauchy('œµ', 5)\n\n    Œº = Œ± + Œ≤2 * X[:,1]\n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y)\n \n    trace_x2 = pm.sample(1000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤1, Œ≤2, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤1, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤2, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\nEchemos un vistazo a los par√°metros \\(\\beta\\) usando un forestplot para compararlos en un solo diagrama.\n\naz.plot_forest([trace_x1x2, trace_x1, trace_x2], model_names=['m_x1x2', 'm_x1', 'm_x2'],\n               var_names=['Œ≤1', 'Œ≤2'], r_hat=False, ess=False, combined=True, \n               kind=\"ridgeplot\", colors='cycle',\n               figsize=(10, 4));\n\n\n\n\nDe acuerdo a la distribuci√≥n a posteriori, los valores de \\(\\beta\\) para m_x1x2 est√°n cerca de 1 y -1 (como se esperaba, de acuerdo a la forma en que generamos los datos). Para el modelo de regresi√≥n lineal simple, es decir, cuando estudiamos cada variable por separado, podemos ver que los valores de \\(\\beta\\) son m√°s cercanos a cero, lo que indica un efecto m√°s d√©bil.\nLo que sucede es que \\(x_1\\) est√° correlacionado con \\(x_2\\), cuando \\(x_1\\) aumenta \\(x_2\\) tambi√©n aumenta. Adem√°s \\(y\\) aumenta, \\(x_1\\) tambi√©n aumenta, pero \\(x_2\\) disminuye. Como resultado de este arreglo particular, obtenemos una cancelaci√≥n parcial de los efectos a menos que incluyamos ambas variables en la misma regresi√≥n lineal. El modelo de regresi√≥n lineal puede desenredar estos efectos porque el modelo est√° aprendiendo, para cada punto de datos, cu√°l es la contribuci√≥n de \\(x_1\\) a \\(y\\) dado un valor de \\(x_2\\), y al rev√©s por \\(x_2\\)."
  },
  {
    "objectID": "05_Regresi√≥n_lineal.html#resumen",
    "href": "05_Regresi√≥n_lineal.html#resumen",
    "title": "6¬† Regresi√≥n Lineal",
    "section": "7.9 Resumen",
    "text": "7.9 Resumen\nUna regresi√≥n lineal simple es un modelo que puede usarse para predecir y/o explicar una variable desde otra. Desde una perspectiva probabilista, un modelo de regresi√≥n lineal es una extensi√≥n del modelo Gaussiano donde la media no se estima directamente, sino que se calcula como una funci√≥n lineal de una variable de predicci√≥n y algunos par√°metros adicionales. Si bien la distribuci√≥n gaussiana es la opci√≥n m√°s com√∫n para la variable dependiente, somos libres de elegir otras distribuciones. Una alternativa especialmente √∫til cuando se trata de posibles valores at√≠picos, es la distribuci√≥n t de Student. Otra forma √∫til de expandir un modelo de regresi√≥n lineal es haciendo una versi√≥n jer√°rquica de √©l. Esto es muy simple de lograr con PyMC y obtenemos los beneficios del shrinkage."
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html",
    "href": "06_Generalizando_modelos_lineales.html",
    "title": "7¬† Generalizando modelos lineales",
    "section": "",
    "text": "8 Regresi√≥n log√≠stica m√∫ltiple\nDe manera similar a la regresi√≥n lineal m√∫ltiple, la regresi√≥n log√≠stica m√∫ltiple consiste en utilizar m√°s de una variable independiente. Intentemos combinar la longitud del s√©palo y el ancho del s√©palo. Recuerda que necesitamos preprocesar un poco los datos."
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#regresi√≥n-polinomial",
    "href": "06_Generalizando_modelos_lineales.html#regresi√≥n-polinomial",
    "title": "7¬† Generalizando modelos lineales",
    "section": "7.1 Regresi√≥n polinomial",
    "text": "7.1 Regresi√≥n polinomial\nAhora vamos a aprender c√≥mo ajustar curvas usando una regresi√≥n lineal. Una manera de ajustar curvas usando un modelo de regresi√≥n lineal es construyendo un polinomio como este:\n\\[\\mu = \\beta_0 x^0 + \\beta_1 x^1  \\dots + \\beta_m x^m \\tag{3.12} \\]\nSi prestamos atenci√≥n, podemos ver que este polinomio esconde un modelo lineal simple. De hecho si hacemos que \\(\\beta_n = 0\\) para \\(n \\gt 1\\) obtendremos:\n\\[\\mu = \\beta_0 + \\beta_1 x^1 \\tag{3.13} \\]\nQue no es otra cosa que la ecuaci√≥n de una recta. Una regresi√≥n polinomial sigue siendo una regresi√≥n lineal, ya que la linearidad del modelo est√° relacionada con la forma en que los par√°metros entran en el modelo y no con las variables. Probemos construyendo una regresi√≥n polinomial de grado 2.\n\\[\\mu = \\beta_0 + \\beta_1 x^1 + \\beta_2 x^2 \\tag{3.14} \\]\nEl tercer t√©rmino controla la curvatura de la relaci√≥n como veremos a continuaci√≥n.\nComo un conjunto de datos, vamos a utilizar el segundo grupo del cuarteto de Anscombe.\n\nans = pd.read_csv('datos/anscombe.csv')\nx_2 = ans[ans.group == 'II']['x'].values\ny_2 = ans[ans.group == 'II']['y'].values\nx_2 = x_2 - x_2.mean()\ny_2 = y_2 - y_2.mean()\n\nplt.scatter(x_2, y_2)\nplt.xlabel('x')\nplt.ylabel('y', rotation=0);\n\n\n\n\n\nwith pm.Model() as model_poly:\n    Œ± = pm.Normal('Œ±', mu=y_2.mean(), sigma=1)\n    Œ≤1 = pm.Normal('Œ≤1', mu=0, sigma=1)\n    Œ≤2 = pm.Normal('Œ≤2', mu=0, sigma=1)\n    œµ = pm.HalfNormal('œµ', 10)\n\n    mu = Œ± + Œ≤1 * x_2 + Œ≤2 * x_2**2\n    \n    y_pred = pm.Normal('y_pred', mu=mu, sigma=œµ, observed=y_2)\n    \n    idata_poly = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤1, Œ≤2, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\nOnce again, we are going to omit some checks and summaries and just plot the results, a nice curved line fitting the data almost with no errors. Take into account the minimalistic nature of the dataset.\n\naz.plot_trace(idata_poly);\n\n\n\n\n\naz.summary(idata_poly)\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      Œ±\n      1.267\n      0.001\n      1.265\n      1.269\n      0.0\n      0.0\n      1857.0\n      1551.0\n      1.0\n    \n    \n      Œ≤1\n      0.500\n      0.000\n      0.500\n      0.500\n      0.0\n      0.0\n      2638.0\n      1874.0\n      1.0\n    \n    \n      Œ≤2\n      -0.127\n      0.000\n      -0.127\n      -0.127\n      0.0\n      0.0\n      1911.0\n      1786.0\n      1.0\n    \n    \n      œµ\n      0.002\n      0.001\n      0.001\n      0.003\n      0.0\n      0.0\n      1433.0\n      1578.0\n      1.0\n    \n  \n\n\n\n\n\nx_p = np.linspace(-6, 6)\npost_mean = idata_poly.posterior.mean((\"chain\", \"draw\"))\n\ny_p = post_mean['Œ±'].item() + post_mean['Œ≤1'].item() * x_p + post_mean['Œ≤2'].item() * x_p**2\nplt.scatter(x_2, y_2)\nplt.xlabel('x',)\nplt.ylabel('y', rotation=0)\nplt.plot(x_p, y_p, c='C1');\n\n\n\n\n\n7.1.1 Interpretando los par√°metros de una regresi√≥n polinomial\nUno de los problemas de la regresi√≥n polin√≥mica es la interpretaci√≥n de sus par√°metros. Si queremos saber c√≥mo cambia \\(y\\) por unidad de cambio de \\(x\\), no podemos simplemente verificar el valor de \\(\\beta_1\\), ya que \\(\\beta_2\\), y los coeficientes m√°s altos (de estar presentes), tendr√°n un efecto en dicha cantidad. Entonces los coeficientes \\(\\beta\\) ya no son pendientes, son otra cosa. En el ejemplo anterior, \\(\\beta_1\\) es positivo y, por lo tanto, la curva comienza con una pendiente positiva, pero \\(\\beta_2\\) es negativo y, por lo tanto, despu√©s de un tiempo, la l√≠nea comienza a curvarse hacia abajo. Es como si tuvi√©ramos dos fuerzas en juego, una empujando la l√≠nea hacia arriba y la otra hacia abajo. La interacci√≥n depende del valor de \\(x\\). Cuando \\(x \\lessapprox 11\\) (en la escala original, o 2 en la escala centrada), la contribuci√≥n dominante proviene de \\(\\beta_1\\), y cuando \\(x \\gtrapprox 11\\), entonces \\(\\beta_2\\) domina.\nEl principal problema de interpretar los par√°metros en modelos polinomiales, es que en general los par√°metros no se traducen a cantidades que tengan sentido a la luz de nuestro conocimiento de dominio. Es decir no podemos relacionarlos con la tasa metab√≥lica de una c√©lula, la energ√≠a emitida por una galaxia o el n√∫mero de habitaciones en una casa. Los par√°metros terminan siendo simplemente perillas que podemos manipular para mejorar el ajuste pero sin un significado claro. En la pr√°ctica, la mayor√≠a de la gente suele estar de acuerdo en que los polinomios de orden superior a dos o tres generalmente no son modelos muy √∫tiles y se prefieren alternativas, quiz√° como splines o los Procesos Gaussianos.\nEn este trabajo se propone una versi√≥n interpretable (y no lineal) de un polinomio de grado 2.\n\\[\n\\alpha_y - (\\alpha_y - \\alpha_0) \\left(\\frac{x_i}{\\alpha_x} -1\\right)^2\n\\] * \\(\\alpha_0\\) : intercepto, valor de \\(Y\\) cuando \\(x=0\\) * \\(\\alpha_x\\) : valor de \\(x_i\\) que maximiza/minimiza \\(Y\\) * \\(\\alpha_y\\) : valor m√°ximo/m√≠nimo de \\(Y\\)"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#varianza-variable",
    "href": "06_Generalizando_modelos_lineales.html#varianza-variable",
    "title": "7¬† Generalizando modelos lineales",
    "section": "7.2 Varianza variable",
    "text": "7.2 Varianza variable\nHemos estado usando el modelo lineal para modelar la media de una distribuci√≥n, dejando la varianza de lado. En caso que consideremos que el supuesto de varianza constante no tiene sentido podemos considerar la varianza como una funci√≥n (lineal) de la variable dependiente.\nLa Organizaci√≥n Mundial de la Salud y otras instituciones de salud de todo el mundo recopilan datos para reci√©n nacidos y adultos mayores y dise√±an est√°ndares de gr√°ficos de crecimiento. Estas tablas son un componente esencial del conjunto de herramientas pedi√°tricas y tambi√©n como una medida del bienestar general de las poblaciones con el fin de formular pol√≠ticas de salud, planificar intervenciones y controlar su eficacia. Un ejemplo de tales datos son la longitud (alturas) de las ni√±as reci√©n nacidas en funci√≥n de la edad (en meses):\n\ndata = pd.read_csv('datos/babies.csv')\ndata.plot.scatter('Meses', 'Longitud');\n\n\n\n\nPara modelar estos datos, presentaremos 3 elementos nuevos en comparaci√≥n con los modelos anteriores:\n\n\\(\\epsilon\\) ahora es una funci√≥n lineal de \\(x\\), y para hacer esto agregamos dos nuevos par√°metros \\(\\gamma\\) y \\(\\delta\\), estos son an√°logos directos de \\(\\alpha\\) y \\(\\beta\\).\nEl modelo lineal para la media es una funci√≥n de \\(\\sqrt{x}\\), esto es solo un truco simple para ajustar un modelo lineal a una curva.\nHemos definido una variable compartida x_shared, esto nos permitir√° cambiar los valores de la variable \\(x\\) (Meses en este ejemplo) sin la necesidad de volver a muestrear el modelo. Por qu√© hacemos estos ser√° evidente pronto si tienen un poco de paciencia.\n\n\nwith pm.Model() as model_vv:\n    x_shared = pm.MutableData(\"x_shared\", data.Meses.values.astype(float))\n    Œ± = pm.Normal('Œ±', sigma=10)\n    Œ≤ = pm.Normal('Œ≤', sigma=10)\n    Œ≥ = pm.HalfNormal('Œ≥', sigma=10)\n    Œ¥ = pm.HalfNormal('Œ¥', sigma=10)\n\n\n    Œº = pm.Deterministic('Œº', Œ± + Œ≤ * x_shared**0.5)\n    œµ = pm.Deterministic('œµ', Œ≥ + Œ¥ * x_shared)\n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=data.Longitud)\n    \n    idata_vv = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤, Œ≥, Œ¥]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\nLa siguiente figura muestra el resultado de nuestro modelo. La media de es \\(\\mu\\) representada con una curva negra, y dos bandas turquesa semitransparentes representan 1 y 2 desviaciones est√°ndar.\n\n_, axes = plt.subplots(1, 2, figsize=(12, 4))\n\naxes[0].plot(data.Meses, data.Longitud, 'C0.', alpha=0.1);\n\nposterior = az.extract(idata_vv)\n\nŒº_m = posterior['Œº'].mean(\"sample\").values\nœµ_m = posterior['œµ'].mean(\"sample\").values\n\naxes[0].plot(data.Meses, Œº_m, c='k')\naxes[0].fill_between(data.Meses, Œº_m + 1 * œµ_m, Œº_m - 1 * œµ_m, alpha=0.6, color='C1')\naxes[0].fill_between(data.Meses, Œº_m + 2 * œµ_m, Œº_m - 2 * œµ_m, alpha=0.4, color='C1')\n\naxes[0].set_xlabel('Meses')\naxes[0].set_ylabel('Longitud');\n\n\naxes[1].plot(data.Meses, œµ_m)\naxes[1].set_xlabel('Meses');\naxes[1].set_ylabel(r'$\\bar œµ$', rotation=0);\n\n\n\n\nAhora que tenemos ajustado el modelo podr√≠amos querer averiguar c√≥mo se compara la longitud de una ni√±a en particular con el modelo. Una forma de responder a esta pregunta es preguntarle al modelo por la distribuci√≥n de la variable longitud para bebas de digamos de 0.5 meses. Usando PyMC3 podemos hacer estas preguntas con la funci√≥n sample_ppc, ya que esto arrojar√° muestras de \\(\\tilde y\\) es decir los valores predichos considerando la incertidumbre de los par√°metros. El √∫nico problema es que, por defecto, esta funci√≥n devolver√° valores de \\(\\tilde y\\) para los valores observados de \\(x\\) y de 0,5 meses (el valor que me importa) no es parte de los datos originales. La manera m√°s f√°cil de obtener predicciones para valores no observados es definir una variable compartida \\(x\\) (como parte del modelo) y luego actualizar el valor de la variable compartida justo antes del muestreo de la distribuci√≥n predictiva a posteriori.\n\nwith model_vv:\n    pm.set_data({\"x_shared\": [0.5]})\n    ppc = pm.sample_posterior_predictive(idata_vv)\n    y_ppc = ppc.posterior_predictive['y_pred'].stack(sample=(\"chain\", \"draw\"))\n\nSampling: [y_pred]\n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00<00:00]\n    \n    \n\n\nAhora podemos graficar la distribuci√≥n esperada de las longitudes para las bebas con 2 semanas de vida y calcular cantidades adicionales, por ejemplo, el percentil de un ni√±o para su longitud:\n\nref = 52.5\ngrid, pdf = az.stats.density_utils._kde_linear(y_ppc.values)\nplt.plot(grid, pdf)\npercentile = int((y_ppc <= ref).mean() * 100)\nplt.fill_between(grid[grid < ref], pdf[grid < ref], label='percentil = {:2d}'.format(percentile))\nplt.xlabel('longitud')\nplt.yticks([])\nplt.legend();"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#modelos-lineales-generalizados",
    "href": "06_Generalizando_modelos_lineales.html#modelos-lineales-generalizados",
    "title": "7¬† Generalizando modelos lineales",
    "section": "7.3 Modelos lineales generalizados",
    "text": "7.3 Modelos lineales generalizados\nHasta el momento hemos asumido que la variable dependiente puede variar, a priori, sin restricciones y por ello usamos como likelihood una Gaussiana (o una generalizaci√≥n de esta como lo es la t de Student). Pero que podemos hacer si la variable respuesta est√° restringida a ser positiva, o discreta, o en el intervalo [0, 1], etc. Usando software como PyMC bastar√≠a con cambiar el likelihood de una Gaussiana a una Poisson (o lo que haga falta), pero si solo hacemos eso tendremos problemas, ya que la combinaci√≥n lineal de par√°metros podr√≠a dar valores fuera del rango permitido (por ej negativos). Para subsanar este problema podemos aplicar una funci√≥n a la combinaci√≥n lineal de variables de entrada, algo como:\n\\[\\mu = f(\\alpha + X \\beta) \\tag{4.1}\\]\ndonde \\(f\\) es lo que se conoce como funci√≥n inversa de enlace. Hay una gran variedad de funciones inversas de enlace que podemos elegir, probablemente la m√°s simple sea la funci√≥n identidad. Esta es una funci√≥n que devuelve el mismo valor utilizado como argumento. Todos los modelos del cap√≠tulo anterior usaron la funci√≥n de identidad, y por simplicidad simplemente la omitimos. La funci√≥n de identidad puede no ser muy √∫til en s√≠ misma, pero nos permite pensar en varios modelos diferentes de una manera unificada.\n\n¬øPor qu√© llamamos a \\(f\\) funci√≥n inversa de enlace en lugar de llamarla simplemente funci√≥n de enlace? La raz√≥n es hist√≥rica. Tradicionalmente las personas aplican funciones al otro lado de la ecuaci√≥n \\(4.1\\), y llaman a esas funciones funciones de enlace, por lo tanto, para evitar confusiones, nos apegaremos al t√©rmino funci√≥n inveras de enlace.\n\nVeamos algunos ejemplos concretos de modelos lineales generalizados"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#regresi√≥n-log√≠stica",
    "href": "06_Generalizando_modelos_lineales.html#regresi√≥n-log√≠stica",
    "title": "7¬† Generalizando modelos lineales",
    "section": "7.4 Regresi√≥n log√≠stica",
    "text": "7.4 Regresi√≥n log√≠stica\nLa regresi√≥n logistica es la generalizaci√≥n del modelo de regresi√≥n que vimos en el cap√≠tulo pasado para cuando la variable dependiente es binaria. Esta generalizaci√≥n se logra en dos pasos. Primero reemplazamos \\(f\\) en \\(4.1\\) por la funci√≥n log√≠stica:\n\\[ \\text{log√≠stica}(z) = \\frac{1}{1 + e^{-z}} \\tag{4.2}\\]\nUsamos esta funci√≥n por que una de sus propiedades es que no importa el valor del argumento \\(z\\), el resultado siempre ser√° un valor en el intervalo [0-1]. La funci√≥n log√≠stica es conocida tambi√©n como funci√≥n sigmoide, por su aspecto t√≠pico de S como se puede ver al ejecutar la siguiente celda:\n\nz = np.linspace(-6, 6)\nlog√≠stica = 1 / (1 + np.exp(-z))\nplt.plot(z, log√≠stica)\nplt.xlabel('z')\nplt.ylabel('log√≠stica(z)');\n\n\n\n\nEl segundo paso consiste en usar como likelihood una distribuci√≥n binomial y no una Gaussiana. De esta forma el modelo queda expresado como:\n\\[\n\\theta = logistic(\\alpha + x\\beta) \\\\\ny = \\text{Bern}(\\theta) \\tag{4.3}\n\\]\nEsto modelo se puede motivar de la siguiente forma. Si nuestros datos son binarios \\(y \\in \\{0, 1\\}\\), como con el ejemplo de la moneda o el diagn√≥stico, vemos que tiene sentido usar una distribuci√≥n bernoulli. Esta distribuci√≥n est√° parametrizada por un √∫nico par√°metro en el intervalo [0, 1], el cual puede ser generado desde un modelo lineal siempre y cuando los valores generados por el modelo lineal sean comprimidos al intervalo [0, 1], algo que puede ser obtenido al emplear una funci√≥n log√≠stica.\nUsando un diagrama de Kruschke una regresi√≥n log√≠stica con priors Gaussianos:"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#el-conjunto-de-datos-del-iris",
    "href": "06_Generalizando_modelos_lineales.html#el-conjunto-de-datos-del-iris",
    "title": "7¬† Generalizando modelos lineales",
    "section": "7.5 El conjunto de datos del Iris",
    "text": "7.5 El conjunto de datos del Iris\nVamos a aplicar una regresi√≥n log√≠stica al conjunto de datos Iris. Este es un conjunto de datos cl√°sico que contiene informaci√≥n sobre flores de 3 especies estrechamente relacionadas: setosa, virginica y versicolor. Estas ser√°n nuestras variables dependientes, las clases que queremos predecir. Tenemos 50 individuos de cada especie y para cada individuo el conjunto de datos contiene cuatro variables (o features) que vamos a usar como variables independientes. Estas son el largo del p√©talo, el ancho del p√©talo, el largo del s√©palo y el ancho del s√©palo. Por si se lo est√°n preguntando, los s√©palos son hojas modificadas, cuya funci√≥n est√° generalmente relacionada con la protecci√≥n de las flores en la yema.\nPodemos cargar un DataFrame con el conjunto de datos del iris haciendo:\n\niris = pd.read_csv('datos/iris.csv')\niris.head()\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n      species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n    \n      3\n      4.6\n      3.1\n      1.5\n      0.2\n      setosa\n    \n    \n      4\n      5.0\n      3.6\n      1.4\n      0.2\n      setosa\n    \n  \n\n\n\n\nAhora graficaremos las 3 especies versus la longitud del s√©palo usando la funci√≥n stripplot de seaborn:\n\nsns.stripplot(x=\"species\", y=\"sepal_length\", data=iris, hue=\"species\", jitter=True, legend=False);\n\n\n\n\nObserve en la figura 4.2 que en el eje y se representan una variable continua mientras que en el eje x la variable es categ√≥rica. La dispersi√≥n (o jitter) de los puntos a lo largo del eje x no tiene ning√∫n significado, y es solo un truco para evitar que todos los puntos colapsen en una sola l√≠nea (pueden probar pasando el argumento jitter=False). Por lo tanto lo √∫nico que importa al leer el eje x es la pertenencia de los puntos a las clases setosa, versicolor o virginica.\nOtra forma de inspeccionar los datos es haciendo una matriz de dispersi√≥n con la funci√≥n pairplot. En la figura 4.3 podemos ver una matriz de \\(4 \\times 4\\), ya que tenemos 4 variables independientes (o features). La matriz es sim√©trica con los tri√°ngulos superior e inferior conteniendo la misma informaci√≥n. En la diagonal principal en vez de tener una gr√°fico de dispersi√≥n de una variable contra si misma (lo cual no es informativo) tenemos un KDE de cada feature para cada especie (o clase). Cada especie est√° representada usando un color particular.\n\nsns.pairplot(iris, hue='species', plot_kws={\"legend\":False});\n\n/home/osvaldo/anaconda3/envs/bayes/lib/python3.9/site-packages/seaborn/axisgrid.py:118: UserWarning: This figure was using constrained_layout, but that is incompatible with subplots_adjust and/or tight_layout; disabling constrained_layout.\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\nAntes de continuar, t√≥mese un tiempo para estudiar las gr√°ficas anteriores y familiarizarse con el conjunto de datos y c√≥mo se relacionan las variables dependientes y las independientes.\n\n7.5.1 El modelo log√≠stico aplicado al conjunto de datos del iris.\nVamos a comenzar con la regresi√≥n log√≠stica m√°s simple posible: dos clases, setosa y versicolor, y solo una variable independiente, la longitud del s√©palo. Como se hace normalmente, vamos a codificar las variables categ√≥ricas setosa y versicolor con los n√∫meros 0 y 1. Usando Pandas podemos hacer:\n\ndf = iris.query(\"species == ('setosa', 'versicolor')\")\ny_0 = pd.Categorical(df['species']).codes\nx_n = 'sepal_length' \nx_0 = df[x_n].values\nx_c = x_0 - x_0.mean()\n\nAl igual que con otros modelos lineales, centrar los datos puede ayudar con el muestreo. Ahora que tenemos los datos en el formato adecuado, finalmente podemos construir el modelo con PyMC.\nObserve c√≥mo la primera parte del siguiente modelo se asemeja a un modelo de regresi√≥n lineal. Este modelo tiene dos variables deterministas: Œ∏ ybd. Œ∏ es la salida de la funci√≥n log√≠stica aplicada a la variable Œº y bd es l√≠mite de decisi√≥n (el cual explicaremos m√°s adelante).Otro punto que vale la pena mencionar es que en lugar de escribir expl√≠citamente la funci√≥n log√≠stica estamos usando pm.math.sigmoid (esto es un alias para una funci√≥n de Theano).\n\nwith pm.Model() as modelo_0:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=10)\n    Œ≤ = pm.Normal('Œ≤', mu=0, sigma=10)\n    \n    Œº = Œ± + pm.math.dot(x_c, Œ≤)    \n    Œ∏ = pm.Deterministic('Œ∏', pm.math.sigmoid(Œº))\n    bd = pm.Deterministic('bd', -Œ±/Œ≤)\n    \n    yl = pm.Bernoulli('yl', p=Œ∏, observed=y_0)\n\n    idata_0 = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n\n\nComo es habitual, tambi√©n mostramos el summary del posterior. M√°s adelante, compararemos el valor que obtengamos para el l√≠mite de decisi√≥n con un valor calculado utilizando otro m√©todo.\n\naz.plot_trace(idata_0, var_names='~Œ∏');\n\n\n\n\n\naz.summary(idata_0, var_names='~Œ∏')\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      Œ±\n      0.300\n      0.332\n      -0.322\n      0.907\n      0.006\n      0.005\n      3040.0\n      2833.0\n      1.0\n    \n    \n      Œ≤\n      5.376\n      1.064\n      3.511\n      7.416\n      0.020\n      0.014\n      3087.0\n      2711.0\n      1.0\n    \n    \n      bd\n      -0.055\n      0.061\n      -0.169\n      0.060\n      0.001\n      0.001\n      3104.0\n      2881.0\n      1.0\n    \n  \n\n\n\n\nAhora vamos a graficar los datos junto con la curva sigmoide ajustada:\n\n_, ax = plt.subplots(figsize=(10, 6))\n\npost_0 = az.extract(idata_0)\n\ntheta = post_0['Œ∏'].mean(\"sample\")\nidx = np.argsort(x_c)\nax.plot(x_c[idx], theta[idx], color='C8', lw=3)\nax.vlines(post_0['bd'].mean(\"sample\"), 0, 1, color='k')\nbd_hdi = az.hdi(post_0.unstack())[\"bd\"]\nax.fill_betweenx([0, 1], bd_hdi[0], bd_hdi[1], color='k', alpha=0.5)\n\nax.scatter(x_c, np.random.normal(y_0, 0.02), marker='.', color=[f'C{x}' for x in y_0])\ntheta_hdi = az.hdi(post_0.unstack())['Œ∏'][idx]\nax.fill_between(x_c[idx], theta_hdi[:,0], theta_hdi[:,1], color='C8', alpha=0.5)\n\nax.set_xlabel(x_n)\nax.set_ylabel('Œ∏', rotation=0, labelpad=20)\n# use original scale for xticks\nlocs, _ = plt.xticks() \nax.set_xticks(locs, np.round(locs + x_0.mean(), 1));\n\n\n\n\nLa figura anterior muestra la longitud del s√©palo para las especies (setosa = 0, versicolor = 1). Para mitigar la superposici√≥n de los datos, hemos agregado ruido (jitter) a las variable-respuesta que es binaria. Una l√≠nea p√∫rpura en forma de S representa el valor medio de \\(\\theta\\). Esta l√≠nea se puede interpretar como la probabilidad que una flor sea versicolor dado el valor de la longitud del s√©palo. La banda p√∫rpura semitransparente es el intervalo del 94% de HDI. Esta figura nos muestra que podemos interpretar la regresi√≥n log√≠stica como una forma de combinar variables linealmente a fin de obtener una probabilidad para variables binarias.\nAlternativamente podemos usar una regresi√≥n log√≠stica para clasificar, esto lo podemos hacer discretizando el valor de probabilidad obtenido. El caso m√°s com√∫n es asignar la clase 1 si la probabilidad es mayor a 0.5 y asignar la clase 0 en caso contrario. En la figura 4.4 hemos graficado este l√≠mite de decisi√≥n usando una l√≠nea vertical negra junto con su 94% HDI (la banda gris). De acuerdo con el l√≠mite de decisi√≥n, los valores \\(x_i\\) (longitud del s√©palo en este caso) a la izquierda corresponden a la clase 0 (setosa) y los valores a la derecha a la clase 1 (versicolor).\nEl l√≠mite de decisi√≥n se define como el valor de \\(x_i\\), para el cual \\(y = 0.5\\). Y resulta ser $- $, como podemos comprobar a continuaci√≥n:\nA partir de la definici√≥n del modelo tenemos la relaci√≥n:\n\\[\\theta = logistic(\\alpha + x \\beta) \\tag{4.4}\\]\nY a partir de la definici√≥n de la funci√≥n log√≠stica tenemos que $= 0.5 $, cuando el argumento de la regresi√≥n log√≠stica es 0, es decir:\n\\[0.5 = log√≠stica(\\alpha + x_i \\beta) \\Leftrightarrow 0 = \\alpha + x_i \\beta \\tag{4.5}\\]\nReordenando 4.5, encontramos que el valor de \\(x_i\\), para el cual, \\(\\theta = 0.5\\) corresponde a la expresi√≥n:\n\\[x_i = - \\frac{\\alpha}{\\beta} \\tag{4.6}\\]\nResumiendo los puntos m√°s importantes hasta el momento:\n\nEl valor de \\(\\theta\\) es, en t√©rminos generales, $p(y= 1 x) $. En este sentido, la regresi√≥n log√≠stica es en realidad una regresi√≥n, solo que estamos regresionando la probabilidad de que un punto de datos pertenezca a la clase 1, dada una combinaci√≥n lineal de caracter√≠sticas.\nEstamos modelando la media de una variable dicot√≥mica, es decir, un n√∫mero en el intervalo [0-1]. Luego, introducimos una regla para convertir esta probabilidad en una asignaci√≥n de dos clases. En este caso, si $p(y = 1) >= 0.5 $ asignamos clase 1, de lo contrario clase 0.\nNo hay nada especial en el valor 0.5, aparte de que es el n√∫mero en el medio entre 0 y 1. Podemos argumentar que este l√≠mite solo es razonable si estamos de acuerdo en cometer un error en una u otra direcci√≥n. En otras palabras, si es lo mismo para nosotros clasificar err√≥neamente una setosa como versicolor o una versicolor como setosa. Resulta que este no es siempre el caso, y el costo asociado a la clasificaci√≥n err√≥nea no tiene por qu√© ser sim√©trico, como recordar√°n del cap√≠tulo 2 cuando analizamos las funciones de p√©rdida."
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#el-l√≠mite-de-decisi√≥n",
    "href": "06_Generalizando_modelos_lineales.html#el-l√≠mite-de-decisi√≥n",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.1 El l√≠mite de decisi√≥n",
    "text": "8.1 El l√≠mite de decisi√≥n\nNo dudes en omitir esta secci√≥n y pasar directamente a la implementaci√≥n del modelo si no est√°s demasiado interesado en c√≥mo podemos obtener el l√≠mite de decisi√≥n.\nDesde el modelo, tenemos:\n\\[\\theta = log√≠stica(\\alpha + \\beta_1 x_1 + \\beta_2 x_2) \\tag{4.7}\\]\nY a partir de la definici√≥n de la funci√≥n log√≠stica, tenemos que \\(\\theta = 0.5\\), cuando el argumento de la regresi√≥n log√≠stica es cero, es decir:\n\\[ 0.5 = log√≠stica(\\alpha + \\beta_1x_1 + \\beta_2x_2) \\Leftrightarrow 0 = \\alpha + \\beta_1x_1 + \\beta_2x_2 \\tag {4.8}\\]\nReordenando, encontramos el valor de \\(x_2\\) para el cual \\(\\theta = 0.5\\) el cual corresponde a la expresi√≥n:\n\\[ x_2 = -\\frac{\\alpha}{\\beta_2} + \\left (-\\frac{\\beta_1}{\\beta_2} x_1 \\right) \\tag {4.9}\\]\nEsta expresi√≥n para el l√≠mite de decisi√≥n tiene la misma forma matem√°tica que la ecuaci√≥n de una l√≠nea, siendo el primer t√©rmino el intercepto y el segundo la pendiente. Los par√©ntesis se utilizan para mayor claridad y podemos omitirlos si queremos. Que el l√≠mite sea una l√≠nea es totalmente razonable, ¬øno es as√≠? Si tenemos una sola variable, tenemos datos unidimensionales y podemos dividirla en dos grupos usando un punto; si tenemos dos variables, tenemos un espacio de datos bidimensional y podemos separarlo usando una l√≠nea; para las tres dimensiones, el l√≠mite ser√° un plano y para dimensiones m√°s altas hablaremos gen√©ricamente acerca de los hiperplanos. Bueno, en realidad siempre podemos hablar de hyperplanos n-dimensionales."
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#implementando-el-modelo",
    "href": "06_Generalizando_modelos_lineales.html#implementando-el-modelo",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.2 Implementando el modelo",
    "text": "8.2 Implementando el modelo\nPara escribir el modelo de regresi√≥n log√≠stica m√∫ltiple utilizando PyMC, aprovechamos sus capacidades de vectorizaci√≥n, lo que nos permite introducir solo modificaciones menores respecto del modelo log√≠stico simple:\n\nwith pm.Model() as modelo_1: \n    Œ± = pm.Normal('Œ±', mu=0, sigma=10) \n    Œ≤ = pm.Normal('Œ≤', mu=0, sigma=2, shape=len(x_n)) \n     \n    Œº = Œ± + pm.math.dot(x_1, Œ≤) \n    Œ∏ = pm.Deterministic('Œ∏', pm.math.sigmoid(Œº)) \n    bd = pm.Deterministic('bd', -Œ±/Œ≤[1] - Œ≤[0]/Œ≤[1] * x_1[:,0])\n     \n    yl = pm.Bernoulli('yl', p=Œ∏, observed=y_1) \n \n    idata_1 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:10<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 10 seconds.\n\n\n\nvarnames = ['Œ±', 'Œ≤'] \naz.plot_forest(idata_1, var_names=varnames, figsize=(10, 3));\n\n\n\n\nComo hicimos para una √∫nica variable predictiva, vamos a graficar los datos y el l√≠mite de decisi√≥n.\n\n_, ax = plt.subplots(figsize=(10, 6))\n\nidx = np.argsort(x_1[:,0]) \n\nbd = idata_1.posterior['bd'].mean((\"chain\", \"draw\"))[idx] \nplt.scatter(x_1[:,0], x_1[:,1], c=[f'C{x}' for x in y_0]) \nplt.plot(x_1[:,0][idx], bd, color='k'); \n \naz.plot_hdi(x_1[:,0], idata_1.posterior['bd'], color=\"C8\")\n    \nax.set_xlabel(x_n[0]) \nax.set_ylabel(x_n[1]);\n\n\n\n\nEl l√≠mite de decisi√≥n es una l√≠nea recta, como ya hemos visto. No se confunda con el aspecto curvo de la banda del 94% de HDI. La curvatura aparente es el resultado de tener m√∫ltiples l√≠neas que giran alrededor de una regi√≥n central (aproximadamente alrededor de la media de x y la media de y)."
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#interpretaci√≥n-de-los-coeficientes-de-una-regresi√≥n-log√≠stica",
    "href": "06_Generalizando_modelos_lineales.html#interpretaci√≥n-de-los-coeficientes-de-una-regresi√≥n-log√≠stica",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.3 Interpretaci√≥n de los coeficientes de una regresi√≥n log√≠stica",
    "text": "8.3 Interpretaci√≥n de los coeficientes de una regresi√≥n log√≠stica\nDebemos tener cuidado al interpretar los coeficientes \\(\\beta\\) de una regresi√≥n log√≠stica. La interpretaci√≥n no es tan sencilla como con los modelos lineales en el cap√≠tulo anterior. La funci√≥n log√≠stica introduce una no linearidad, que debemos tener en cuenta. Si \\(\\beta\\) es positivo, aumentar \\(x\\) aumentar√° \\(p(y = 1)\\) en cierta cantidad, pero la cantidad no es una funci√≥n lineal de \\(x\\), es en cambio una funci√≥n no-lineal de \\(x\\). Podemos visualizar este hecho en la figura 4.4, en lugar de una l√≠nea con una pendiente constante, tenemos una l√≠nea en forma de S con una pendiente que cambia en funci√≥n de \\(x\\). Un poco de √°lgebra nos puede dar una idea de cu√°nto cambia \\(p(y=1)\\) con \\(\\beta\\):\nEl modelo log√≠stico b√°sico es:\n\\[\\theta = logistic (\\alpha + X \\beta) \\tag{4.11} \\]\nEl inverso de la log√≠stica es la funci√≥n logit, que es:\n\\[ logit(z) = log \\left (\\frac{z}{1-z} \\right) \\tag{4.12}\\]\nPor lo tanto, si tomamos la primera ecuaci√≥n en esta secci√≥n y aplicamos la funci√≥n logit a ambos t√©rminos, obtenemos:\n\\[ logit(\\theta) = \\alpha + X \\beta \\tag{4.13}\\]\nO equivalente:\n\\[ log \\left (\\frac{\\theta} {1-\\theta} \\right) = \\alpha + X \\beta \\tag {4.14}\\]\nRecuerden que \\(\\theta\\) en nuestro modelo era la probabilidad de $y = 1 $, por lo tanto:\n\\[ log \\left(\\frac {p(y = 1)} {1-p (y = 1)} \\right) = \\alpha + X \\beta \\tag {4.15} \\]\nLa cantidad \\[\\frac{p (y = 1)} {1-p (y = 1)}\\] se conoce como odds. Los odds a favor se definen como la relaci√≥n entre la probabilidad de √©xito y la probabilidad de no √©xito. Mientras que la probabilidad de obtener 2 tirando un dado es 1/6, los odds para el mismo evento son \\(\\frac{1/6}{5/6} \\simeq 0.2\\) o dicho de otra forma 1 evento favorable frente a 5 eventos desfavorables. Los odds suelen ser utilizadas por los apostadores ya que proporcionan una herramienta m√°s intuitiva que las probabilidades en bruto cuando se piensa en la forma correcta de apostar.\n\nEn una regresi√≥n log√≠stica, el coeficiente \\(\\beta\\) codifica el aumento en unidades de log-odds por unidad de aumento de la variable \\(x\\).\n\nLa transformaci√≥n de probabilidad a odds es una transformaci√≥n monot√≥nica, lo que significa que las probabilidades aumentan a medida que aumenta la probabilidad. Mientras que las probabilidades est√°n restringidas al intervalo \\([0, 1]\\), los odds viven en el intervalo \\([0, \\infty]\\). El logaritmo es otra transformaci√≥n mon√≥tonica y los log-odds est√°n en el intervalo \\([-\\infty, \\infty]\\). La figura 4.6 muestra c√≥mo la probabilidad est√° relacionada con los odds y los log-odds.\n\nprobability = np.linspace(0.01, 1, 100)\nodds = probability / (1 - probability)\n\n_, ax1 = plt.subplots()\nax2 = ax1.twinx()\nax1.plot(probability, odds, 'C0')\nax2.plot(probability, np.log(odds), 'C2')\n\nax1.set_xlabel('probabilidad')\nax1.set_ylabel('odds', color='C0')\nax2.set_ylabel('log-odds', color='C2');\n\n/tmp/ipykernel_16695/2677285095.py:2: RuntimeWarning: divide by zero encountered in divide\n  odds = probability / (1 - probability)\n\n\n\n\n\nPor lo tanto, los valores de los coeficientes proporcionados por summary est√°n en la escala log-odds.\n\ndf = az.summary(idata_1, var_names=['Œ±', 'Œ≤'])\ndf\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      Œ±\n      -9.019\n      4.745\n      -18.156\n      -0.685\n      0.089\n      0.066\n      2918.0\n      3083.0\n      1.0\n    \n    \n      Œ≤[0]\n      4.642\n      0.909\n      3.036\n      6.413\n      0.018\n      0.013\n      2672.0\n      2638.0\n      1.0\n    \n    \n      Œ≤[1]\n      -5.179\n      0.980\n      -6.955\n      -3.279\n      0.018\n      0.013\n      2907.0\n      2779.0\n      1.0\n    \n  \n\n\n\n\nUna forma muy emp√≠rica de entender los modelos es cambiar los par√°metros y ver qu√© sucede. En el siguiente bloque de c√≥digo, calculamos las log-odds en favor de versicolor como \\(\\text {log_odds_versicolor_i} = \\alpha + beta_1 x1 + \\beta_2 x2\\), y luego la probabilidad de versicolor con la funci√≥n log√≠stica. Luego repetimos el c√°lculo arreglando \\(x_2\\) y aumentando \\(x_1\\) en 1.\n\nx_1 = 4.5  # sepal_length\nx_2 = 3   # sepal_width\n\nlog_odds_versicolor_i = (df['mean'] * [1, x_1, x_2]).sum()\nprobability_versicolor_i = logistic(log_odds_versicolor_i)\n\n\nlog_odds_versicolor_f = (df['mean'] * [1, x_1 + 1, x_2]).sum()\nprobability_versicolor_f = logistic(log_odds_versicolor_f)\n\n(f'{log_odds_versicolor_f - log_odds_versicolor_i:.2f}', \n f'{probability_versicolor_f - probability_versicolor_i:.2f}')\n\n('4.64', '0.70')\n\n\nSi ejecutas el c√≥digo, encontrar√°s que el aumento en las log-odds es de \\(\\approx 4.7\\), que es exactamente el valor de \\(\\beta_0\\) (verifique el summary para trace_1). Esto est√° en l√≠nea con nuestro hallazgo anterior que muestra que los coeficientes \\(\\beta\\) indican el aumento en unidades log-odds por incremento unitario de la variable \\(x\\). El aumento en la probabilidad es \\(\\approx 0.70\\)."
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#trabajando-con-variables-correlacionadas",
    "href": "06_Generalizando_modelos_lineales.html#trabajando-con-variables-correlacionadas",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.4 Trabajando con variables correlacionadas",
    "text": "8.4 Trabajando con variables correlacionadas\nSabemos por el cap√≠tulo anterior que trabajar con variables muy correlacionadas puede traernos problemas. Las variables correlacionadas se traducen en combinaciones m√°s amplias de coeficientes que explican los datos o, desde el punto de vista complementario, variables correlacioadas tienen menos poder para restringir los modelos. Un problema similar ocurre cuando las clases se vuelven perfectamente separables, es decir, no hay superposici√≥n entre clases dada la combinaci√≥n lineal de variables en nuestro modelo. Podemos visualizar un ejemplo de esto al usar el conjunto de datos iris con el modelo_1, pero esta vez utilizando las variables ancho de p√©talo y largo de p√©talo. Encontraras que los coeficientes \\(\\beta\\) son m√°s amplios que antes y tambi√©n el 94% HDI (banda gris en la figura 4.5) es mucho m√°s amplia. La figura 4.7 muestra un heatmap para las variables sepal_length y sepal_width (usadas en el primer ejemplo) la correlaci√≥n no es tan alta como la correlaci√≥n entre las variables petal_length y petal_width (usada en el segundo ejemplo).\n\ncorr = iris[iris['species'] != 'virginica'].corr() \nmask = np.tri(*corr.shape).T \nsns.heatmap(corr.abs(), mask=mask, annot=True, cmap='viridis');\n\n\n\n\nPara generar la figura 4.7, hemos utilizado una m√°scara que elimina el tri√°ngulo superior y los elementos diagonales del heatmap, ya que estos son poco informativos o redundantes. Observe tambi√©n que hemos graficado el valor absoluto de la correlaci√≥n, ya que en este momento no nos importa el signo de la correlaci√≥n entre las variables, solo su fuerza.\nUna soluci√≥n cuando se trabaja con variables (altamente) correlacionadas, es simplemente eliminar una (o m√°s de una) de las variables correlacionadas. Otra opci√≥n es poner m√°s informaci√≥n en el a priori, esto se puede lograr con a prioris informativos si es que contamos con informaci√≥n previa √∫til, o m√°s general utilizando a prioris ligeramente informativos. Andrew Gelman y el equipo de Stan recomiendan usar el siguiente a priori al realizar una regresi√≥n log√≠stica:\n\\[ \\beta \\sim Student t (0, \\nu, sd) \\tag {4.10}\\]\ndonde sd se elije de forma que informe d√©bilmente sobre los valores esperados para la escala. Se sugiere que el par√°metro de normalidad \\(\\nu\\) sea alrededor de 3-7. Lo que dice este a priori es que esperamos que el coeficiente sea peque√±o, pero ponemos colas pesadas porque esto nos lleva a un modelo m√°s robusto que el uso de una distribuci√≥n gaussiana."
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#tratando-con-clases-desequilibradas",
    "href": "06_Generalizando_modelos_lineales.html#tratando-con-clases-desequilibradas",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.5 Tratando con clases desequilibradas",
    "text": "8.5 Tratando con clases desequilibradas\nEl conjunto de datos del iris est√° completamente equilibrado; en el sentido de que cada categor√≠a tiene exactamente el mismo n√∫mero de observaciones. Tenemos 50 setosas, 50 versicolores, y 50 virgininas. Por el contrario, muchos conjuntos de datos constan de datos no balanceados, es decir, hay muchos m√°s datos de una clase que de la otra. Cuando esto sucede, la regresi√≥n log√≠stica puede generar problemas, es decir, el l√≠mite no se puede determinar con la misma precisi√≥n que cuando el conjunto de datos est√° m√°s equilibrado.\nPara ver un ejemplo de este comportamiento, vamos a usar el conjunto de datos del iris y vamos a eliminar arbitrariamente algunos puntos de datos de la clase setosa:\n\ndf = iris.query(\"species == ('setosa', 'versicolor')\") \ndf = df[45:]  \ny_3 = pd.Categorical(df['species']).codes \nx_n = ['sepal_length', 'sepal_width'] \nx_3 = df[x_n].values\n\nY ahora ejecutamos una regresi√≥n log√≠stica m√∫ltiple, tal cual hicimos antes.\n\nwith pm.Model() as modelo_3: \n    Œ± = pm.Normal('Œ±', mu=0, sigma=10) \n    Œ≤ = pm.Normal('Œ≤', mu=0, sigma=2, shape=len(x_n)) \n     \n    Œº = Œ± + pm.math.dot(x_3, Œ≤) \n    Œ∏ = pm.math.sigmoid(Œº)\n    bd = pm.Deterministic('bd', -Œ±/Œ≤[1] - Œ≤[0]/Œ≤[1] * x_3[:,0]) \n     \n    yl = pm.Bernoulli('yl', p=Œ∏, observed=y_3) \n \n    idata_3 = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:05<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 6 seconds.\n\n\nEl l√≠mite de decisi√≥n se desplaza hacia la clase menos abundante y la incertidumbre es m√°s grande que antes. Este es el comportamiento t√≠pico de un modelo log√≠stico para datos no balanceados. ¬°Pero espera un minuto! Bien podr√≠as argumentar que te estoy enga√±ando ya que la mayor incertidumbre es en realidad el producto de tener menos datos y no solo menos setosas que versicolores. Este es un punto totalmente v√°lido, pero si realizas el ejercicio 2 podr√°s verificar que lo que explica esta gr√°fica son los datos desequilibrados.\n\nidx = np.argsort(x_3[:,0]) \nbd = idata_3.posterior['bd'].mean((\"chain\", \"draw\"))[idx] \nplt.scatter(x_3[:,0], x_3[:,1], c= [f'C{x}' for x in y_3]) \nplt.plot(x_3[:,0][idx], bd, color='C8'); \n \nbd_hdi = az.hdi(idata_3.posterior)['bd'][idx] \nplt.fill_between(x_3[:,0][idx], bd_hdi[:,0], bd_hdi[:,1], color='C8', alpha=0.5); \n \nplt.xlabel(x_n[0]) \nplt.ylabel(x_n[1]);\n\n\n\n\n¬øQu√© hacer si encontramos datos desequilibrados? Bueno, la soluci√≥n obvia es obtener un conjunto de datos con aproximadamente la misma cantidad por clase. Este es un punto a tener en cuenta al recopilar o generar los datos. Si no ten√©s control sobre el conjunto de datos, debes tener cuidado al interpretar los resultados para datos no balanceados. Verifique la incertidumbre del modelo y ejecute algunas verificaciones predictivas posteriores para ver si los resultados son √∫tiles para usted. Otra opci√≥n ser√≠a utilizar priors m√°s informativos y/o ejecutar un modelo alternativo como se explica m√°s adelante en este cap√≠tulo."
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#regresi√≥n-softmax-o-multinomial",
    "href": "06_Generalizando_modelos_lineales.html#regresi√≥n-softmax-o-multinomial",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.6 Regresi√≥n softmax (o multinomial)",
    "text": "8.6 Regresi√≥n softmax (o multinomial)\nUna forma de generalizar la regresi√≥n log√≠stica a m√°s de dos clases es con la regresi√≥n softmax. Necesitamos introducir 2 cambios con respecto a la regresi√≥n log√≠stica, primero reemplazamos la funci√≥n log√≠stica con la funci√≥n softmax:\n\\[softmax (\\mu_i) = \\frac {exp (\\mu_i)} {\\sum exp (\\mu_k)} \\tag{4.16}\\]\nEn palabras, para obtener la salida de la funci√≥n softmax para el i-esimo elemento de un vector \\(\\mu\\), tomamos la exponencial del valor i-esimo dividido por la suma de todos los valores del vector \\(\\mu\\) exponenciados.\nLa funci√≥n softmax garantiza que obtendremos valores positivos que suman 1. La funci√≥n softmax se reduce a la funci√≥n log√≠stica cuando \\(k=2\\). Como nota al margen, la funci√≥n softmax tiene la misma forma que la distribuci√≥n de Boltzmann, distribuci√≥n central en la mec√°nica estad√≠stica, una rama muy poderosa de la f√≠sica que se ocupa de la descripci√≥n probabil√≠stica de los sistemas at√≥micos y moleculares. La distribuci√≥n de Boltzmann (y a veces la funci√≥n softmax) incluye un par√°metro llamado temperatura (T) que divide \\(\\mu\\); cuando $ T $ la distribuci√≥n de probabilidad se vuelve plana y todos los estados son igualmente probables, y cuando \\(T \\rightarrow 0\\) solo se llena el estado m√°s probable y, por lo tanto, el softmax se comporta como la funci√≥n m√°ximo.\nEl segundo cambio en la regresi√≥n softmax es que reemplazamos la distribuci√≥n de Bernoulli por la distribuci√≥n categ√≥rica. La distribuci√≥n categ√≥rica es la generalizaci√≥n de Bernoulli a m√°s de dos resultados. Adem√°s, como la distribuci√≥n de Bernoulli (tirada de una sola moneda) es un caso especial de la Binomial (tiradas de \\(n\\) monedas), la categ√≥rica (tirada de un dado de \\(k\\) caras) es un caso especial de la distribuci√≥n multinomial (\\(n\\) tiradas de un dado de \\(k\\) caras).\nk-diagram\nPara ejemplificar la regresi√≥n de softmax, continuaremos trabajando con el conjunto de datos iris, solo que esta vez usaremos sus 3 clases (setosa, versicolor y virginica) y sus cuatro caracter√≠sticas (largo s√©palo, ancho s√©palo, longitud del p√©talo y ancho del p√©talo). Tambi√©n vamos a estandarizar los datos, ya que esto ayudar√° a que el sampler se ejecute de manera m√°s eficiente (tambi√©n podr√≠amos centrar los datos):\n\ny_s = pd.Categorical(iris['species']).codes\nx_n = iris.columns[:-1]\nx_s = iris[x_n].values\nx_s = (x_s - x_s.mean(axis=0)) / x_s.std(axis=0)\n\nEl c√≥digo de PyMC refleja los pocos cambios entre el modelo log√≠stico y el modelo softmax. Presta atenci√≥n a los valores de shape para los coeficientes $$ y \\(\\beta\\). En el siguiente c√≥digo usamos la funci√≥n softmax de Theano. Hemos utilizado la expresi√≥n import theano.tensor as tt, que es la convenci√≥n utilizada por los desarrolladores de PyMC:\n\nwith pm.Model() as modelo_s:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=5, shape=3)\n    Œ≤ = pm.Normal('Œ≤', mu=0, sigma=5, shape=(4,3))\n    Œº = pm.Deterministic('Œº', Œ± + pm.math.dot(x_s, Œ≤))\n    Œ∏ = pm.math.softmax(Œº)\n    yl = pm.Categorical('yl', p=Œ∏, observed=y_s)\n    idata_s = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:27<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 28 seconds.\n\n\n\naz.plot_forest(idata_s, var_names=['Œ±', 'Œ≤'], figsize=(10, 4), combined=True);\n\n\n\n\n¬øQu√© tan bien funciona nuestro modelo? Averig√ºemos cu√°ntos casos podemos predecir correctamente. En el siguiente c√≥digo, solo usamos la media de los par√°metros para calcular la probabilidad de que cada punto de datos pertenezca a cada una de las tres clases, luego asignamos la clase usando la funci√≥n argmax. Y comparamos el resultado con los valores observados:\n\ndata_pred = idata_s.posterior['Œº'].mean((\"chain\", \"draw\"))\n\ny_pred = [np.exp(point)/np.sum(np.exp(point), axis=0) for point in data_pred]\n\nf'{np.sum(y_s == np.argmax(y_pred, axis=1)) / len(y_s):.2f}'\n\n'0.95'\n\n\nEl resultado es que clasificamos correctamente \\(\\approx 95 \\%\\) de los datos. Ese es realmente un muy buen trabajo. Sin embargo, una verdadera prueba para evaluar el rendimiento de nuestro modelo ser√≠a verificarlo con un conjunto de datos no usado para ajustar al modelo. De lo contrario, es posible que estemos sobreestimando la capacidad real del modelo para generalizar a otros datos.\nEs posible que hayas notado que las distribuciones marginales de cada par√°metro son muy amplias. Este es el mismo problema de no identificabilidad que ya hemos encontrado para los datos correlacionados en otros modelos de regresi√≥n o con clases perfectamente separables. En este caso, el ancho posterior se debe a la condici√≥n de que todas las probabilidades deben sumar 1. Dada esta condici√≥n, estamos usando m√°s par√°metros de los que necesitamos para especificar completamente el modelo. En t√©rminos simples, si ten√©s 10 n√∫meros que suman 1, solo necesit√°s darme 9 de ellos; el otro puedo calcularlo. Esto es precisamente lo que est√° pasando con este problema. Una soluci√≥n es fijar los par√°metros extra a alg√∫n valor, por ejemplo, cero. El siguiente c√≥digo muestra c√≥mo lograr esto usando PyMC:\n\nwith pm.Model() as modelo_sf:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=2, shape=2)\n    Œ≤ = pm.Normal('Œ≤', mu=0, sigma=2, shape=(4,2))\n    Œ±_f = pm.math.concatenate([[0] ,Œ±])\n    Œ≤_f = pm.math.concatenate([np.zeros((4,1)) , Œ≤], axis=1)\n    Œº = Œ±_f + pm.math.dot(x_s, Œ≤_f)\n    Œ∏ = pm.math.softmax(Œº)\n    yl = pm.Categorical('yl', p=Œ∏, observed=y_s)\n    idata_sf = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:08<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 8 seconds.\n\n\n\naz.plot_forest(idata_sf, var_names=['Œ±', 'Œ≤'], figsize=(10, 3), combined=True);"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#linear-discriminant-analysis-lda",
    "href": "06_Generalizando_modelos_lineales.html#linear-discriminant-analysis-lda",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.7 Linear discriminant analysis (LDA)",
    "text": "8.7 Linear discriminant analysis (LDA)\nHasta ahora hemos discutido la regresi√≥n log√≠stica y algunas extensiones de la misma. En todos estos casos, calculamos $p(y x) $, es decir, la probabilidad que una clase \\(y\\) teniendo como dato una o m√°s variables \\(x\\), luego usamos un umbral o l√≠mite para convertir la probabilidad computada en un l√≠mite discreto lo que nos permite asignar clases.\nEste enfoque no es √∫nico. Una alternativa es modelar primero \\(p(x \\mid y)\\). No vamos a entrar en mucho detalle aqu√≠ sobre este tipo de modelos para clasificaci√≥n, pero vamos a ver un ejemplo que ilustra la idea central de este tipo de modelo. Lo haremos para dos clases y una sola variable, exactamente como el primer modelo que construimos en este cap√≠tulo, es m√°s usaremos los mismos datos.\nEn el siguiente c√≥digo se puede ver que ahora el l√≠mite de decisi√≥n se define como el promedio entre las medias de las Gaussianas. Este modelo es equivalente a lo que se conoce como an√°lisis discriminante lineal (Linear Discriminar Analysis).\n\nwith pm.Model() as modelo_lda:\n    Œº = pm.Normal('Œº', mu=0, sigma=10, shape=2)\n    œÉ = pm.HalfNormal('œÉ', 10)\n    setosa = pm.Normal('setosa', mu=Œº[0], sigma=œÉ, observed=x_0[:50])\n    versicolor = pm.Normal('versicolor', mu=Œº[1], sigma=œÉ, observed=x_0[50:])\n    bd = pm.Deterministic('bd', (Œº[0] + Œº[1]) / 2)\n    idata_lda = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œº, œÉ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n\n\nAhora vamos a generar una figura que muestra las dos clases (setosa = 0 yversicolor = 1) contra los valores de la longitud del s√©palo, y tambi√©n el l√≠mite de decisi√≥n como una l√≠nea turquesa y el intervalo del 94% de HDI como una banda turquesa semitransparente.\n\nplt.axvline(idata_lda.posterior['bd'].mean((\"chain\", \"draw\")), ymax=1, color='C1')\nbd_hdi = az.hdi(idata_lda.posterior)['bd'].values\nplt.fill_betweenx([0, 1], bd_hdi[0], bd_hdi[1], color='C1', alpha=0.5)\n\nplt.plot(x_0, np.random.normal(y_0, 0.02), '.', color='k')\nplt.ylabel('Œ∏', rotation=0)\nplt.xlabel('sepal_length');\n\n\n\n\nComo habr√° notado, la figura 4.9 es bastante similar a la figura 4.4. Verifique tambi√©n los valores de la decisi√≥n de l√≠mite en el siguiente summary:\n\naz.summary(idata_lda)\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      Œº[0]\n      5.005\n      0.064\n      4.889\n      5.133\n      0.001\n      0.001\n      6084.0\n      3292.0\n      1.0\n    \n    \n      Œº[1]\n      5.936\n      0.064\n      5.821\n      6.059\n      0.001\n      0.001\n      5652.0\n      3249.0\n      1.0\n    \n    \n      œÉ\n      0.447\n      0.032\n      0.392\n      0.510\n      0.000\n      0.000\n      5429.0\n      3241.0\n      1.0\n    \n    \n      bd\n      5.471\n      0.046\n      5.384\n      5.554\n      0.001\n      0.000\n      5770.0\n      2905.0\n      1.0\n    \n  \n\n\n\n\nTanto el modelo LDA como la regresi√≥n log√≠stica proporcionan resultados similares. El modelo discriminante lineal puede extenderse a m√°s de una caracter√≠stica al modelar las clases como Gaussianas multivariadas. Adem√°s, es posible relajar el supuesto de que las clases comparten una varianza com√∫n (o covarianza). Esto conduce a un modelo conocido como an√°lisis discriminante cuadr√°tico (QDA).\nEn general, los modelos LDA o QDA funcionar√°n mejor que una regresi√≥n log√≠stica cuando las caracter√≠sticas que estamos usando est√©n m√°s o menos distribuidas como Gaussianas y la regresi√≥n log√≠stica funcionar√° mejor en el caso contrario. Una ventaja de modelos como LDA y QDA (o generalizaciones de esta idea) es que puede ser m√°s f√°cil o m√°s natural incorporar informaci√≥n previa.\nEs importante tener en cuenta que los l√≠mites de decisi√≥n de LDA y QDA pueden ser calculados anal√≠ticamente y, por lo tanto, por lo general se calculan de esa manera. Para usar un LDA para dos clases y una caracter√≠stica, solo necesitamos calcular la media de cada distribuci√≥n y promediar esos dos valores, y obtenemos la decisi√≥n de los l√≠mites. En el modelo anterior, lo hicimos, pero con un giro Bayesiano. Estimamos los par√°metros de las dos Gaussianas y luego insertamos esas estimaciones en una f√≥rmula predefinida."
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#regresi√≥n-de-poisson",
    "href": "06_Generalizando_modelos_lineales.html#regresi√≥n-de-poisson",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.8 Regresi√≥n de Poisson",
    "text": "8.8 Regresi√≥n de Poisson\nOtro modelo lineal generalizado muy popular es la regresi√≥n de Poisson. Este modelo asume que los datos se distribuyen de acuerdo con la distribuci√≥n de Poisson.\nUn escenario en el que la distribuci√≥n de Poisson es √∫til es cuando se analizan cosas, como la descomposici√≥n de un n√∫cleo radioactivo, el n√∫mero de hijos por pareja o el n√∫mero de seguidores de Twitter. Lo que todos estos ejemplos tienen en com√∫n es que usualmente los modelamos usando n√∫meros discretos no negativos {0, 1, 2, 3 ‚Ä¶}. Este tipo de variable recibe el nombre de datos de conteo (count data).\n\n8.8.1 La distribuci√≥n de Poisson\nImagina que estamos contando la cantidad de autos rojos que pasan por una avenida por hora. Podr√≠amos usar la distribuci√≥n de Poisson para describir estos datos. La distribuci√≥n de Poisson se utiliza generalmente para describir la probabilidad que ocurra un n√∫mero determinado de eventos independientes entre si en un intervalo de tiempo o espacio fijo. Esta distribuci√≥n discreta se parametriza utilizando solo un valor, \\(\\mu\\) (la tasa, tambi√©n com√∫nmente representada con la letra griega \\(\\lambda\\)). \\(\\mu\\) corresponde a la media y tambi√©n a la varianza de la distribuci√≥n. La funci√≥n de probabilidad de masa de la distribuci√≥n de Poisson es:\n\\[ f(x \\mid \\mu) = \\frac {e^{-\\mu}\\mu^x} {x!} \\tag{4.17}\\]\nd√≥nde: * \\(\\mu\\) es el n√∫mero promedio de eventos por unidad de tiempo / espacio * \\(x\\) es un valor entero positivo 0, 1, 2, ‚Ä¶ * \\(x!\\) es el factorial de x, k! = k √ó (k - 1) √ó (k - 2) √ó ‚Ä¶ √ó 2 √ó 1\nEn la siguiente gr√°fica, podemos ver algunos ejemplos de la familia de distribuci√≥n de Poisson, para diferentes valores de \\(\\mu\\).\n\nmu_params = [0.5, 1.5, 3, 8]\nx = np.arange(0, max(mu_params) * 3)\nfor mu in mu_params:\n    y = pz.Poisson(mu).rv_frozen.pmf(x)\n    plt.plot(x, y, 'o-', label=f'Œº = {mu:3.1f}')\nplt.legend()\nplt.xlabel('x')\nplt.ylabel('f(x)');\n\n\n\n\nEs importante notar que \\(\\mu\\) puede ser un flotante, pero la distribuci√≥n modela probabilidad de un n√∫mero discreto de eventos. En la figura 4.10, los puntos representan los valores de la distribuci√≥n, mientras que las l√≠neas continuas son una ayuda visual que nos ayuda a comprender f√°cilmente la forma de la distribuci√≥n. Recuerde, la distribuci√≥n de Poisson es una distribuci√≥n discreta.\nLa distribuci√≥n de Poisson puede verse como un caso especial de la distribuci√≥n binomial cuando la cantidad de intentos \\(n\\) es muy grande pero la probabilidad de √©xito \\(p\\) es muy baja. Sin entrar en detalles matem√°ticos, tratemos de aclarar la afirmaci√≥n anterior. Siguiendo el ejemplo del auto, podemos afirmar que o vemos el auto rojo o no, por lo que podemos usar una distribuci√≥n binomial. En ese caso tenemos:\n\\[ x \\sim Bin(n, p) \\tag{4.18}\\]\nEntonces, la media de la distribuci√≥n binomial es:\n\\[\\mathbf{E}[x] = np \\tag{4.19} \\]\nY la varianza viene dada por:\n\\[ \\mathbf {V}[x] = np (1 - p) \\tag{4.20}\\]\nPero tenga en cuenta que incluso si se encuentra en una avenida muy transitada, la posibilidad de ver un auto rojo en comparaci√≥n con el n√∫mero total de autom√≥viles en una ciudad es muy peque√±o y, por lo tanto, tenemos:\n\\[n >> p \\Rightarrow np \\simeq np (1-p) \\tag{4.21}\\]\nEntonces, podemos hacer la siguiente aproximaci√≥n:\n\\[\\mathbf {V}[x] = np \\tag{4.22}\\]\nAhora la media y la varianza est√°n representadas por el mismo n√∫mero y podemos declarar con confianza que nuestra variable se distribuye como una distribuci√≥n de Poisson:\n\\[x \\sim Poisson(\\mu = np) \\tag{4.23}\\]"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#el-modelo-de-poisson-inflado-de-ceros",
    "href": "06_Generalizando_modelos_lineales.html#el-modelo-de-poisson-inflado-de-ceros",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.9 El modelo de Poisson inflado de ceros",
    "text": "8.9 El modelo de Poisson inflado de ceros\nAl contar cosas, una posibilidad es no contar esas cosas, es decir obtener cero. El n√∫mero cero puede ocurrir generalmente por muchas razones; obtuvimos un cero porque est√°bamos contando autos rojos y un auto rojo no pas√≥ por la avenida o porque no logramos verlo (tal vez no vimos pasar un diminuto auto rojo detr√°s de un gran cami√≥n). Entonces, si usamos una distribuci√≥n de Poisson, notaremos, por ejemplo, cuando realizamos una verificaci√≥n predictiva posterior, que el modelo gener√≥ menos ceros en comparaci√≥n con los datos.\n¬øC√≥mo arreglamos eso? Podemos tratar de abordar la causa exacta por la cual nuestro modelo predice menos ceros de los observados e incluir ese factor en el modelo. Sin embargo, suele ser el caso, que es suficiente y m√°s f√°cil para nuestro prop√≥sito, asumir que simplemente tenemos una mezcla de dos procesos:\n\nUno modelado por una distribuci√≥n de Poisson con probabilidad \\(\\psi\\)\nOtra persona que da ceros adicionales con probabilidad \\(1 - \\psi\\).\n\nEsto se conoce como modelo Poisson inflado de ceros (ZeroInflatedPoisson). En algunos textos, encontrar√°s que \\(\\psi\\) se usa para representar los ceros extra y \\(1-\\psi\\) la probabilidad de Poisson.\nB√°sicamente una distribuci√≥n ZIP nos dice que:\n\\[p(y_j = 0) = 1 - \\psi + (\\psi) e^{-\\mu} \\tag{4.24}\\]\n\\[p(y_j = k_i ) = \\psi \\frac{\\mu^x_i e^{-\\mu}}{x_i!} \\tag{4.25}\\]\nDonde \\(1-\\psi\\) es la probabilidad de ceros adicionales. Podr√≠amos implementar f√°cilmente estas ecuaciones en un modelo PyMC. Sin embargo, podemos hacer algo a√∫n m√°s f√°cil y usar la distribuci√≥n ZIP de PyMC.\n\n#np.random.seed(42)\nn = 100\nŒ∏_real = 2.5\nœà = 0.1\n\n# Simulate some data\ncounts = np.array([(np.random.random() > (1-œà)) * np.random.poisson(Œ∏_real)\n                   for i in range(n)])\n\n\nwith pm.Model() as ZIP:\n    œà = pm.Beta('œà', 1., 1.)\n    Œ∏ = pm.Gamma('Œ∏', 2., 0.1)\n    y = pm.ZeroInflatedPoisson('y', œà, Œ∏, observed=counts)\n    idata = pm.sample(1000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [œà, Œ∏]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\naz.plot_trace(idata);\n\n\n\n\n\naz.summary(idata)\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      œà\n      0.131\n      0.037\n      0.069\n      0.202\n      0.001\n      0.000\n      3599.0\n      2480.0\n      1.0\n    \n    \n      Œ∏\n      2.445\n      0.506\n      1.473\n      3.369\n      0.008\n      0.006\n      3714.0\n      2602.0\n      1.0"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#regresi√≥n-de-poisson-y-regresi√≥n-zip",
    "href": "06_Generalizando_modelos_lineales.html#regresi√≥n-de-poisson-y-regresi√≥n-zip",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.10 Regresi√≥n de Poisson y regresi√≥n ZIP",
    "text": "8.10 Regresi√≥n de Poisson y regresi√≥n ZIP\nEl modelo ZIP puede parecer un poco aburrido, pero a veces necesitamos estimar distribuciones simples como esta u otra como las distribuciones de Poisson o Gaussianas. Adem√°s, podemos usar las distribuciones Poisson o ZIP como parte de un modelo lineal. Como vimos con la regresi√≥n log√≠stica (y softmax) podemos usar una funci√≥n de enlace inverso para transformar el resultado de un modelo lineal en una variable adecuada para ser utilizada con otra distribuci√≥n que no sea la normal. En la siguiente figura, vemos una posible implementaci√≥n de una regresi√≥n ZIP. La regresi√≥n de Poisson ser√° similar, pero sin la necesidad de incluir \\(\\phi\\) ya que no modelaremos un exceso de ceros. Observe que ahora usamos la funci√≥n exponencial como la funci√≥n de enlace inverso. Esta elecci√≥n garantiza que los valores devueltos por el modelo lineal sean positivos.\nPara ejemplificar la implementaci√≥n de un modelo de regresi√≥n ZIP, vamos a trabajar con un conjunto de datos tomado del Instituto de Investigaci√≥n y Educaci√≥n Digital.\nEl problema es el siguiente: trabajamos en la administraci√≥n de un parque y queremos mejorar la experiencia de los visitantes. Por lo tanto, decidimos realizar una breve encuesta a 250 grupos que visitan el parque. Parte de los datos que recopilamos (a nivel de grupo) consiste en:\n\nLa cantidad de peces que capturaron (contar)\nCu√°ntos ni√±os hab√≠a en el grupo (ni√±o)\nYa sea que hayan tra√≠do o no una casa-rodante o ‚Äúcaravana‚Äù al parque (camper).\n\nUsando estos datos, vamos a construir un modelo que predice el n√∫mero de peces capturados en funci√≥n de las variables ni√±o y caravana. Podemos usar Pandas para cargar los datos:\n\nfish_data = pd.read_csv('datos/fish.csv')\n\nLo dejo como un ejercicio para que explore el conjunto de datos utilizando gr√°ficos y / o una funci√≥n de Pandas, como describe(). Por ahora vamos a continuar traduciendo el diagrama de Kruschke anterior a PyMC3:\n\nwith pm.Model() as ZIP_reg:\n    œà = pm.Beta('œà', 1, 1)\n    Œ± = pm.Normal('Œ±', 0, 10)\n    Œ≤ = pm.Normal('Œ≤', 0, 10, shape=2)\n    Œ∏ = pm.math.exp(Œ± + Œ≤[0] * fish_data['child'] + Œ≤[1] * fish_data['camper'])\n    yl = pm.ZeroInflatedPoisson('yl', œà, Œ∏, observed=fish_data['count'])\n    idata_ZIP_reg = pm.sample()\naz.plot_trace(idata_ZIP_reg);\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [œà, Œ±, Œ≤]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\n\n\n\nPara entender mejor los resultados de nuestra inferencia, hagamos una gr√°fica.\n\nchildren = [0, 1, 2, 3, 4]\nfish_count_pred_0 = []\nfish_count_pred_1 = []\n\npost_ZIP_reg = az.extract(idata_ZIP_reg)\n\nfor n in children:\n    without_camper = post_ZIP_reg['Œ±'] + post_ZIP_reg['Œ≤'].sel({\"Œ≤_dim_0\":0}) * n\n    with_camper = without_camper + post_ZIP_reg['Œ≤'].sel({\"Œ≤_dim_0\":1})\n    fish_count_pred_0.append(np.exp(without_camper))\n    fish_count_pred_1.append(np.exp(with_camper))\nplt.plot(children, fish_count_pred_0, 'C0.', alpha=0.01)\nplt.plot(children, fish_count_pred_1, 'C1.', alpha=0.01)\n\n    \nplt.xticks(children);\nplt.xlabel('Number of children')\nplt.ylabel('Fish caught')\nplt.plot([], 'C0o', label='without camper')\nplt.plot([], 'C1o', label='with camper')\nplt.legend();"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#regresi√≥n-por-cuantiles",
    "href": "06_Generalizando_modelos_lineales.html#regresi√≥n-por-cuantiles",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.11 Regresi√≥n por cuantiles",
    "text": "8.11 Regresi√≥n por cuantiles\nEn los ejemplos anteriores nos focalizamos en usar un modelo lineal para estimar la media de la variable respuesta, condicionada a una o m√°s covariables. Quiz√° el caso m√°s com√∫n sea usar la distribuci√≥n Normal. Pero aprendimos que podemos aplicar la misma idea cambiando la distribuci√≥n por otras como la Poisson, binomial, etc, seg√∫n nuestras necesidades.\nLa regresi√≥n por cuantiles consiste en utilizar un modelo lineal para estimar un cuantil. Cuando el cuantil a estimar es la mediana, la motivaci√≥n suele ser la necesidad de una regresi√≥n robusta. En ese caso la regresi√≥n por cuantiles cumplir√≠a una funci√≥n similar al modelo robusto donde reemplazamos la Gaussiana por una distribuci√≥n t de Student. Otras veces la motivaci√≥n surge del inter√©s en modelar relaciones entre variables cuando no hay relaci√≥n entre las medias de dichas variables, o cuando esta es muy debil. Una disciplina donde las regresiones por cuantiles son frecuentes es la ecolog√≠a. Esto se debe posiblemente, a que la existencia de complejas interacciones entre variables, donde el efecto de una variable sobre otra es distinto para distintos rangos de la variable.\n\nx = np.linspace(-6, 6, 2000)\nquantiles =  np.array([0.2, 0.5, 0.8])\nkappas = (quantiles/(1-quantiles))**0.5\nfor q, m in zip(quantiles, [0, 0, -1]):\n    Œ∫ = (q/(1-q))**0.5\n    plt.plot(x, stats.laplace_asymmetric(Œ∫, m, 1).pdf(x), label=f\"q={q:}, Œº={m}, œÉ=1\")\nplt.yticks([]);\nplt.legend();\n\n\n\n\n\nquantiles = np.array([0.05, 0.5, 0.95])\nŒ∫ = (quantiles/(1-quantiles))**0.5\n\ny_con = np.stack([data.Longitud.values]* 3).T\nx_con = np.stack([data.Meses.values]* 3).T\n\n\nwith pm.Model() as model_q:\n    Œ± = pm.Normal('Œ±', 50, 3, shape=3)\n    Œ≤ = pm.Normal('Œ≤', 0, 5, shape=3)\n    œÉ = pm.HalfNormal('œÉ', 5)\n\n    Œº = pm.Deterministic('Œº', Œ± + Œ≤ * x_con**0.5)\n    \n    y_pred = pm.AsymmetricLaplace('y_pred',  Œ∫, Œº, œÉ, observed=y_con)\n    \n    idata_q = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤, œÉ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:11<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 11 seconds.\n\n\n\naz.summary(idata_q, var_names=\"~Œº\")\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      Œ±[0]\n      45.402\n      0.230\n      44.963\n      45.833\n      0.006\n      0.004\n      1727.0\n      1965.0\n      1.0\n    \n    \n      Œ±[1]\n      47.954\n      0.229\n      47.504\n      48.360\n      0.005\n      0.004\n      1774.0\n      1965.0\n      1.0\n    \n    \n      Œ±[2]\n      52.390\n      0.185\n      52.092\n      52.763\n      0.005\n      0.003\n      1557.0\n      1939.0\n      1.0\n    \n    \n      Œ≤[0]\n      6.658\n      0.082\n      6.517\n      6.817\n      0.002\n      0.001\n      1713.0\n      2111.0\n      1.0\n    \n    \n      Œ≤[1]\n      7.895\n      0.078\n      7.739\n      8.035\n      0.002\n      0.001\n      1706.0\n      1849.0\n      1.0\n    \n    \n      Œ≤[2]\n      8.825\n      0.059\n      8.714\n      8.942\n      0.002\n      0.001\n      1530.0\n      1718.0\n      1.0\n    \n    \n      œÉ\n      0.548\n      0.011\n      0.528\n      0.568\n      0.000\n      0.000\n      2661.0\n      2451.0\n      1.0\n    \n  \n\n\n\n\n\nplt.plot(data.Meses, data.Longitud, \"k.\")\nfor idx, label in enumerate((\"q=0.1\", \"q=0.5\", \"q=0.9\")):\n    plt.plot(data.Meses.values, idata_q.posterior[\"Œº\"].mean((\"chain\", \"draw\"))[:,idx],\n            label=label, lw=3);\n    \nplt.legend();\n\n\n\n\n\nwith pm.Model() as model_n:\n    Œ± = pm.Normal('Œ±', 50, 3)\n    Œ≤ = pm.Normal('Œ≤', 0, 5)\n    œÉ = pm.HalfNormal('œÉ', 5)\n\n    Œº = pm.Deterministic('Œº', Œ± + Œ≤ * data.Meses.values**0.5)\n    \n    y_pred = pm.Normal('y_pred',  Œº, œÉ, observed=data.Longitud.values)\n    \n    idata_n = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤, œÉ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\nplt.plot(data.Meses, data.Longitud, \".\", color=\"0.8\")\nfor idx, label in enumerate([f\"{q=:}\" for q in quantiles]):\n    plt.plot(data.Meses.values, idata_q.posterior[\"Œº\"].mean((\"chain\", \"draw\"))[:,idx],\n            label=label);\n    \nplt.legend();\n\nup = (idata_n.posterior[\"Œº\"] + idata_n.posterior[\"œÉ\"]*1.65).mean((\"chain\", \"draw\"))\ndown = (idata_n.posterior[\"Œº\"] - idata_n.posterior[\"œÉ\"]*1.65).mean((\"chain\", \"draw\"))\n\nplt.plot(data.Meses.values, down, \"C0\", label=\"Œº - 1.65œÉ\", ls=\"--\");\nplt.plot(data.Meses.values, idata_n.posterior[\"Œº\"].mean((\"chain\", \"draw\")), \"C1\", label=\"Œº\",ls=\"--\");\nplt.plot(data.Meses.values, up, \"C2\", label=\"Œº + 1.65œÉ\", ls=\"--\");\n\n\nplt.legend();"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#resumen",
    "href": "06_Generalizando_modelos_lineales.html#resumen",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.12 Resumen",
    "text": "8.12 Resumen"
  },
  {
    "objectID": "06_Generalizando_modelos_lineales.html#ejercicios",
    "href": "06_Generalizando_modelos_lineales.html#ejercicios",
    "title": "7¬† Generalizando modelos lineales",
    "section": "8.13 Ejercicios",
    "text": "8.13 Ejercicios\n\nEs conocido que para muchas especies el peso no escala con la altura/longitud, pero si lo hace con el logaritmo de peso. Use esa informaci√≥n para ajustar el conjunto de datos howell (sin distinci√≥n por edad). Repita el ajuste usando un polinomio de grado 2. Explique y compare ambos resultados.\nVuelva a correr el modelo_0 pero esta vez usando las variables petal_length y petal_width ¬øEn que difieren los resultados? ¬øCu√°n ancho o angosto es el intervalo HDI 94%?\nRepita el ejercicio 1, esta vez usando una distribuci√≥n t de Student como prior ligeramente informativo. Pruebe con distintos valores de \\(\\nu\\).\nUse un modelo lineal (como los vistos en el cap√≠tulo anterior) para clasificar setosa o versicolor en funci√≥n de sepal_length. ¬øCu√°n √∫til es este modelo comparado con una regresi√≥n log√≠stica?\nEn la secci√≥n Interpretando los coeficientes de una regresion log√≠stica vimos el efecto sobre el log_odds de cambiar la variable sepal_length en 1 unidad. Usando la figura 4.6 corrobore que el valor obtenido para log_odds_versicolor_i se corresponde con el valor de probability_versicolor_i. Haga lo mismo para log_odds_versicolor_f y probability_versicolor_f. Si solo sabemos que el valor de log_odds_versicolor es negativo que podemos decir de la probabilidad de versicolor, use la figura 4.6 como gu√≠a ¬øEs este resultado evidente de la definici√≥n de log-odds?\nPara modelo_1 verifica cuanto cambian el valor de log-odd al incrementar sepal_leght de 5.5 a 6.5. ¬øC√∫al es el cambio en valores de probabilidad? ¬øCu√°l es el cambio en t√©rminos de log-odds y probabilidad al pasar de 4.5 a 5.5?\nEn el ejemplo de clases desbalanceadas cambie df = df[45:] por df = df[22:78]. Esto dejar√° m√°s o menos el mismo n√∫mero de datos, pero con las clases balanceadas. Compare con los resultados previos. ¬øCu√°l caso es m√°s parecido a usar el conjunto de datos completo?\nSuponga que en vez de usar una regresi√≥n softmax usamos un modelo lineal simple codificando \\(\\text{setosa}=0\\), \\(\\text{versicolor}=1\\) y \\(\\text{virginica}=1\\). Bajo el modelo lineal simple que pasar√≠a si cambi√°ramos el orden del c√≥digo.\nCompara los likelihoods para el modelo_0 y para el modelo_lda. Usa la funci√≥n pm.sample_posterior_predictive para generar datos a partir de estos dos modelos. ¬øEn que difirien los datos predichos para ambos modelos?\nExtienda el modelo ZIP_reg para incluir la variable persons. Usa esta variable para modelar el n√∫mero de ceros extra. Deber√°s obtener un modelo que incluya dos modelos lineales, uno que conecte las variables children y camper a la tasa de Poisson y otro que conecte el n√∫mero de personas con la variable \\(\\psi\\). Presta atenci√≥n si es necesario usar una funci√≥n inversa de enlace.\nUse los datos empleados en el ejemplo de la regresi√≥n log√≠stica robusta con un modelo de regresi√≥n log√≠stica simple. ¬øCu√°l es el efecto de los outliers? Pruebe agregando o eliminado outliers."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html",
    "href": "07_Comparaci√≥n_de_modelos.html",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "",
    "text": "9 La navaja de Occam: simplicidad y exactitud\nAl elegir entre explicaciones alternativas, existe un principio conocido como la navaja de Occam que establece de manera general que si tenemos dos o m√°s explicaciones equivalentes para el mismo fen√≥meno, debemos elegir la m√°s simple.\nHay muchas justificaciones para esta heur√≠stica; una de ellas est√° relacionada con el criterio de falsabilidad introducido por Popper, otra tiene una perspectiva m√°s pragm√°tica y afirma que, dado que los modelos m√°s simples son m√°s f√°ciles de entender que los modelos m√°s complejos, es conveniente quedarse con el m√°s simple. Otra justificaci√≥n se basa en propia estad√≠sticas Bayesiana, como veremos cuando analicemos los Factores de Bayes. Sin entrar en los detalles de estas justificaciones, vamos a aceptar este criterio como una regla √∫til por el momento, simplemente algo que suena como una gu√≠a razonable.\nOtro factor que generalmente debemos tener en cuenta al comparar modelos es su exactitud, es decir, qu√© tan bueno es un modelo ajustando los datos. Un cantidad comunmente usada en regresi√≥n es el coeficiente de determinaci√≥n R¬≤, que podemos interpretar como la proporci√≥n de varianza explicada en una regresi√≥n lineal. En la secci√≥n anterior vimos algunos ejemplos de pruebas predictivas a posteriori a modo de evaluaci√≥n de cual modelo ajusta mejor los datos. En definitiva, si tenemos dos (o m√°s) modelos y uno de ellos explica los datos mejor que el otro, deber√≠amos preferir ese modelo, es decir, queremos el modelo con mayor exactitud ¬øVerdad?\nIntuitivamente, parece que al comparar modelos, tendemos a preferir aquellos que mejor ajusten los datos y aquellos que sean m√°s simples. Hasta ahora todo bien, pero ¬øQu√© hacemos si el modelo m√°s simple es el peor ajustando los datos? O de forma m√°s general, ¬øC√≥mo balancear ambas contribuciones?"
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#pruebas-predictivas-a-posteriori",
    "href": "07_Comparaci√≥n_de_modelos.html#pruebas-predictivas-a-posteriori",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "8.1 Pruebas predictivas a posteriori",
    "text": "8.1 Pruebas predictivas a posteriori\nPreviamente hemos presentado y discutido las pruebas predictivas a posteriori como una forma de evaluar qu√© tan bien los modelos explican los mismos datos que se usan para ajustar al modelo. El prop√≥sito de este tipo de pruebas no es el de dictaminar que un modelo es incorrecto; ¬°Esto ya lo sabemos! El objetivo del ejercicio es comprender qu√© tan bien estamos capturando los datos. Es frecuente que capturemos diferentes aspectos de los datos de diferentes maneras. Al realizar pruebas predictivas a posteriori, esperamos comprender mejor las limitaciones de un modelo, ya sea para tenerlas en cuenta o para intentar mejorar el modelo. Es esperable que un modelo no sea capaz de reproducir todos los aspectos de un problema y, por lo general, esto no es un problema ya que los modelos se construyen con un prop√≥sito en mente. Una prueba predictiva a posteriori es una forma de evaluar ese prop√≥sito, por lo tanto, si tenemos m√°s de un modelo, podemos compararlos mediante pruebas predictivas a posteriori.\nComo ya vimos, las pruebas predictivas a posteriori a menudo se realizan mediante visualizaciones como en el siguiente ejemplo:\n\ndummy_data = np.loadtxt('datos/dummy.csv')\nx_1 = dummy_data[:,0]\ny_1 = dummy_data[:,1]\n\norder = 2\nx_1p = np.vstack([x_1**i for i in range(1, order+1)])\nx_1s = (x_1p - x_1p.mean(axis=1, keepdims=True)) / x_1p.std(axis=1, keepdims=True)\ny_1s = (y_1 - y_1.mean()) / y_1.std()\nplt.scatter(x_1s[0], y_1s)\nplt.xlabel('x')\nplt.ylabel('y');\n\n\n\n\nAhora, vamos a ajustar estos datos con dos modelos ligeramente diferentes, uno lineal y el otro un polinomio de orden 2, tambi√©n conocido como modelo parab√≥lico o cuadr√°tico:\n\nwith pm.Model() as model_l:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=1)\n    Œ≤ = pm.Normal('Œ≤', mu=0, sigma=10)\n    œµ = pm.HalfNormal('œµ', 5)\n\n    Œº = Œ± + Œ≤ * x_1s[0]\n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y_1s)\n\n    idata_l = pm.sample(2000, idata_kwargs={\"log_likelihood\": True})\n    idata_l.extend(pm.sample_posterior_predictive(idata_l))\n\nwith pm.Model() as model_p:\n    Œ± = pm.Normal('Œ±', mu=0, sigma=1)\n    Œ≤ = pm.Normal('Œ≤', mu=0, sigma=10, shape=order)\n    œµ = pm.HalfNormal('œµ', 5)\n\n    Œº = Œ± + pm.math.dot(Œ≤, x_1s)\n    \n    y_pred = pm.Normal('y_pred', mu=Œº, sigma=œµ, observed=y_1s)\n\n    idata_p = pm.sample(2000, idata_kwargs={\"log_likelihood\": True})\n    idata_p.extend(pm.sample_posterior_predictive(idata_p))\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:05<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 5 seconds.\nSampling: [y_pred]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00<00:00]\n    \n    \n\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Œ±, Œ≤, œµ]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:08<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 9 seconds.\nSampling: [y_pred]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00<00:00]\n    \n    \n\n\nAhora, vamos a visualizar el ajuste para ambos modelos:\n\nx_new = np.linspace(x_1s[0].min(), x_1s[0].max(), 100)\n\nposterior_l = az.extract(idata_l)\nposterior_p = az.extract(idata_p)\n\nŒ±_l_post = posterior_l['Œ±'].mean().item()\nŒ≤_l_post = posterior_l['Œ≤'].mean().item()\ny_l_post = Œ±_l_post + Œ≤_l_post *  x_new\n\nplt.plot(x_new, y_l_post, 'C0', label='modelo lineal')\n\nŒ±_p_post = posterior_p['Œ±'].mean().item()\nŒ≤_p_post = posterior_p['Œ≤'].mean(\"sample\")\nidx = np.argsort(x_1s[0])\ny_p_post = Œ±_p_post + np.dot(Œ≤_p_post, x_1s)\n\nplt.plot(x_1s[0][idx], y_p_post[idx], 'C1', label=f'polinomio de orden {order}')\n\nplt.plot(x_1s[0], y_1s, \"k.\")\nplt.legend();\n\n\n\n\nEl modelo de orden 2 parece estar haciendo un mejor trabajo, pero el modelo lineal no es tan malo. Veamos un prueba predictiva a posteriori\n\n_, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\naz.plot_ppc(idata_l, num_pp_samples=100, ax=axes[0], legend=False)\naxes[0].set_title('modelo lineal')\naz.plot_ppc(idata_p, num_pp_samples=100, ax=axes[1]);\naxes[1].set_title(f'polinomio de orden {order}');\n\n\n\n\nEn vez de comparar directamente la distribuci√≥n de datos observados versus la distribuci√≥n predicha podemos comparar estad√≠sticos sumarios.\nEn el panel superior de la siguiente figura se muestra 2 KDEs, representando la distribuci√≥n de las medias predichas por los modelos. El punto sobre eje x indica el valor observado.\nEn el segundo panel lo mismo pero para el rango intercuartil.\n\nfig, axes = plt.subplots(2, 1, figsize=(12, 8), sharey=\"row\")\ncolors = [\"C0\", \"C1\"]\ntitles = [\"mediana\", \"rango intercuartil\"]\nmodelos = [\"lineal\", f'orden {order}']\nidatas = [idata_l, idata_p]\n\ndef iqr(x, a=-1):\n    return np.subtract(*np.percentile(x, [75, 25], axis=a))\n\nfor idata, c in zip(idatas, colors):\n    az.plot_bpv(idata, kind=\"t_stat\", t_stat=\"mean\", ax=axes[0], color=c)\n    \n\nfor idata, c in zip(idatas, colors):\n    az.plot_bpv(idata, kind=\"t_stat\", t_stat=iqr, ax=axes[1], color=c)\n\nfor ax, title, in zip(axes, titles):\n    ax.set_title(title)\n    for idx, (c, modelo) in enumerate(zip(colors, modelos)):\n        ax.legend_.legendHandles[idx]._alpha = 1\n        ax.legend_.legendHandles[idx]._color = c\n        ax.legend_._loc = 1\n        ax.legend_.texts[idx]._text = modelo + \" \" + ax.legend_.texts[idx]._text\n\n\n\n\nEn la figura anterior tambi√©n se incluyen unos valores llamados bpv, Bayesian p-value. Los bpv son una forma num√©rica de resumir una comparaci√≥n entre datos simulados y datos reales. Para obtenerlos se elige un estad√≠stico sumario, como por ejemplo la mediana, el cual es calculado tanto para los datos como para las simulaciones. Luego contamos la cantidad de veces que el estad√≠stico predicho es igual o mayor al calculado a partir de los datos observados. Si los valores observado y concuerdan con los predichos, deber√≠amos esperar un valor p de 0.5. Es decir la mitad de las predicciones est√°n por debajo y la mitad por encima de lo observado. Caso contrario, estamos en presencia de una distribuci√≥n predictiva a posteriori sesgada.\nSi est√°s familiarizado con los m√©todos frecuentistas es posible que ya conozcas el concepto de valor p. Adem√°s es posible que hayas escuchado que en estad√≠stica Bayesiana no se usan valores p. Por lo que este ejemplo puede generarte confusi√≥n. Veamos que est√° pasando. Estos bpv son efectivame valores p ya que se definen de como:\n\\[\\text{Bayesian p-value } \\triangleq p(T_{\\mathcal{sim}} \\le T_{\\mathcal{obs}} ) \\mid \\hat y)\\]\nEs decir, queremos estimar la probabilidad de obtener un estad√≠stico \\(T_{sim}\\), a partir de las simulaciones, que sea igual o menor que la de obtener un valor de estad√≠sitco \\(T_{obs}\\) a partir de los datos. En principio \\(T\\) puede ser casi cualquier cantidad derivada de los datos. En la figura anterior \\(T\\) es la mediana (panel superior) o el rango interquartil (panel inferior). En este ejemplo es razonable que la media de bien por que precisamente el modelo lineal est√° construido para capturar la media. Si en vez de graficar la media, evaluaramos la mediana, veriamos diferencias algo m√°s grandes. En general un estad√≠stico que sea ortogonal a lo que el modelo ajusta de forma directa ser√° m√°s informativo. Ante la duda puede ser conveniente evaluar m√°s de un estad√≠stico. En general es √∫til preguntarse que aspectos de los datos nos interesa capturar mejor.\nLo Bayesiano de estos valores p es que NO estamos usando una distribuci√≥n de muestreo sino la distribuci√≥n predictiva a posteriori. Adem√°s NO estamos asumiendo ninguna hip√≥tesis nula para calcular el valor p.¬†En cambio, estamos, permitiendo que los par√°metros var√≠en de acuerdo con el modelo y los datos. Otra diferencia es que no estamos usando ning√∫n m√©todo predefinido para declarar significaci√≥n estad√≠stica, ni estamos realizando pruebas de hip√≥tesis.\nOtra forma de usar los bvp, es preguntarse para cada valor observado, cual es la probabilidad de predecir un valor menor o igual\n\\[p(\\tilde y_i  \\le y_i \\mid y_i)\\]\nSi el modelo est√° bien calibrado la probabilidad deber√≠a ser la misma para todos los valores no importan si estos son altos, bajos, en las colas en el seno de la distribuci√≥n etc. Es decir esperar√≠amos ver una distribuci√≥n uniforme.\nSiguiedo esta idea, en la siguiente figura se muestra una gr√°fica que muestra la distribuci√≥nes para el modelo lineal y el de order 2. La linea blanca indica la distribuci√≥n uniforme esperada y la banda gris indica las desviaciones esperadas dado el tama√±o finito de la muestra observada.\n\nfig, ax = plt.subplots(figsize=(10, 3))\n\nfor idata, c in zip(idatas, colors):\n    az.plot_bpv(idata, color=c, ax=ax)\n\n\n\n\nLas pruebas predictivas a posteriori, ya sea utilizando gr√°ficos o res√∫menes num√©ricos como los valores p bayesianos, o incluso una combinaci√≥n de ambos son ideas muy flexibles. El concepto es lo suficientemente general para permitir que una analista use su imaginaci√≥n para encontrar diferentes formas de explorar la distribuci√≥n predictiva a posteriori y use las que mejor se ajusten a los fines de poder interpretar los datos y modelos.\nEn las siguientes secciones vamos a explorar otros m√©todos para comparar modelos."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#muchos-par√°metros-pueden-conducir-a-sobreajuste",
    "href": "07_Comparaci√≥n_de_modelos.html#muchos-par√°metros-pueden-conducir-a-sobreajuste",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.1 Muchos par√°metros (pueden) conducir a sobreajuste",
    "text": "9.1 Muchos par√°metros (pueden) conducir a sobreajuste\nVamos a comenzar por combinar polinomios cada vez m√°s complejos en un conjunto de datos muy simple. En lugar de utilizar la maquinaria Bayesiana, usaremos la aproximaci√≥n de m√≠nimos cuadrados para ajustar modelos lineales. Recuerde que este √∫ltimo se puede interpretar desde una perspectiva Bayesiana como un modelo con a prioris planos. Entonces, en cierto sentido, seguimos siendo Bayesianos solo que estamos tomando un atajo ;-)\n\n_, ax = plt.subplots(1, 1, figsize=(12, 4))\n\n\nx0 = np.array([4., 5., 6., 9., 12, 14.])\ny0 = np.array([4.2, 6.1, 5., 10., 10, 14.])\n\norder = [0, 1, 5]\nax.plot(x0, y0, 'ko', zorder=3)\n\n\nax.set_yticks([])\nax.set_xticks([])\n\nx_n = np.linspace(x0.min(), x0.max(), 100)\nps = []\nfor i in order:\n    p = np.polynomial.Polynomial.fit(x0, y0, deg=i)\n    ps.append(p)\n    yhat = p(x0)\n    ybar = np.mean(y0)\n    ss_regression = np.sum((yhat-y0)**2)\n    ss_total = np.sum((ybar-y0)**2)\n    r2 = 1 - ss_regression / ss_total\n    ax.plot(x_n, p(x_n), label=f'orden {i}, $R^2$= {r2:.3f}')\n\n    \nax.legend(loc=2, fontsize=12);\n\n\n\n\nDe la figura anterior podemos ver que el aumento de la complejidad del modelo se acompa√±a de una mayor exactitud reflejada en el coeficiente de determinaci√≥n R¬≤. De hecho, podemos ver que el polinomio de orden 5 se ajusta perfectamente a los datos, obteniendo un R¬≤=1.\n¬øPor qu√© el polinomio de grado 5 puede capturar los datos sin perder uno solo de ellos? La raz√≥n es que tenemos el mismo n√∫mero de par√°metros que de datos es decir 6. Por lo tanto, el modelo est√° actuando simplemente como una forma alternativa de expresar los datos. El modelo no est√° aprendiendo algo sobre los datos, ¬°Est√° memorizando los datos! A partir de este simple ejemplo, podemos ver que un modelo con mayor ajuste no siempre es lo ideal.\nAhora agregaremos dos datos nuevos y sin volver a ajustar los modelos veremos como cambia el R¬≤. Se puede ver que al modelo lineal le va mejor en este caso que al polinomial.\n\n_, ax = plt.subplots( figsize=(12, 4))\nx_ = np.array([6.5, 10])\ny_ = np.array([7, 10])\n\nax.plot(x0, y0, 'ko', zorder=3)\nax.plot(x_, y_, 'ks', zorder=3)\n\nax.set_yticks([])\nax.set_xticks([])\n\nx1 = np.concatenate((x0, x_))\ny1 = np.concatenate((y0, y_))\n\nfor idx, i in enumerate(order):\n    yhat = ps[idx](x1)\n    ybar = np.mean(y1)\n    ss_regression = np.sum((yhat-y1)**2)\n    ss_total = np.sum((ybar-y1)**2)\n    r2 = 1 - ss_regression / ss_total\n    ax.plot(x_n, ps[idx](x_n), label=f'orden {i}, $R^2$= {r2:.3f}')\n\n    \nax.legend(loc=2, fontsize=12);\n\n\n\n\nCuando un modelo ajusta muy bien, el conjunto de datos utilizado para aprender los par√°metros de ese modelo, pero muy mal otros conjuntos de datos, decimos que tenemos sobreajuste (overfitting). Este es un problema muy com√∫n al analizar datos.\nUna forma muy √∫til de pensar el sobreajuste es considerar que un conjunto de datos tiene dos componentes; la se√±al y el ruido. La se√±al es lo que queremos capturar (o aprender) de los datos. Si usamos un conjunto de datos es porque creemos que hay una se√±al all√≠, de lo contrario ser√° un ejercicio f√∫til. El ruido, en cambio, no es √∫til y es el producto de los errores de medici√≥n, las limitaciones en la forma en que se generaron o capturaron los datos, la presencia de datos corruptos, etc. Un modelo sobreajusta cuando es tan flexible (para un conjunto de datos) que es capaz de aprender el ruido. Esto tiene como consecuencia que la se√±al queda oculta.\nEsta es una justificaci√≥n pr√°ctica para la navaja de Occam. Y nos advierte que al menos en principio, siempre es posible crear un modelo tan complejo que explique todos los detalles, incluso los m√°s irrelevantes. Tal como en el Imperio descripto por Borges, donde los cart√≥grafos alcanzaron tal nivel de sofisticaci√≥n que crearon un mapa del Imperio cuyo tama√±o era el del propio Imperio, y que coincid√≠a punto por punto con √©l."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#muy-pocos-par√°metros-conducen-a-un-subajuste",
    "href": "07_Comparaci√≥n_de_modelos.html#muy-pocos-par√°metros-conducen-a-un-subajuste",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.2 Muy pocos par√°metros conducen a un subajuste",
    "text": "9.2 Muy pocos par√°metros conducen a un subajuste\nContinuando con el mismo ejemplo pero en el otro extremo de complejidad, tenemos el modelo de orden 0. Este modelo es simplemente una Gaussiana disfrazada de modelo lineal. Este modelo solo es capaz de capturar el valor de la media de \\(Y\\), y es por lo tanto totalente indiferente a los valores de \\(x\\). Decimos que este modelo ha subajustado los datos."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#el-equilibrio-entre-simplicidad-y-exactitud",
    "href": "07_Comparaci√≥n_de_modelos.html#el-equilibrio-entre-simplicidad-y-exactitud",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.3 El equilibrio entre simplicidad y exactitud",
    "text": "9.3 El equilibrio entre simplicidad y exactitud\nTodo debe hacerse tan simple como sea posible, pero no m√°s simple es una cita que a menudo se atribuye a Einstein y es similar a la navaja de Occam. Al igual que en una dieta saludable, al modelar tenemos que mantener un balance. Idealmente, nos gustar√≠a tener un modelo que ni sub-ajuste ni sobre-ajuste los datos. De alguna forma hay que balancear simplicidad y bondad de ajuste."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#medidas-de-exactitud-predictiva",
    "href": "07_Comparaci√≥n_de_modelos.html#medidas-de-exactitud-predictiva",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.4 Medidas de exactitud predictiva",
    "text": "9.4 Medidas de exactitud predictiva\nEn el ejemplo previo, es relativamente facil de ver que el modelo de orden 0 es demasiado simple mientras que el modelo de orde 5 es demasiado complejo. Pero que podemos decir de los otros dos modelos? C√≥mo podr√≠amos establecer un ranking num√©rico de estos modelos? Para poder hacer esto necesitamos formalizar nuestra intuici√≥n sobre este balance entre simplicidad y exactitud\nVeamos un par de t√©rminos que nos ser√°n de utilidad.\n\nExactitud dentro de la muestra (within-sample accuracy). La exactitud medida con los mismos datos usado para ajustar el modelo.\nExactitud fuera de la muestra (out-of-sample accuracy). La exactitud medida con datos no usados para ajustar el modelo.\n\nLa exactitud dentro de la muestra ser√°, en promedio, menor a la exactitud fuera de la muestra. Es por ello que usar la exactitud dentro de la muestra para evaluar un modelo en general conducir√° a pensar que tenemos un mejor modelo de lo que realmente es. Utilizar la exactitud fuera de la muestra es por lo tanto una mejor idea para evitar enga√±arnos a nosotros mismos. Sin embargo, esta aproximaci√≥n requiere dejar datos fuera del ajuste, lo cual es un lujo que en general no nos podemos dar. Ya que este es un problema central en el an√°lisis de datos existen varias propuestas para abordarlo. Dos aproximaciones muy populares son:\n\nValidaci√≥n cruzada: esta es una estrategia emp√≠rica basada en dividir los datos disponibles en subconjuntos separados que se utilizan para ajustar y evaluar de forma alternativa\nCriterios de informaci√≥n: este es un t√©rmino general usado para referirse a varias expresiones que aproximan la exactitud fuera de la muestra como la exactitud dentro de la muestra m√°s un t√©rmino que penaliza a modelos complejos.\n\n\n9.4.1 Validaci√≥n cruzada\nLa validaci√≥n cruzada es una soluci√≥n simple y, en la mayor√≠a de los casos, efectiva para comparar modelos. Tomamos nuestros datos y los dividimos en K porciones. Intentamos mantener las porciones m√°s o menos iguales (en tama√±o y, a veces, tambi√©n en otras caracter√≠sticas, como, por ejemplo, un n√∫mero igual de clases). Luego usamos K-1 porciones para entrenar el modelo y el resto para evaluarlo. Este proceso se repite sistem√°ticamente dejando, por cada iteraci√≥n, una porci√≥n diferente fuera del conjunto de entrenamiento y usando esa porci√≥n como el conjunto de validaci√≥n. Esto se repite hasta que hayamos completado K rondas de ajuste-evaluaci√≥n. La exactitud del modelo ser√° la del promedio a lo largo de las K rondas. Esto se conoce como validaci√≥n cruzada K-fold. Cuando K es igual a la cantidad de puntos de datos, obtenemos lo que se conoce como validaci√≥n cruzada dejando un punto afuera (LOOCV del ingl√©s leave-one-out cross-validation). Por √∫ltimo una vez que hemos relizado la validaci√≥n cruzada, usamos todos los datos para ajustar por √∫ltima vez nuestro modelo y este es el modelo que se utiliza para hacer predicciones o para cualquier otro fin.\n\nLa validaci√≥n cruzada es una pr√°ctica est√°dard en en machine learning. Y apenas hemos descripto los aspectos m√°s esenciales de esta pr√°ctica. Para mayor informaci√≥n pueden leer The Hundred-Page Machine Learning Book](http://themlbook.com/) o Python Machine Learning, by Sebastian Raschka, o Python Data Science Handbook by Jake Vanderplas.\nLa validaci√≥n cruzada es una idea muy simple y √∫til, pero para algunos modelos o para grandes cantidades de datos, el costo computacional de la validaci√≥n cruzada puede estar m√°s all√° de nuestras posibilidades. Muchas personas han tratado de encontrar cantidades m√°s simples de calcular que se aproximen a los resultados obtenidos con la validaci√≥n cruzada o que funcionen en escenarios donde la validaci√≥n cruzada no puede ser tan f√°cil de realizar. Y ese es el tema de la siguiente secci√≥n.\n\n\n9.4.2 Criterios de informaci√≥n\nLos criterios de informaci√≥n son una colecci√≥n de herramientas estrechamente relacionadas que se utilizan para comparar modelos en t√©rminos de la bondad del ajuste y de la complejidad del modelo. En otras palabras, los criterios de informaci√≥n formalizan la intuici√≥n que desarrollamos al comienzo del cap√≠tulo. La forma exacta en que se derivan estas cantidades tiene que ver con un campo conocido como Teor√≠a de la Informaci√≥n.\n\n9.4.2.1 El log-likelihood y la deviance\nUna forma intuitiva de medir qu√© tan bien un modelo se ajusta a los datos es calcular el error cuadr√°tico medio entre los datos y las predicciones realizadas por el modelo:\n\\[\\frac{1}{n} \\sum_{i=1}^{n}  (y_i - \\operatorname{E} (y_i \\mid \\theta))^2\\]\n\\(\\operatorname{E} (y_i \\mid \\theta)\\) es el valor predicho dados los par√°metros estimados. Es importante notar que esto es esencialmente el promedio entre la diferencia entre los datos observados y los predichos. Tomar el cuadrado de los errores asegura que las diferencias no se cancelen y enfatiza grandes errores comparado con otros alternativas como por ejemplo calcular el valor absoluto.\nEl error cuadr√°tico medio, puede resultarnos familiar ya que es muy popular. Pero si nos detenemos a reflexionar sobre esta cantidad veremos que en principio no tiene nada de especial y bien podr√≠amos idear otras expresiones similares. Cuando adoptamos una aproximaci√≥n probabilista vemos que una expresi√≥n m√°s general (y natural) es la siguiente:\n\\[ \\sum_{i=1}^{n} \\log p(y_i \\mid \\theta)\\]\nEsto es, la suma (sobre \\(n\\) datos) de los likelihoods (en escala logar√≠tmica). Esto es natural por que al elegir un likelihood en un modelo estamos eleigiendo impl√≠citamente una m√©trica para evaluar el ajuste del modelo. Cuando \\(p(y_i \\mid \\theta)\\) es una gaussiana entonces la suma de log-likelihood ser√° proporcional al error cuadr√°tico medio.\nCuando se discuten criterios de informaci√≥n y por razones puramente hist√≥ricas suele ser com√∫n hablar de deviance que es simplemente:\n\\[-2\\ \\sum_{i=1}^{n} \\log \\ p(y_i \\mid \\theta)\\]\nEs decir el log-likelihood multiplicado por -2.\nLa deviance es usada en contextos Bayesianos y no Bayesianos, la diferencia es que bajo un marco Bayesiano \\(\\theta\\) representa una distribuci√≥n de probabilidad y no una estimaci√≥n puntual.\n\nCuanto menor es la deviance, mayor es el likelihood y mayor es el acuerdo entre las predicciones del modelo y los datos. Es decir, a menor deviance, mejor ajuste\nLa deviance se calcula a partir de los datos usados para ajustar el modelo es por lo tanto una forma de estimar la exactitud dentro de la muestra. Como ya vimos esto significa que en promedio la deviance va a tender a elegir modelos m√°s complejos, necesitamos por lo tanto alg√∫n criterio para balancear esa tendencia.\n\nEn las siguientes secciones, aprenderemos sobre diferentes criterios de informaci√≥n. Los cuales tienen en com√∫n el uso de la desviace y un t√©rmino de penalizaci√≥n. La diferencia radica en c√≥mo se calculan cada uno de estos dos t√©rminos.\n\n\n9.4.2.2 Criterio de informaci√≥n de Akaike\nEste es un criterio de informaci√≥n muy conocido y ampliamente utilizado fuera del universo Bayesiano y se define como:\n\\[AIC = -2 \\sum_{i=1}^{n} \\log p(y_i \\mid \\hat{\\theta}_{mle}) + 2 k \\]\nDonde, k es el n√∫mero de par√°metros del modelo y \\(\\hat{\\theta}_{mle}\\) es la estimaci√≥n por m√°xima verosimilitud para \\(\\theta\\).\nLa estimaci√≥n de m√°xima verosimilitud es una pr√°ctica com√∫n para los no-bayesianos y, en general, es equivalente a la estimaci√≥n Bayesiana del m√°ximo a posteriori (MAP) cuando se usan priors planos. Es importante notar que $_{mle} $ es una estimaci√≥n puntual y no una distribuci√≥n.\nAc√° vemos como el factor \\(-2\\) aparece de nuevo, como ya dijimos esto tiene razones hist√≥ricas y no es relevante ya que es una constante. Lo importante, desde el punto de vista pr√°ctico, es que el primer t√©rmino toma en cuenta cuan bien el modelo ajusta los datos, mientras que el segundo t√©rmino penaliza la complejidad del modelo. Por lo tanto si dos modelos ajustan los datos igualmente bien. AIC dice que deberemos elegir aquel modelo con el menor n√∫mero de par√°metros, lo cual nos recuerda a la navaja de Ocam.\nAIC funciona bien en enfoques no-bayesianos, pero de lo contrario es problem√°tico. Una de las razones es que no utiliza la distribuci√≥n a posteriori y, por lo tanto, descarta informaci√≥n sobre la incertidumbre en la estimaci√≥n. Adem√°s AIC asume que los priors son planos y, por lo tanto, AIC es incompatible con priors informativos y ligeramente informativos como los utilizados en este libro. Tampoco es buena idea usarlo con modelos jer√°rquicos por lo que ya dijimos. Adem√°s, la cantidad de par√°metros de un modelo no es una buena medida de la complejidad del mismo cuando se usan priors informativos o estructuras como la jer√°rquica ya que estas son formas de regularizar el modelo que es una forma de reducir la cantidad efectiva de par√°metros. M√°s adelante volveremos sobre esta idea de regularizaci√≥n.\n\n\n9.4.2.3 Widely applicable information criterion\nWAIC es algo as√≠ como la versi√≥n Bayesiana de AIC, al igual que este √∫ltimo WAIC se compone de dos t√©rminos uno que mide el ajuste y otro que penaliza. La siguiente expresi√≥n asume que la distribuci√≥n a posteriori est√° representada como una muestra de tama√±o S.\n\\[WAIC = -2 \\sum_i^n \\log \\left(\\frac{1}{S} \\sum_{s=1}^S p(y_i \\mid \\theta^s) \\right) + 2 \\sum_i^n  \\left( V_{s=1}^S \\log p(y_i \\mid \\theta^s) \\right)\\]\nEl primer t√©rino es similar al criterio de Akaike, solo que evaluado para todas las observaciones y todas las muestras del posterior. El segundo t√©rmino es un poco m√°s dificil de justificar sin entrar en tecnicismos. Pero es tabi√©n una forma de penalizar la complejidad del modelo. Lo importante desde el punto de vista pr√°ctico es que WAIC usa todo el posterior (y no una estimaci√≥n puntual) para el c√°lculo de ambos t√©rminos, por lo que WAIC puede ser aplicado virtualmente a cualquier modelo Bayesiano.\n\n\n9.4.2.4 Validaci√≥n cruzada de dejando uno afuera mediante muestreo de importancia usando un suavizado de Pareto\nEl problema clave con la validaci√≥n cruzada dejando uno fuera es que es muy costosa ya que tenemos que reajustar el modelo tantas veces como datos tengamos. Por suerte, hay formas de evitar la fuerza bruta y aproximar la estimaci√≥n ajustando una sola vez lo datos, y esto es lo que hace el m√©todo ‚Äúmuestreo de importancia usando un suavizado de Pareto‚Äù. El nombre es tan poco amigable que en la pr√°ctica le decimos LOO. Conceptualmente lo que est√°mos tratando de calcular es:\n\\[\n\\text{ELPD}_\\text{LOO-CV} = \\sum_{i=1}^{n} \\log\n    \\int \\ p(y_i \\mid \\theta) \\; p(\\theta \\mid y_{-i}) d\\theta\n\\]\n\\[\n\\sum_{i}^{n} \\log\n    \\left( \\frac{1}{s}\\sum_j^s \\mathbin{\\color{#E9692C}{p(y_i \\mid \\theta_{-i}^j)}} \\right)\n\\]\nEs posible aproximar \\(\\color{#E9692C}{p(y_i \\mid \\theta_{-i}^j})\\) usando importance sampling, que es una forma de approximar una distribuci√≥n repesando valores obtenidos de otra distribuci√≥n. En nuestro caso la distribuci√≥n conocida, una vez ajustado un modelo, es el log-likelihood. Y queremos aproximar el log-likelihood si hubieramos eliminado una observaci√≥n. Para ello necesitamos estimar la ‚Äúimportancia‚Äù (o peso) que cada observaci√≥n tiene en determinar la distribuci√≥n a posteriori. Una distribuci√≥n ser√° m√°s ‚Äúimportante‚Äù (o pesada) mientras m√°s cambie el posterior al eliminar esa observaci√≥n. Intuitivamente una observaci√≥n relativamente poco probable es m√°s importante que una relativamente esperada. Mientras mayor la sorpresa, mayor la importancia. Por suerte estos pesos se puede estimar sin necesidad de reajustar el modelo, de hecho el peso de la observaci√≥n \\(i\\) para la muestra del posterior \\(s\\) es:\n\\[\nw_s = \\frac{1}{p(y_i \\mid \\theta_s)}\n\\]\nEl problema es que bajo ciertas condiciones estos pesos puede no ser confiables. El principal problema es que unos pocos \\(w_s\\) podr√≠an ser tan grandes que dominan el c√°lculo, y es aqu√≠ donde entra el suavizado de Pareto que basicamente consiste en reemplazar algunos de estos pesos por pesos obtenidos a partir de ajustar una distribuci√≥n de Pareto ¬øpor qu√© una distribuci√≥n de Pareto? Por que la teor√≠a indica que los pesos debe≈ïian seguir esta distribuci√≥n. Entonces para cada observation \\(y_i\\) , los pesos m√°s grandes se usan para estimar una distribuci√≥n de Pareto y esa distribuci√≥n se usa para reemplazar esos pesos por pesos ‚Äúsuavizados‚Äù. Este procedimiento le da robustes a la estimaci√≥n del ELPD y adem√°s provee de un diag√≥stico ya que valores de \\(k\\) (uno de los par√°metros de la distribuci√≥n de Pareto) mayores a 0.7 indican que posiblemente tengamos observaciones ‚Äúmuy influyentes‚Äù.\n\n\n9.4.2.5 Otros criterios de informaci√≥n\nOtro criterio de informaci√≥n muy usado es DIC, si usamos el bayes√≥metero‚Ñ¢ DIC, es m√°s bayesiano que AIC pero menos que WAIC. Aunque a√∫n es popular, WAIC y LOO han demostrado ser m√°s √∫tiles tanto te√≥ricamente como emp√≠ricamente que DIC. Por lo cual NO recomendamos su uso.\nOtro criterio muy usado es BIC (del ingl√©s Bayesian Information Criteria), al igual que la regresi√≥n log√≠stica y la * sopa seca * de mi madre, este nombre puede ser enga√±oso. BIC se propuso como una forma de corregir algunos de los problemas con AIC y el autor propuso una justificaci√≥n Bayesiana para ello. Pero BIC no es realmente Bayesiano en el sentido que al igual que AIC asume priors planos y utiliza una estimaci√≥n por m√°xima verosimilitud.\nPero lo que es m√°s importante, es que BIC difiere de AIC y WAIC en su objetivo. AIC y WAIC intentan reflejar cual modelo generaliza mejor a otros datos (exactitud predictiva) mientras que BIC intenta identificar cual es el modelo correcto y por lo tanto est√° m√°s relacionado los factores de Bayes que con WAIC. M√°s adelante discutiremos Factores de Bayes y veremos como se diferenci de criterios como WAIC y LOO."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#calcular-los-criterios-de-informaci√≥n-con-arviz",
    "href": "07_Comparaci√≥n_de_modelos.html#calcular-los-criterios-de-informaci√≥n-con-arviz",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.5 Calcular los criterios de informaci√≥n con ArviZ",
    "text": "9.5 Calcular los criterios de informaci√≥n con ArviZ\nAfortunadamente, calcular los criterios de informaci√≥n con ArviZ es muy simple. Veamos:\n\nwaic_l = az.waic(idata_l)\nwaic_l\n\nComputed from 8000 posterior samples and 33 observations log-likelihood matrix.\n\n          Estimate       SE\nelpd_waic   -14.27     2.65\np_waic        2.36        -\n\n\n\nwaic_p = az.waic(idata_p)\nwaic_p\n\nComputed from 8000 posterior samples and 33 observations log-likelihood matrix.\n\n          Estimate       SE\nelpd_waic    -4.49     2.34\np_waic        2.61        -\n\n\nLo mismo para LOO.\n\nloo_l = az.loo(idata_l)\nloo_l\n\nComputed from 8000 posterior samples and 33 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   -14.30     2.66\np_loo        2.39        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)       33  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nloo_p = az.loo(idata_p)\nloo_p\n\nComputed from 8000 posterior samples and 33 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo    -4.52     2.35\np_loo        2.64        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)       33  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\nTanto az.waic como az.loo devuelven 3 valores\n\nUna estimaci√≥n puntual del ELPD.\nEl error est√°ndar de esa estimaci√≥n\nEl n√∫mero efectivo de par√°metros\n\nAdem√°s LOO devuelve un diagn√≥stico basado en el par√°metro k, correspondiente al ajuste de la distribuci√≥n de Pareto.\nLos valores de WAIC o LOO no tienen sentido por si mismos, si no que deben ser interpretados de forma relativa. Es por ello que ArviZ ofrece dos funciones auxiliares para facilitar esta comparaci√≥n veamos primero a az.compare.\n\ncmp_df = az.compare({'modelo_l':idata_l, 'modelo_p':idata_p})\ncmp_df\n\n\n\n\n\n  \n    \n      \n      rank\n      elpd_loo\n      p_loo\n      elpd_diff\n      weight\n      se\n      dse\n      warning\n      scale\n    \n  \n  \n    \n      modelo_p\n      0\n      -4.517563\n      2.638813\n      0.000000\n      1.000000e+00\n      2.345124\n      0.000000\n      False\n      log\n    \n    \n      modelo_l\n      1\n      -14.295518\n      2.387078\n      9.777955\n      2.291500e-13\n      2.657647\n      2.684915\n      False\n      log\n    \n  \n\n\n\n\nEn las filas tenemos los modelos comparados y en la columnas tenemos\n\nrank : el orden de los modelos (de mejor a peor)\nelpd : la estimaci√≥n puntual del elpd usando\np : los par√°metros efectivos\nelpd_diff : la diferencia entre el ELPD del mejor modelo y los dem√°s modelos\nweight : el peso relativo de cada modelo. Si quisieramos hacer predicciones combinando los distintos modelos, en vez de elegir uno solo, este ser√≠a el peso que deber√≠amos asignar a cada modelo. En este caso vemos que el modelo polinomial se lleva todo el peso.\nse : el error est√°ndard del ELPD\ndse : el error est√°ndard de las difencias\nwarning : una advertencia sobre valores de k altos\nscale : la escala en la que se calcula el ELPD\n\nTambi√©n podemos obtener m√°s o menos la misma informaci√≥n de forma gr√°fica usando la funci√≥n az.compareplot.\n\naz.plot_compare(cmp_df);\n\n\n\n\n\nLos c√≠rculos vac√≠os representan los valores del ELPD y lineas negras el error est√°ndar.\nEl valor m√°s alto del ELPD se indica con una l√≠nea gris discontinua vertical para facilitar la comparaci√≥n con otros valores.\nPara todos los modelos, excepto el mejor, tambi√©n obtenemos un tri√°ngulo que indica el valor de la diferencia del ELPD entre cada modelo y el mejor modelo. La barra de error gris que indica el error est√°ndar de las diferencias entre las estimaciones puntuales.\n\nLa forma m√°s sencilla de utilizar los criterios de informaci√≥n es elegir un √∫nico modelo. Simplemente elija el modelo con el valor m√°s alto de ELPD. Si seguimos esta regla tendremos que aceptar que el modelo cuadr√°tico es el mejor. Incluso si tenemos en cuenta los errores estandar podemos ver que estos no se solapan. Lo que nos da cierta seguridad que efectivamente los modelos son diferentes entre si. Si, en cambio, los errores est√°ndar se superpusieran, deber√≠amos proporcionar una respuesta m√°s matizada."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#promedio-de-modelos",
    "href": "07_Comparaci√≥n_de_modelos.html#promedio-de-modelos",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.6 Promedio de modelos",
    "text": "9.6 Promedio de modelos\nLa selecci√≥n de modelos es atractiva por su simplicidad, pero podr√≠amos estar descartando informaci√≥n sobre la incertidumbre en nuestros modelos. Esto es de alguna manera similar a calcular el posterior completo y luego solo mantener la media del posterior; esto puede conducirnos a confiar demasiado en lo que creemos saber.\nUna alternativa es seleccionar un solo modelo, pero informar y analizar los diferentes modelos junto con los valores de los criterios de informaci√≥n calculados, sus valores de error est√°ndar y quiz√°s tambi√©n las pruebas predictivas a posteriori. Es importante poner todos estos n√∫meros y pruebas en el contexto de nuestro problema para que nosotros y nuestra audiencia podamos tener una mejor idea de las posibles limitaciones y deficiencias de los modelos. Para quienes trabajan en el mundo acad√©mico, estos elementos se pueden utilizar para agregar elementos a la secci√≥n de discusi√≥n de un paper, presentaci√≥n, tesis, etc. Y en la industria esto puede ser √∫til para informar a clientes sobre las ventajas y limitaciones de las predicciones o conclusiones del modelado.\nOtra posibilidad es promediar los modelos. De esta forma estamos introduciendo la incertidumbre que tenemos sobre la bondad de cada modelo. De esta fora podemos generar un metamodelo (y meta-predicciones) usando un promedio pesado de cada modelo.\n\nidata_w = az.weight_predictions(idatas, weights=[0.35, 0.65])\n\n\n_, ax = plt.subplots(figsize=(10, 6))\naz.plot_kde(idata_l.posterior_predictive['y_pred'].values, plot_kwargs={'color':'C0'}, label='modelo lineal', ax=ax)\naz.plot_kde(idata_p.posterior_predictive['y_pred'].values, plot_kwargs={'color':'C1'}, label='orden 2', ax=ax)\naz.plot_kde(idata_w.posterior_predictive['y_pred'].values, plot_kwargs={'color':'C2'}, label='modelo pesado', ax=ax)\n\nplt.plot(y_1s, np.zeros_like(y_1s), 'k|', label='observed data')\nplt.yticks([])\nplt.legend();\n\n\n\n\nHay otras formas de promediar modelos, como, por ejemplo, construir expl√≠citamente un metamodelo que incluya todos los modelos de inter√©s como casos particulares. Por ejemplo un polinomio de grado 2 contiene como caso particular un modelo lineal, o un modelo jer√°rquico es la versi√≥n continua entre dos extremos un modelo agrupado y uno desagrupado."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#factores-de-bayes",
    "href": "07_Comparaci√≥n_de_modelos.html#factores-de-bayes",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.7 Factores de Bayes",
    "text": "9.7 Factores de Bayes\nUna alternativa LOO, validaci√≥n cruzada y los criterios de informaci√≥n son los factores de Bayes. Es com√∫n que factores de Bayes aparezcan en la literatura como una alternativa Bayesiana al contraste de hip√≥tesis frecuentista.\nLa ‚Äúmanera Bayesiana‚Äù de comparar modelos es calcular la verosimilitud marginal de cada modelo \\(p(y \\mid M_k)\\), es decir, la probabilidad de los datos observados \\(Y\\) dado el modelo \\(M_k\\). Esta cantidad, la verosimilitud marginal, es simplemente la constante de normalizaci√≥n del teorema de Bayes. Podemos ver esto si escribimos el teorema de Bayes y hacemos expl√≠cito el hecho de que todas las inferencias dependen del modelo.\n\\[p (\\theta \\mid Y, M_k ) = \\frac{p(Y \\mid \\theta, M_k) p(\\theta \\mid M_k)}{p(Y \\mid M_k)}\\]\nd√≥nde:\n\n\\(y\\) son los datos\n\\(\\theta\\) los par√°metros\n\\(M_k\\) un modelo de k modelos competidores\n\nSi nuestro objetivo principal es elegir solo un modelo, el mejor, de un conjunto de modelos podemos elegir el que tiene el mayor valor de \\(p(y \\mid M_k)\\). Esto est√° bien si asumimos que todos los modelos tienen la misma probabilidad a priori. De lo contrario debemos calcular:\n\\[p(M_k \\mid y) \\propto p(y \\mid M_k) p(M_k)\\]\nSi en cambio, nuestro objetivo principal es comparar comparar modelos para determinar cu√°les son m√°s probables y en qu√© medida. Esto se puede lograr utilizando los factores de Bayes:\n\\[FB_{01} = \\frac{p(y \\mid M_0)}{p(y \\mid M_1)}\\]\nes decir, el cociente entre la verosimilitud marginal de dos modelos. Cuanto mayor sea el FB, mejor el modelo en el numerador (\\(M_0\\) en este ejemplo). Para facilitar la interpretaci√≥n de los FB, Harold Jeffreys propuso una escala para la interpretaci√≥n de los Factores de Bayes con niveles de apoyo o fuerza. Esta es solo una manera de poner n√∫meros en palabras.\n\n1-3: anecd√≥tico\n3-10: moderado\n10-30: fuerte\n30-100: muy fuerte\n\\(>\\) 100: extremo\n\nHay que tener en cuenta que si se obtiene n√∫meros por debajo de 1, entonces el soporte es para el modelo en el denominador, tambi√©n hay tablas disponibles para esos casos. O simplemente podemos tomar la inversa de los valores del valor obtenido.\nEs muy importante recordar que estas reglas son solo convenciones, gu√≠as simples en el mejor de los casos. Los resultados siempre deben ponerse en el contexto de nuestros problemas y deben ir acompa√±ados de suficientes detalles para que otros puedan evaluar por s√≠ mismos si est√°n de acuerdo con nuestras conclusiones. No es lo mismo la prueba necesaria para asegurar algo en f√≠sica de part√≠culas, o en un juzgado, o para decidir realziar una evacuaci√≥n frente a una cat√°strofe natural que se avecina."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#algunas-observaciones",
    "href": "07_Comparaci√≥n_de_modelos.html#algunas-observaciones",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.8 Algunas observaciones",
    "text": "9.8 Algunas observaciones\nAhora discutiremos brevemente algunos hechos clave sobre la verosimilitud marginal\n\nEl bueno\n\nNavaja de Occam incluida: Los modelos con m√°s par√°metros tienen una penalizaci√≥n mayor que los modelos con menos par√°metros. La raz√≥n intuitiva es que cuanto mayor es el n√∫mero de par√°metros, m√°s se extiende el prior con respecto al likelihood.\n\nEl malo\n\nPara muchas problema la verosimilitud marginal no puede ser calculada analiticamente. Y aproximarla num√©ricamente suele ser una tarea dif√≠cil que suele requerir de m√©todos especializados. Esto se debe a que es necesario calcular una integral de una funci√≥n altamente variable en un espacio de par√°metros de gran dimensi√≥n.\n\n\n\\[p(y \\mid M_k) = \\int_{\\theta_k} p(y \\mid \\theta_k, M_k) \\; p(\\theta_k | M_k) \\; d\\theta_k\\]\n\nEl feo\n\nLa probabilidad marginal depende sensiblemente de la distribuci√≥n a prior para los par√°metros en cada modelo \\(p(\\theta_k \\mid M_k)\\).\n\n\nEs importante notar que lo bueno y lo feo est√°n relacionados. Usar la verosimilitud marginal para comparar modelos es una buena idea porque ya incluye una penalizaci√≥n para modelos complejos (lo que nos ayuda a prevenir el sobreajuste) y, al mismo tiempo, un cambio en el prior afectar√° los c√°lculos de la verosimilitud marginal. Al principio esto suena un poco tonto; ya sabemos que los priors afectan los c√°lculos (de lo contrario, simplemente podr√≠amos evitarlos), pero el punto aqu√≠ es la palabra sensiblemente. Estamos hablando que cambios en el posterior que apenas tendr√≠an efecto en el posterior tendr√°n un gran impacto en el valor de la verosimilitud marginal.\nEl uso de los FB suele ser una divisoria de aguas entre Bayesianos. La dificultad de su c√°lculo y la sensibilidad a los priors son algunos de los argumentos. Otra raz√≥n es que al igual que lo p-valores y en general las pruebas de hip√≥tesis los BF favorecen el pensamiento dicot√≥mico por sobre la estimaci√≥n del ‚Äútama√±o del efecto‚Äù. Es decir en vez de hacernos preguntas del estilo ¬øCuantos a√±os m√°s de vida puede proporcionar, en promedio, un tratamiento oncol√≥gico? terminamos preguntando si la diferencia entre tratar y no tratar a un paciente es ‚Äúestad√≠sticamente significativa‚Äù. Ojo que esta √∫ltima pregunta puede ser √∫til en algunos contextos, el punto es que en muchos otros contextos, ese tipo de preguntas no es la pregunta m√°s relevante."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#c√°lculo-de-los-fb",
    "href": "07_Comparaci√≥n_de_modelos.html#c√°lculo-de-los-fb",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.9 C√°lculo de los FB",
    "text": "9.9 C√°lculo de los FB\nLa verosimilitud marginal generalmente no est√° disponible en forma cerrada, excepto para algunos modelos. Por esta raz√≥n, se han ideado muchos m√©todos para calcular la probabilidad marginal. Algunos de estos m√©todos son tan simples e ingenuos que funciona muy mal en la pr√°ctica. La mayor√≠a de los m√©todos √∫tiles se han propuesto originalmente en el campo de la mec√°nica estad√≠stica. Esta conexi√≥n se explica porque la verosimilitud marginal es an√°loga a una cantidad central en f√≠sica estad√≠stica conocida como funci√≥n de partici√≥n que a su vez est√° estrechamente relacionada con otra cantidad muy importante, la energ√≠a libre. Muchas de las conexiones entre la mec√°nica estad√≠stica y la inferencia bayesiana se resumen aqu√≠.\n\n9.9.1 Analiticamente\nPara algunos modelos, como el modelo beta-binomial, podemos calcular la verosimilitud marginal anal√≠ticamente. Si escribimos este modelo como:\n\\[\\theta \\sim Beta(\\alpha, \\beta)\\] \\[y \\sim Bin(n=1, p=\\theta)\\]\nla verosimilitud marginal ser√°:\n\\[p(y) = \\binom {n}{h} \\frac{B(\\alpha + h,\\ \\beta + n - h)} {B(\\alpha, \\beta)}\\]\nd√≥nde:\n\n\\(B\\) es la funci√≥n beta no confundirse con la distribuci√≥n \\(Beta\\)\n\\(n\\) es el n√∫mero de intentos\n\\(h\\) es el n√∫mero de √©xito\n\nComo solo nos importa el valor relativo de la verosimilitud marginal bajo dos modelos diferentes (para los mismos datos), podemos omitir el coeficiente binomial \\(\\binom {n}{h}\\), por lo que podemos escribir:\n\\[p(y) \\propto \\frac{B(\\alpha + h,\\ \\beta + n - h)} {B(\\alpha, \\beta)}\\]\nEsta expresi√≥n ha sido codificada en la siguiente celda, pero con un giro. Usaremos la funci√≥n betaln en lugar de la funci√≥n beta, esto se hace para evitar el overflow.\n\ndef beta_binom(prior, y):\n    \"\"\"\n    Calcula la probabilidad marginal, anal√≠ticamente, para un modelo beta-binomial.\n\n     prior : tupla\n         tupla de par√°metro alfa y beta para el prior (distribuci√≥n beta)\n     y : array\n         array con \"1\" y \"0\" correspondientes al √©xito y falla respectivamente\n    \"\"\"\n    alpha, beta = prior\n    h = np.sum(y)\n    n = len(y)\n    p_y = np.exp(betaln(alpha + h, beta + n - h) - betaln(alpha, beta))\n    return p_y\n\nNuestros datos para este ejemplo consisten en 100 ‚Äúlanzamientos de una moneda‚Äù y el mismo n√∫mero de ‚Äúcaras‚Äù y cecas‚Äù observadas. Compararemos dos modelos uno con un prior uniforme y otro con un prior m√°s concentrado alrededor de \\(\\theta = 0.5\\)\n\ny = np.repeat([1, 0], [50, 50])  # 50 \"caras\" y 50 \"cecas\"\npriors = ((1, 1), (30, 30))\n\n\nfor a, b in priors:\n    x = np.linspace(0, 1, 300)\n    x_pdf = pz.Beta(a, b).rv_frozen.pdf(x)\n    plt.plot(x, x_pdf, label=rf\"$\\alpha$ = {a:d}, $\\beta$ = {b:d}\")\n    plt.yticks([])\n    plt.xlabel(\"$\\\\theta$\")\n    plt.legend()\n\n\n\n\nLa siguiente celda devuelve el factor de Bayes\n\nBF = beta_binom(priors[1], y) / beta_binom(priors[0], y)\nprint(round(BF))\n\n5\n\n\nVemos que el modelo con el prior \\(\\text{beta}(30, 30)\\), m√°s concentrado, tiene \\(\\approx 5\\) veces m√°s apoyo que el modelo con el $(1, 1). Esto es esperable ya que el prior para el primer caso se concentra alrededor de \\(\\theta = 0.5\\) y los datos \\(Y\\) tienen el mismo n√∫mero de caras y cruces, es decir acuerdan con un valor de \\(\\theta\\) alrededor de 0.5.\n\n\n9.9.2 Sequential Monte Carlo\nEl m√©todo Sequential Monte Carlo es un m√©todo de meustreo que b√°sicamente progresa mediante una serie de secuencias sucesivas desde el prior al posterior. Un subproducto de este proceso es la estimaci√≥n de la verosimilitud marginal. En realidad, por razones num√©ricas, el valor devuelto es el logaritmo de la verosimilitud marginal.\n\nmodels = []\nidatas = []\nfor alpha, beta in priors:\n    with pm.Model() as model:\n        a = pm.Beta(\"a\", alpha, beta)\n        yl = pm.Bernoulli(\"yl\", a, observed=y)\n        idata = pm.sample_smc(random_seed=42)\n        models.append(model)\n        idatas.append(idata)\n\nInitializing SMC sampler...\nSampling 4 chains in 4 jobs\n\n\n\n\n\n\n\n    \n      \n      100.00% [100/100 00:00<?  Stage: 2 Beta: 1.000]\n    \n    \n\n\n    \n\n\n/home/osvaldo/proyectos/00_BM/arviz/arviz/data/base.py:221: UserWarning: More chains (4) than draws (3). Passed array should have shape (chains, draws, *shape)\n  warnings.warn(\nInitializing SMC sampler...\nSampling 4 chains in 4 jobs\n\n\n\n\n\n\n\n    \n      \n      100.00% [100/100 00:00<?  Stage: 0 Beta: 1.000]\n    \n    \n\n\n    \n\n\n/home/osvaldo/proyectos/00_BM/arviz/arviz/data/base.py:221: UserWarning: More chains (4) than draws (1). Passed array should have shape (chains, draws, *shape)\n  warnings.warn(\n\n\n\nBF_smc = np.exp(\n    idatas[1].sample_stats[\"log_marginal_likelihood\"].mean()\n    - idatas[0].sample_stats[\"log_marginal_likelihood\"].mean()\n)\nnp.round(BF_smc).item()\n\n5.0\n\n\nComo podemos ver en la celda anterior, ¬°SMC da esencialmente la misma respuesta que el c√°lculo anal√≠tico!\nNota: En la celda de arriba calculamos una diferencia (en lugar de una divisi√≥n) porque estamos en la escala logar√≠tmica, por la misma raz√≥n tomamos la exponencial antes de devolver el resultado. Finalmente, la raz√≥n por la que calculamos la media es porque obtenemos un valor logar√≠tmico de probabilidad marginal por cadena.\nLa ventaja de usar SMC para calcular la verosimilitud marginal es que podemos usarlo para una gama m√°s amplia de modelos, ya que ya no necesitamos conocer una expresi√≥n en forma cerrada. El costo que pagamos por esta flexibilidad es un c√°lculo m√°s costoso. Adem√°s hay que tener en cuenta que SMC (con un kernel Metropolis independiente implementado en PyMC) no es tan eficiente como NUTS. A medida que aumenta la dimensionalidad del problema, una estimaci√≥n m√°s precisa de la posterior y la verosimilitud marginal requerir√° un mayor n√∫mero de muestras del posterior."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#factores-de-bayes-e-inferencia",
    "href": "07_Comparaci√≥n_de_modelos.html#factores-de-bayes-e-inferencia",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.10 Factores de bayes e inferencia",
    "text": "9.10 Factores de bayes e inferencia\nHasta ahora hemos usado los factores de Bayes para juzgar qu√© modelo parece ser mejor para explicar los datos, y obtenemos que uno de los modelos es \\(\\approx 5\\) mejor que el otro.\nPero, ¬øqu√© pasa con el posterior que obtenemos de estos modelos? ¬øQu√© tan diferentes son?\n\naz.summary(idatas[0], var_names=\"a\", kind=\"stats\").round(2)\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n    \n  \n  \n    \n      a\n      0.5\n      0.05\n      0.4\n      0.59\n    \n  \n\n\n\n\n\naz.summary(idatas[1], var_names=\"a\", kind=\"stats\").round(2)\n\n\n\n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n    \n  \n  \n    \n      a\n      0.5\n      0.04\n      0.42\n      0.57\n    \n  \n\n\n\n\nPodemos argumentar que los resultados son bastante similares, tenemos el mismo valor medio para \\(\\theta\\) y un posterior ligeramente m√°s ancho para model_0, como se esperaba ya que este modelo tiene un prior m√°s amplio. Tambi√©n podemos verificar la distribuci√≥n predictiva posterior para ver qu√© tan similares son.\n\nppc_0 = pm.sample_posterior_predictive(idatas[0], model=models[0]).posterior_predictive\nppc_1 = pm.sample_posterior_predictive(idatas[1], model=models[1]).posterior_predictive\n\nSampling: [yl]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00<00:00]\n    \n    \n\n\nSampling: [yl]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00<00:00]\n    \n    \n\n\n\n_, ax = plt.subplots(figsize=(9, 6))\n\nbins = np.linspace(0.2, 0.8, 8)\nax = az.plot_dist(\n    ppc_0[\"yl\"].mean(\"yl_dim_2\"),\n    label=\"model_0\",\n    kind=\"hist\",\n    hist_kwargs={\"alpha\": 0.5, \"bins\": bins},\n)\nax = az.plot_dist(\n    ppc_1[\"yl\"].mean(\"yl_dim_2\"),\n    label=\"model_1\",\n    color=\"C1\",\n    kind=\"hist\",\n    hist_kwargs={\"alpha\": 0.5, \"bins\": bins},\n    ax=ax,\n)\nax.legend()\nax.set_xlabel(\"$\\\\theta$\")\nax.xaxis.set_major_formatter(FormatStrFormatter(\"%0.1f\"))\nax.set_yticks([]);\n\n\n\n\nEn este ejemplo, los datos observados son m√°s consistentes con el modelo_1, por que el prior se concentra en torno al valor correcto de \\(\\theta\\), mientras que el modelo_0, asigna la misma probabilidad a todos los valores posibles de \\(\\theta\\). Esta diferencia entre los modelos es capturada por el factor de Bayes. Podr√≠amos decir que los factores de Bayes miden qu√© modelo, en su conjunto, es mejor para explicar los datos. Y esto incluye los detalles del prior, sin importar cuan similares son las predicciones de los modelos. En muchos escenarios lo que nos interesa al comparar modelos es cuan similares son las predicciones. Que es lo que estima LOO o validaci√≥n cruzada."
  },
  {
    "objectID": "07_Comparaci√≥n_de_modelos.html#cociente-de-savage-dickey",
    "href": "07_Comparaci√≥n_de_modelos.html#cociente-de-savage-dickey",
    "title": "8¬† Comparaci√≥n de modelos",
    "section": "9.11 Cociente de Savage-Dickey",
    "text": "9.11 Cociente de Savage-Dickey\nPara los ejemplos anteriores hemos comparado dos modelos beta-binomiales, podr√≠amos haber comparado dos modleos completamente diferentes. Pero hay veces que queremos comparar una hip√≥tesis nula H_0 (o modelo nulo) contra una alternativa H_1. Por ejemplo, para responder a la pregunta ¬øEst√° sesgada esta moneda?, podr√≠amos comparar el valor \\(\\theta = 0.5\\) (que representa el no-sesgo) con el resultado de un modelo en el que permitimos que \\(\\theta\\) var√≠e. Para este tipo de comparaci√≥n, el modelo nulo est√° anidado dentro de la alternativa, lo que significa que el valor nulo es un valor particular del modelo que estamos construyendo. En esos casos, calcular el factor de Bayes es muy f√°cil y no requiere ning√∫n m√©todo especial. Solo necesitamos comparar el prior y el posterior evaluados en el valor nulo (por ejemplo \\(\\theta = 0.5\\) ), bajo el modelo alternativo. Podemos ver que esto es cierto a partir de la siguiente expresi√≥n:\n\\[\nBF_{01} = \\frac{p(y \\mid H_0)}{p(y \\mid H_1)} \\frac{p(\\theta=0.5 \\mid y, H_1)}{p(\\theta=0.5 \\mid H_1)}\n\\]\nQue es cierta solo cuando H_0 es un caso particular de H_1.\nHag√°moslo con PyMC y ArviZ. Solo necesitamos obtener muestras del prior y del posterior para un modelo. Probemos con el modelo beta-binomial con prior uniforme.\n\nwith pm.Model() as model_uni:\n    a = pm.Beta(\"a\", 1, 1)\n    yl = pm.Bernoulli(\"yl\", a, observed=y)\n    idata_uni = pm.sample(2000, random_seed=42)\n    idata_uni.extend(pm.sample_prior_predictive(8000))\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [a]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:03<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 4 seconds.\nSampling: [a, yl]\n\n\nY ahora llamamos a la funci√≥n de ArviZ az.plot_bf\n\naz.plot_bf(idata_uni, var_name=\"a\", ref_val=0.5);\n\n\n\n\nEl gr√°fico muestra un KDE para el prior (azul) y otro para el posterior (turquesa). Los dos puntos negros muestran que evaluamos ambas distribuciones en el valor 0.5. Podemos ver que el factor de Bayes a favor de la hip√≥tesis nula, BF_01, es \\(\\approx 8\\), lo que podemos interpretar como una evidencia moderada a favor de la hip√≥tesis nula (ver la escala de Jeffreys que discutimos antes).\nComo ya comentamos, los factores de Bayes miden qu√© modelo, en su conjunto, es mejor para explicar los datos. Y esto incluye el prior, incluso si el prior tiene un impacto relativamente bajo en el c√≥mputo del posterior. Tambi√©n podemos ver este efecto del prior al comparar un segundo modelo con el modelo nulo.\nSi en cambio nuestro modelo fuera un beta-binomial con beta prior (30, 30), el BF_01 ser√≠a m√°s bajo (anecd√≥tico en la escala de Jeffrey). Esto se debe a que, seg√∫n este modelo, el valor de \\(\\theta=0.5\\) es mucho m√°s probable priori que para un prior uniforme y, por lo tanto, el posterior y el prior ser√°n mucho m√°s similares. Es decir, no hay demasiada sorpresa al ver la que el posterior se concentra alrededor de 0.5 despu√©s de recopilar datos.\nVamos a calcularlo para verlo por nosotros mismos.\n\nwith pm.Model() as model_conc:\n    a = pm.Beta(\"a\", 30, 30)\n    yl = pm.Bernoulli(\"yl\", a, observed=y)\n    idata_conc = pm.sample(2000, random_seed=42)\n    idata_conc.extend(pm.sample_prior_predictive(8000))\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [a]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:04<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 4 seconds.\nSampling: [a, yl]\n\n\n\naz.plot_bf(idata_conc, var_name=\"a\", ref_val=0.5);"
  }
]