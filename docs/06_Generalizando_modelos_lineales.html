<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>generalizando_modelos_lineales</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        <div class="sidebar-tools-collapse">
    <a href="" title="" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-github"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-collapse-item" href="https://github.com/Grupo-de-modelado-probabilista/Modelado_Bayesiano">
          Fuente
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-collapse-item" href="https://github.com/Grupo-de-modelado-probabilista/Modelado_Bayesiano/issues/new">
          Reportar errores
          </a>
        </li>
    </ul>
</div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">home</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Introducción al modelado, inferencia y análisis de modelos Bayesianos</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Capítulo 0</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_Probabilidad.html" class="sidebar-item-text sidebar-link">Probabilidad</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Capítulo 1</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Inferencia_Bayesiana.html" class="sidebar-item-text sidebar-link">Inferencia Bayesiana</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Capítulo 2</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Programación_probabilística.html" class="sidebar-item-text sidebar-link">Programación probabilista</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Capítulo 3</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Modelos_jerárquicos.html" class="sidebar-item-text sidebar-link">Modelado Jerárquico</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">Capítulo 4</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Diagnóstico_MCMC.html" class="sidebar-item-text sidebar-link">MCMC y diagnóstico del muestro</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">Capítulo 5</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Regresión_lineal.html" class="sidebar-item-text sidebar-link">Regresión Lineal</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Capítulo 6</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_Generalizando_modelos_lineales.html" class="sidebar-item-text sidebar-link active">Generalizando modelos lineales</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">Capítulo 7</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_Comparación_de_modelos.html" class="sidebar-item-text sidebar-link">Comparación de modelos</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#generalizando-modelos-lineales" id="toc-generalizando-modelos-lineales" class="nav-link active" data-scroll-target="#generalizando-modelos-lineales">Generalizando modelos lineales</a>
  <ul class="collapse">
  <li><a href="#regresión-polinomial" id="toc-regresión-polinomial" class="nav-link" data-scroll-target="#regresión-polinomial">Regresión polinomial</a>
  <ul class="collapse">
  <li><a href="#interpretando-los-parámetros-de-una-regresión-polinomial" id="toc-interpretando-los-parámetros-de-una-regresión-polinomial" class="nav-link" data-scroll-target="#interpretando-los-parámetros-de-una-regresión-polinomial">Interpretando los parámetros de una regresión polinomial</a></li>
  </ul></li>
  <li><a href="#varianza-variable" id="toc-varianza-variable" class="nav-link" data-scroll-target="#varianza-variable">Varianza variable</a></li>
  <li><a href="#modelos-lineales-generalizados" id="toc-modelos-lineales-generalizados" class="nav-link" data-scroll-target="#modelos-lineales-generalizados">Modelos lineales generalizados</a></li>
  <li><a href="#regresión-logística" id="toc-regresión-logística" class="nav-link" data-scroll-target="#regresión-logística">Regresión logística</a></li>
  <li><a href="#el-conjunto-de-datos-del-iris" id="toc-el-conjunto-de-datos-del-iris" class="nav-link" data-scroll-target="#el-conjunto-de-datos-del-iris">El conjunto de datos del Iris</a>
  <ul class="collapse">
  <li><a href="#el-modelo-logístico-aplicado-al-conjunto-de-datos-del-iris." id="toc-el-modelo-logístico-aplicado-al-conjunto-de-datos-del-iris." class="nav-link" data-scroll-target="#el-modelo-logístico-aplicado-al-conjunto-de-datos-del-iris.">El modelo logístico aplicado al conjunto de datos del iris.</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#regresión-logística-múltiple" id="toc-regresión-logística-múltiple" class="nav-link" data-scroll-target="#regresión-logística-múltiple">Regresión logística múltiple</a>
  <ul class="collapse">
  <li><a href="#el-límite-de-decisión" id="toc-el-límite-de-decisión" class="nav-link" data-scroll-target="#el-límite-de-decisión">El límite de decisión</a></li>
  <li><a href="#implementando-el-modelo" id="toc-implementando-el-modelo" class="nav-link" data-scroll-target="#implementando-el-modelo">Implementando el modelo</a></li>
  <li><a href="#interpretación-de-los-coeficientes-de-una-regresión-logística" id="toc-interpretación-de-los-coeficientes-de-una-regresión-logística" class="nav-link" data-scroll-target="#interpretación-de-los-coeficientes-de-una-regresión-logística">Interpretación de los coeficientes de una regresión logística</a></li>
  <li><a href="#trabajando-con-variables-correlacionadas" id="toc-trabajando-con-variables-correlacionadas" class="nav-link" data-scroll-target="#trabajando-con-variables-correlacionadas">Trabajando con variables correlacionadas</a></li>
  <li><a href="#tratando-con-clases-desequilibradas" id="toc-tratando-con-clases-desequilibradas" class="nav-link" data-scroll-target="#tratando-con-clases-desequilibradas">Tratando con clases desequilibradas</a></li>
  <li><a href="#regresión-softmax-o-multinomial" id="toc-regresión-softmax-o-multinomial" class="nav-link" data-scroll-target="#regresión-softmax-o-multinomial">Regresión softmax (o multinomial)</a></li>
  <li><a href="#linear-discriminant-analysis-lda" id="toc-linear-discriminant-analysis-lda" class="nav-link" data-scroll-target="#linear-discriminant-analysis-lda">Linear discriminant analysis (LDA)</a></li>
  <li><a href="#regresión-de-poisson" id="toc-regresión-de-poisson" class="nav-link" data-scroll-target="#regresión-de-poisson">Regresión de Poisson</a>
  <ul class="collapse">
  <li><a href="#la-distribución-de-poisson" id="toc-la-distribución-de-poisson" class="nav-link" data-scroll-target="#la-distribución-de-poisson">La distribución de Poisson</a></li>
  </ul></li>
  <li><a href="#el-modelo-de-poisson-inflado-de-ceros" id="toc-el-modelo-de-poisson-inflado-de-ceros" class="nav-link" data-scroll-target="#el-modelo-de-poisson-inflado-de-ceros">El modelo de Poisson inflado de ceros</a></li>
  <li><a href="#regresión-de-poisson-y-regresión-zip" id="toc-regresión-de-poisson-y-regresión-zip" class="nav-link" data-scroll-target="#regresión-de-poisson-y-regresión-zip">Regresión de Poisson y regresión ZIP</a></li>
  <li><a href="#regresión-por-cuantiles" id="toc-regresión-por-cuantiles" class="nav-link" data-scroll-target="#regresión-por-cuantiles">Regresión por cuantiles</a></li>
  <li><a href="#resumen" id="toc-resumen" class="nav-link" data-scroll-target="#resumen">Resumen</a></li>
  <li><a href="#ejercicios" id="toc-ejercicios" class="nav-link" data-scroll-target="#ejercicios">Ejercicios</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="generalizando-modelos-lineales" class="level1">
<h1>Generalizando modelos lineales</h1>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> preliz <span class="im">as</span> pz</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> expit <span class="im">as</span> logistic</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>warnings.simplefilter(action<span class="op">=</span><span class="st">'ignore'</span>, category<span class="op">=</span><span class="pp">FutureWarning</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>az.style.use(<span class="st">'arviz-doc'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>En el último capítulo, usamos una combinación lineal de variables independientes para predecir la media de una variable dependiente. Asumimos que en general la variable dependiente se distribuía como una Gaussiana y también exploramos que sucedía al relajar esta condición y usar una distribución t de Student. En este capítulo veremos que es posible realizar otras variantes sobre la idea central de modelo lineal</p>
<p>En el presente capítulo veremos:</p>
<ul>
<li>Regresión polinomial</li>
<li>Varianza no constante</li>
<li>Regresión logística</li>
<li>La función de softmax y la regresión logística multinomial</li>
<li>Regresión de Poisson</li>
<li>Regresión de Poisson cero-inflada</li>
</ul>
<section id="regresión-polinomial" class="level2">
<h2 class="anchored" data-anchor-id="regresión-polinomial">Regresión polinomial</h2>
<p>Ahora vamos a aprender cómo ajustar curvas usando una regresión lineal. Una manera de ajustar curvas usando un modelo de regresión lineal es construyendo un polinomio como este:</p>
<p><span class="math display">\[\mu = \beta_0 x^0 + \beta_1 x^1  \dots + \beta_m x^m \tag{3.12} \]</span></p>
<p>Si prestamos atención, podemos ver que este polinomio <em>esconde</em> un modelo lineal simple. De hecho si hacemos que <span class="math inline">\(\beta_n = 0\)</span> para <span class="math inline">\(n \gt 1\)</span> obtendremos:</p>
<p><span class="math display">\[\mu = \beta_0 + \beta_1 x^1 \tag{3.13} \]</span></p>
<p>Que no es otra cosa que la ecuación de una recta. Una regresión polinomial sigue siendo una regresión lineal, ya que la linearidad del modelo está relacionada con la forma en que los parámetros entran en el modelo y no con las variables. Probemos construyendo una regresión polinomial de grado 2.</p>
<p><span class="math display">\[\mu = \beta_0 + \beta_1 x^1 + \beta_2 x^2 \tag{3.14} \]</span></p>
<p>El tercer término controla la curvatura de la relación como veremos a continuación.</p>
<p>Como un conjunto de datos, vamos a utilizar el segundo grupo del cuarteto de Anscombe.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>ans <span class="op">=</span> pd.read_csv(<span class="st">'datos/anscombe.csv'</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>x_2 <span class="op">=</span> ans[ans.group <span class="op">==</span> <span class="st">'II'</span>][<span class="st">'x'</span>].values</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>y_2 <span class="op">=</span> ans[ans.group <span class="op">==</span> <span class="st">'II'</span>][<span class="st">'y'</span>].values</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>x_2 <span class="op">=</span> x_2 <span class="op">-</span> x_2.mean()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>y_2 <span class="op">=</span> y_2 <span class="op">-</span> y_2.mean()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_2, y_2)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>, rotation<span class="op">=</span><span class="dv">0</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_poly:</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span>y_2.mean(), sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    β<span class="dv">1</span> <span class="op">=</span> pm.Normal(<span class="st">'β1'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    β<span class="dv">2</span> <span class="op">=</span> pm.Normal(<span class="st">'β2'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    ϵ <span class="op">=</span> pm.HalfNormal(<span class="st">'ϵ'</span>, <span class="dv">10</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> α <span class="op">+</span> β<span class="dv">1</span> <span class="op">*</span> x_2 <span class="op">+</span> β<span class="dv">2</span> <span class="op">*</span> x_2<span class="op">**</span><span class="dv">2</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> pm.Normal(<span class="st">'y_pred'</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>ϵ, observed<span class="op">=</span>y_2)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    idata_poly <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β1, β2, ϵ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.</code></pre>
</div>
</div>
<p>Once again, we are going to omit some checks and summaries and just plot the results, a nice curved line fitting the data almost with no errors. Take into account the minimalistic nature of the dataset.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>az.plot_trace(idata_poly)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>az.summary(idata_poly)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>α</th>
      <td>1.267</td>
      <td>0.001</td>
      <td>1.265</td>
      <td>1.269</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1857.0</td>
      <td>1551.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>β1</th>
      <td>0.500</td>
      <td>0.000</td>
      <td>0.500</td>
      <td>0.500</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2638.0</td>
      <td>1874.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>β2</th>
      <td>-0.127</td>
      <td>0.000</td>
      <td>-0.127</td>
      <td>-0.127</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1911.0</td>
      <td>1786.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>ϵ</th>
      <td>0.002</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>0.003</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1433.0</td>
      <td>1578.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>x_p <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>post_mean <span class="op">=</span> idata_poly.posterior.mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>y_p <span class="op">=</span> post_mean[<span class="st">'α'</span>].item() <span class="op">+</span> post_mean[<span class="st">'β1'</span>].item() <span class="op">*</span> x_p <span class="op">+</span> post_mean[<span class="st">'β2'</span>].item() <span class="op">*</span> x_p<span class="op">**</span><span class="dv">2</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_2, y_2)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>,)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>, rotation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>plt.plot(x_p, y_p, c<span class="op">=</span><span class="st">'C1'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<section id="interpretando-los-parámetros-de-una-regresión-polinomial" class="level3">
<h3 class="anchored" data-anchor-id="interpretando-los-parámetros-de-una-regresión-polinomial">Interpretando los parámetros de una regresión polinomial</h3>
<p>Uno de los problemas de la regresión polinómica es la interpretación de sus parámetros. Si queremos saber cómo cambia <span class="math inline">\(y\)</span> por unidad de cambio de <span class="math inline">\(x\)</span>, no podemos simplemente verificar el valor de <span class="math inline">\(\beta_1\)</span>, ya que <span class="math inline">\(\beta_2\)</span>, y los coeficientes más altos (de estar presentes), tendrán un efecto en dicha cantidad. Entonces los coeficientes <span class="math inline">\(\beta\)</span> ya no son pendientes, son otra cosa. En el ejemplo anterior, <span class="math inline">\(\beta_1\)</span> es positivo y, por lo tanto, la curva comienza con una pendiente positiva, pero <span class="math inline">\(\beta_2\)</span> es negativo y, por lo tanto, después de un tiempo, la línea comienza a curvarse hacia abajo. Es como si tuviéramos dos fuerzas en juego, una empujando la línea hacia arriba y la otra hacia abajo. La interacción depende del valor de <span class="math inline">\(x\)</span>. Cuando <span class="math inline">\(x \lessapprox 11\)</span> (en la escala original, o 2 en la escala centrada), la contribución dominante proviene de <span class="math inline">\(\beta_1\)</span>, y cuando <span class="math inline">\(x \gtrapprox 11\)</span>, entonces <span class="math inline">\(\beta_2\)</span> domina.</p>
<p>El principal problema de interpretar los parámetros en modelos polinomiales, es que en general los parámetros no se traducen a cantidades que tengan sentido a la luz de nuestro conocimiento de dominio. Es decir no podemos relacionarlos con la tasa metabólica de una célula, la energía emitida por una galaxia o el número de habitaciones en una casa. Los parámetros terminan siendo simplemente <em>perillas</em> que podemos manipular para mejorar el ajuste pero sin un significado claro. En la práctica, la mayoría de la gente suele estar de acuerdo en que los polinomios de orden superior a dos o tres generalmente no son modelos muy útiles y se prefieren alternativas, quizá como splines o los Procesos Gaussianos.</p>
<p>En este <a href="https://www.tandfonline.com/doi/abs/10.1207/S15327906MBR3704_04">trabajo</a> se propone una versión interpretable (y no lineal) de un polinomio de grado 2.</p>
<p><span class="math display">\[
\alpha_y - (\alpha_y - \alpha_0) \left(\frac{x_i}{\alpha_x} -1\right)^2
\]</span> * <span class="math inline">\(\alpha_0\)</span> : intercepto, valor de <span class="math inline">\(Y\)</span> cuando <span class="math inline">\(x=0\)</span> * <span class="math inline">\(\alpha_x\)</span> : valor de <span class="math inline">\(x_i\)</span> que maximiza/minimiza <span class="math inline">\(Y\)</span> * <span class="math inline">\(\alpha_y\)</span> : valor máximo/mínimo de <span class="math inline">\(Y\)</span></p>
</section>
</section>
<section id="varianza-variable" class="level2">
<h2 class="anchored" data-anchor-id="varianza-variable">Varianza variable</h2>
<p>Hemos estado usando el modelo lineal para modelar la media de una distribución, dejando la varianza de lado. En caso que consideremos que el supuesto de varianza constante no tiene sentido podemos considerar la varianza como una función (lineal) de la variable dependiente.</p>
<p>La Organización Mundial de la Salud y otras instituciones de salud de todo el mundo recopilan datos para recién nacidos y adultos mayores y diseñan estándares de gráficos de crecimiento. Estas tablas son un componente esencial del conjunto de herramientas pediátricas y también como una medida del bienestar general de las poblaciones con el fin de formular políticas de salud, planificar intervenciones y controlar su eficacia. Un ejemplo de tales datos son la longitud (alturas) de las niñas recién nacidas en función de la edad (en meses):</p>
<div class="cell" data-execution_count="284">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'datos/babies.csv'</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>data.plot.scatter(<span class="st">'Meses'</span>, <span class="st">'Longitud'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Para modelar estos datos, presentaremos 3 elementos nuevos en comparación con los modelos anteriores:</p>
<ul>
<li><span class="math inline">\(\epsilon\)</span> ahora es una función lineal de <span class="math inline">\(x\)</span>, y para hacer esto agregamos dos nuevos parámetros <span class="math inline">\(\gamma\)</span> y <span class="math inline">\(\delta\)</span>, estos son análogos directos de <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span>.</li>
<li>El modelo lineal para la media es una función de <span class="math inline">\(\sqrt{x}\)</span>, esto es solo un truco simple para ajustar un modelo lineal a una curva.</li>
<li>Hemos definido una variable compartida <code>x_shared</code>, esto nos permitirá cambiar los valores de la variable <span class="math inline">\(x\)</span> (<code>Meses</code> en este ejemplo) sin la necesidad de volver a muestrear el modelo. Por qué hacemos estos será evidente pronto si tienen un poco de paciencia.</li>
</ul>
<div class="cell" data-execution_count="288">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_vv:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    x_shared <span class="op">=</span> pm.MutableData(<span class="st">"x_shared"</span>, data.Meses.values.astype(<span class="bu">float</span>))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    γ <span class="op">=</span> pm.HalfNormal(<span class="st">'γ'</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    δ <span class="op">=</span> pm.HalfNormal(<span class="st">'δ'</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> pm.Deterministic(<span class="st">'μ'</span>, α <span class="op">+</span> β <span class="op">*</span> x_shared<span class="op">**</span><span class="fl">0.5</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    ϵ <span class="op">=</span> pm.Deterministic(<span class="st">'ϵ'</span>, γ <span class="op">+</span> δ <span class="op">*</span> x_shared)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> pm.Normal(<span class="st">'y_pred'</span>, mu<span class="op">=</span>μ, sigma<span class="op">=</span>ϵ, observed<span class="op">=</span>data.Longitud)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    idata_vv <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β, γ, δ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.</code></pre>
</div>
</div>
<p>La siguiente figura muestra el resultado de nuestro modelo. La media de es <span class="math inline">\(\mu\)</span> representada con una curva negra, y dos bandas turquesa semitransparentes representan 1 y 2 desviaciones estándar.</p>
<div class="cell" data-execution_count="289">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(data.Meses, data.Longitud, <span class="st">'C0.'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>)<span class="op">;</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>posterior <span class="op">=</span> az.extract(idata_vv)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>μ_m <span class="op">=</span> posterior[<span class="st">'μ'</span>].mean(<span class="st">"sample"</span>).values</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>ϵ_m <span class="op">=</span> posterior[<span class="st">'ϵ'</span>].mean(<span class="st">"sample"</span>).values</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(data.Meses, μ_m, c<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].fill_between(data.Meses, μ_m <span class="op">+</span> <span class="dv">1</span> <span class="op">*</span> ϵ_m, μ_m <span class="op">-</span> <span class="dv">1</span> <span class="op">*</span> ϵ_m, alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span><span class="st">'C1'</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].fill_between(data.Meses, μ_m <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> ϵ_m, μ_m <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> ϵ_m, alpha<span class="op">=</span><span class="fl">0.4</span>, color<span class="op">=</span><span class="st">'C1'</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Meses'</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Longitud'</span>)<span class="op">;</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(data.Meses, ϵ_m)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Meses'</span>)<span class="op">;</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="vs">r'$\bar ϵ$'</span>, rotation<span class="op">=</span><span class="dv">0</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Ahora que tenemos ajustado el modelo podríamos querer averiguar cómo se compara la longitud de una niña en particular con el modelo. Una forma de responder a esta pregunta es preguntarle al modelo por la distribución de la variable <em>longitud</em> para bebas de digamos de 0.5 meses. Usando PyMC3 podemos hacer estas preguntas con la función sample_ppc, ya que esto arrojará muestras de <span class="math inline">\(\tilde y\)</span> es decir los valores predichos considerando la incertidumbre de los parámetros. El único problema es que, por defecto, esta función devolverá valores de <span class="math inline">\(\tilde y\)</span> para los valores observados de <span class="math inline">\(x\)</span> y de 0,5 meses (el valor que me importa) no es parte de los datos originales. La manera más fácil de obtener predicciones para valores no observados es definir una variable compartida <span class="math inline">\(x\)</span> (como parte del modelo) y luego actualizar el valor de la variable compartida justo antes del muestreo de la distribución predictiva <em>a posteriori</em>.</p>
<div class="cell" data-execution_count="290">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> model_vv:</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    pm.set_data({<span class="st">"x_shared"</span>: [<span class="fl">0.5</span>]})</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    ppc <span class="op">=</span> pm.sample_posterior_predictive(idata_vv)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    y_ppc <span class="op">=</span> ppc.posterior_predictive[<span class="st">'y_pred'</span>].stack(sample<span class="op">=</span>(<span class="st">"chain"</span>, <span class="st">"draw"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [y_pred]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4000" class="" max="4000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4000/4000 00:00&lt;00:00]
    </div>
    
</div>
</div>
<p>Ahora podemos graficar la distribución esperada de las longitudes para las bebas con 2 semanas de vida y calcular cantidades adicionales, por ejemplo, el percentil de un niño para su longitud:</p>
<div class="cell" data-execution_count="293">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>ref <span class="op">=</span> <span class="fl">52.5</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>grid, pdf <span class="op">=</span> az.stats.density_utils._kde_linear(y_ppc.values)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plt.plot(grid, pdf)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>percentile <span class="op">=</span> <span class="bu">int</span>((y_ppc <span class="op">&lt;=</span> ref).mean() <span class="op">*</span> <span class="dv">100</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>plt.fill_between(grid[grid <span class="op">&lt;</span> ref], pdf[grid <span class="op">&lt;</span> ref], label<span class="op">=</span><span class="st">'percentil = </span><span class="sc">{:2d}</span><span class="st">'</span>.<span class="bu">format</span>(percentile))</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'longitud'</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>plt.yticks([])</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="modelos-lineales-generalizados" class="level2">
<h2 class="anchored" data-anchor-id="modelos-lineales-generalizados">Modelos lineales generalizados</h2>
<p>Hasta el momento hemos asumido que la variable dependiente puede variar, a priori, sin restricciones y por ello usamos como likelihood una Gaussiana (o una generalización de esta como lo es la t de Student). Pero que podemos hacer si la variable respuesta está restringida a ser positiva, o discreta, o en el intervalo [0, 1], etc. Usando software como PyMC bastaría con cambiar el likelihood de una Gaussiana a una Poisson (o lo que haga falta), pero si solo hacemos eso tendremos problemas, ya que la combinación lineal de parámetros podría dar valores fuera del rango permitido (por ej negativos). Para subsanar este problema podemos aplicar una función a la combinación lineal de variables de entrada, algo como:</p>
<p><span class="math display">\[\mu = f(\alpha + X \beta) \tag{4.1}\]</span></p>
<p>donde <span class="math inline">\(f\)</span> es lo que se conoce como función inversa de enlace. Hay una gran variedad de funciones inversas de enlace que podemos elegir, probablemente la más simple sea la función identidad. Esta es una función que devuelve el mismo valor utilizado como argumento. Todos los modelos del capítulo anterior usaron la función de identidad, y por simplicidad simplemente la omitimos. La función de identidad puede no ser muy útil en sí misma, pero nos permite pensar en varios modelos diferentes de una manera unificada.</p>
<blockquote class="blockquote">
<p>¿Por qué llamamos a <span class="math inline">\(f\)</span> <em>función inversa de enlace</em> en lugar de llamarla simplemente función de enlace? La razón es histórica. Tradicionalmente las personas aplican funciones <em>al otro lado</em> de la ecuación <span class="math inline">\(4.1\)</span>, y llaman a esas funciones <em>funciones de enlace</em>, por lo tanto, para evitar confusiones, nos apegaremos al término función inveras de enlace.</p>
</blockquote>
<p>Veamos algunos ejemplos concretos de modelos lineales generalizados</p>
</section>
<section id="regresión-logística" class="level2">
<h2 class="anchored" data-anchor-id="regresión-logística">Regresión logística</h2>
<p>La regresión logistica es la generalización del modelo de regresión que vimos en el capítulo pasado para cuando la variable dependiente es binaria. Esta generalización se logra en dos pasos. Primero reemplazamos <span class="math inline">\(f\)</span> en <span class="math inline">\(4.1\)</span> por la función logística:</p>
<p><span class="math display">\[ \text{logística}(z) = \frac{1}{1 + e^{-z}} \tag{4.2}\]</span></p>
<p>Usamos esta función por que una de sus propiedades es que no importa el valor del argumento <span class="math inline">\(z\)</span>, el resultado siempre será un valor en el intervalo [0-1]. La función logística es conocida también como función sigmoide, por su aspecto típico de <em>S</em> como se puede ver al ejecutar la siguiente celda:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>logística <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>plt.plot(z, logística)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'z'</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'logística(z)'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>El segundo paso consiste en usar como likelihood una distribución binomial y no una Gaussiana. De esta forma el modelo queda expresado como:</p>
<p><span class="math display">\[
\theta = logistic(\alpha + x\beta) \\
y = \text{Bern}(\theta) \tag{4.3}
\]</span></p>
<p>Esto modelo se puede motivar de la siguiente forma. Si nuestros datos son binarios <span class="math inline">\(y \in \{0, 1\}\)</span>, como con el ejemplo de la moneda o el diagnóstico, vemos que tiene sentido usar una distribución bernoulli. Esta distribución está parametrizada por un único parámetro en el intervalo [0, 1], el cual puede ser generado desde un modelo lineal siempre y cuando los valores generados por el modelo lineal sean <em>comprimidos</em> al intervalo [0, 1], algo que puede ser obtenido al emplear una función logística.</p>
<p>Usando un diagrama de Kruschke una regresión logística con priors Gaussianos:</p>
<p><img alt="regresión_logística" src="imagenes/logística.png" width="250"></p>
</section>
<section id="el-conjunto-de-datos-del-iris" class="level2">
<h2 class="anchored" data-anchor-id="el-conjunto-de-datos-del-iris">El conjunto de datos del Iris</h2>
<p>Vamos a aplicar una regresión logística al conjunto de datos Iris. Este es un conjunto de datos clásico que contiene información sobre flores de 3 especies estrechamente relacionadas: setosa, virginica y versicolor. Estas serán nuestras variables dependientes, las clases que queremos predecir. Tenemos 50 individuos de cada especie y para cada individuo el conjunto de datos contiene cuatro variables (o <em>features</em>) que vamos a usar como variables independientes. Estas son el largo del pétalo, el ancho del pétalo, el largo del sépalo y el ancho del sépalo. Por si se lo están preguntando, los sépalos son hojas modificadas, cuya función está generalmente relacionada con la protección de las flores en la yema.</p>
<p>Podemos cargar un DataFrame con el conjunto de datos del iris haciendo:</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> pd.read_csv(<span class="st">'datos/iris.csv'</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>iris.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>sepal_length</th>
      <th>sepal_width</th>
      <th>petal_length</th>
      <th>petal_width</th>
      <th>species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Ahora graficaremos las 3 especies versus la longitud del sépalo usando la función stripplot de seaborn:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>sns.stripplot(x<span class="op">=</span><span class="st">"species"</span>, y<span class="op">=</span><span class="st">"sepal_length"</span>, data<span class="op">=</span>iris, hue<span class="op">=</span><span class="st">"species"</span>, jitter<span class="op">=</span><span class="va">True</span>, legend<span class="op">=</span><span class="va">False</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Observe en la figura 4.2 que en el eje <code>y</code> se representan una variable continua mientras que en el eje <code>x</code> la variable es categórica. La dispersión (o <em>jitter</em>) de los puntos a lo largo del eje <code>x</code> no tiene ningún significado, y es solo un <em>truco</em> para evitar que todos los puntos colapsen en una sola línea (pueden probar pasando el argumento <code>jitter=False</code>). Por lo tanto lo único que importa al leer el eje <code>x</code> es la pertenencia de los puntos a las clases <code>setosa</code>, <code>versicolor</code> o <code>virginica</code>.</p>
<p>Otra forma de inspeccionar los datos es haciendo una matriz de dispersión con la función <code>pairplot</code>. En la figura 4.3 podemos ver una matriz de <span class="math inline">\(4 \times 4\)</span>, ya que tenemos 4 variables independientes (o <em>features</em>). La matriz es simétrica con los triángulos superior e inferior conteniendo la misma información. En la diagonal principal en vez de tener una gráfico de dispersión de una variable contra si misma (lo cual no es informativo) tenemos un KDE de cada feature para cada especie (o clase). Cada especie está representada usando un color particular.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>sns.pairplot(iris, hue<span class="op">=</span><span class="st">'species'</span>, plot_kws<span class="op">=</span>{<span class="st">"legend"</span>:<span class="va">False</span>})<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/osvaldo/anaconda3/envs/bayes/lib/python3.9/site-packages/seaborn/axisgrid.py:118: UserWarning: This figure was using constrained_layout, but that is incompatible with subplots_adjust and/or tight_layout; disabling constrained_layout.
  self._figure.tight_layout(*args, **kwargs)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-17-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Antes de continuar, tómese un tiempo para estudiar las gráficas anteriores y familiarizarse con el conjunto de datos y cómo se relacionan las variables dependientes y las independientes.</p>
<section id="el-modelo-logístico-aplicado-al-conjunto-de-datos-del-iris." class="level3">
<h3 class="anchored" data-anchor-id="el-modelo-logístico-aplicado-al-conjunto-de-datos-del-iris.">El modelo logístico aplicado al conjunto de datos del iris.</h3>
<p>Vamos a comenzar con la regresión logística más simple posible: dos clases, setosa y versicolor, y solo una variable independiente, la longitud del sépalo. Como se hace normalmente, vamos a codificar las variables categóricas setosa y versicolor con los números 0 y 1. Usando Pandas podemos hacer:</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> iris.query(<span class="st">"species == ('setosa', 'versicolor')"</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>y_0 <span class="op">=</span> pd.Categorical(df[<span class="st">'species'</span>]).codes</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>x_n <span class="op">=</span> <span class="st">'sepal_length'</span> </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>x_0 <span class="op">=</span> df[x_n].values</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>x_c <span class="op">=</span> x_0 <span class="op">-</span> x_0.mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Al igual que con otros modelos lineales, centrar los datos puede ayudar con el muestreo. Ahora que tenemos los datos en el formato adecuado, finalmente podemos construir el modelo con PyMC.</p>
<p>Observe cómo la primera parte del siguiente modelo se asemeja a un modelo de regresión lineal. Este modelo tiene dos variables deterministas: <code>θ</code> y<code>bd</code>. <code>θ</code> es la salida de la función logística aplicada a la variable <code>μ</code> y <code>bd</code> es límite de decisión (el cual explicaremos más adelante).Otro punto que vale la pena mencionar es que en lugar de escribir explícitamente la función logística estamos usando <code>pm.math.sigmoid</code> (esto es un alias para una función de Theano).</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_0:</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> α <span class="op">+</span> pm.math.dot(x_c, β)    </span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    θ <span class="op">=</span> pm.Deterministic(<span class="st">'θ'</span>, pm.math.sigmoid(μ))</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    bd <span class="op">=</span> pm.Deterministic(<span class="st">'bd'</span>, <span class="op">-</span>α<span class="op">/</span>β)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    yl <span class="op">=</span> pm.Bernoulli(<span class="st">'yl'</span>, p<span class="op">=</span>θ, observed<span class="op">=</span>y_0)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    idata_0 <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.</code></pre>
</div>
</div>
<p>Como es habitual, también mostramos el summary del posterior. Más adelante, compararemos el valor que obtengamos para el límite de decisión con un valor calculado utilizando otro método.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>az.plot_trace(idata_0, var_names<span class="op">=</span><span class="st">'~θ'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>az.summary(idata_0, var_names<span class="op">=</span><span class="st">'~θ'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>α</th>
      <td>0.300</td>
      <td>0.332</td>
      <td>-0.322</td>
      <td>0.907</td>
      <td>0.006</td>
      <td>0.005</td>
      <td>3040.0</td>
      <td>2833.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>β</th>
      <td>5.376</td>
      <td>1.064</td>
      <td>3.511</td>
      <td>7.416</td>
      <td>0.020</td>
      <td>0.014</td>
      <td>3087.0</td>
      <td>2711.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>bd</th>
      <td>-0.055</td>
      <td>0.061</td>
      <td>-0.169</td>
      <td>0.060</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>3104.0</td>
      <td>2881.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Ahora vamos a graficar los datos junto con la curva sigmoide ajustada:</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>_, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>post_0 <span class="op">=</span> az.extract(idata_0)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> post_0[<span class="st">'θ'</span>].mean(<span class="st">"sample"</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.argsort(x_c)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>ax.plot(x_c[idx], theta[idx], color<span class="op">=</span><span class="st">'C8'</span>, lw<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>ax.vlines(post_0[<span class="st">'bd'</span>].mean(<span class="st">"sample"</span>), <span class="dv">0</span>, <span class="dv">1</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>bd_hdi <span class="op">=</span> az.hdi(post_0.unstack())[<span class="st">"bd"</span>]</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>ax.fill_betweenx([<span class="dv">0</span>, <span class="dv">1</span>], bd_hdi[<span class="dv">0</span>], bd_hdi[<span class="dv">1</span>], color<span class="op">=</span><span class="st">'k'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>ax.scatter(x_c, np.random.normal(y_0, <span class="fl">0.02</span>), marker<span class="op">=</span><span class="st">'.'</span>, color<span class="op">=</span>[<span class="ss">f'C</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> x <span class="kw">in</span> y_0])</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>theta_hdi <span class="op">=</span> az.hdi(post_0.unstack())[<span class="st">'θ'</span>][idx]</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>ax.fill_between(x_c[idx], theta_hdi[:,<span class="dv">0</span>], theta_hdi[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'C8'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(x_n)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'θ'</span>, rotation<span class="op">=</span><span class="dv">0</span>, labelpad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="co"># use original scale for xticks</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>locs, _ <span class="op">=</span> plt.xticks() </span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(locs, np.<span class="bu">round</span>(locs <span class="op">+</span> x_0.mean(), <span class="dv">1</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>La figura anterior muestra la longitud del sépalo para las especies (setosa = 0, versicolor = 1). Para mitigar la superposición de los datos, hemos agregado ruido (<em>jitter</em>) a las variable-respuesta que es binaria. Una línea púrpura en forma de <em>S</em> representa el valor medio de <span class="math inline">\(\theta\)</span>. Esta línea se puede interpretar como la probabilidad que una flor sea versicolor dado el valor de la longitud del sépalo. La banda púrpura semitransparente es el intervalo del 94% de HDI. Esta figura nos muestra que podemos interpretar la regresión logística como una forma de combinar variables linealmente a fin de obtener una probabilidad para variables binarias.</p>
<p>Alternativamente podemos usar una regresión logística para clasificar, esto lo podemos hacer discretizando el valor de probabilidad obtenido. El caso más común es asignar la clase 1 si la probabilidad es mayor a 0.5 y asignar la clase 0 en caso contrario. En la figura 4.4 hemos graficado este límite de decisión usando una línea vertical negra junto con su 94% HDI (la banda gris). De acuerdo con el límite de decisión, los valores <span class="math inline">\(x_i\)</span> (longitud del sépalo en este caso) a la izquierda corresponden a la clase 0 (setosa) y los valores a la derecha a la clase 1 (versicolor).</p>
<p>El límite de decisión se define como el valor de <span class="math inline">\(x_i\)</span>, para el cual <span class="math inline">\(y = 0.5\)</span>. Y resulta ser $- $, como podemos comprobar a continuación:</p>
<p>A partir de la definición del modelo tenemos la relación:</p>
<p><span class="math display">\[\theta = logistic(\alpha + x \beta) \tag{4.4}\]</span></p>
<p>Y a partir de la definición de la función logística tenemos que $= 0.5 $, cuando el argumento de la regresión logística es 0, es decir:</p>
<p><span class="math display">\[0.5 = logística(\alpha + x_i \beta) \Leftrightarrow 0 = \alpha + x_i \beta \tag{4.5}\]</span></p>
<p>Reordenando 4.5, encontramos que el valor de <span class="math inline">\(x_i\)</span>, para el cual, <span class="math inline">\(\theta = 0.5\)</span> corresponde a la expresión:</p>
<p><span class="math display">\[x_i = - \frac{\alpha}{\beta} \tag{4.6}\]</span></p>
<p>Resumiendo los puntos más importantes hasta el momento:</p>
<ul>
<li><p>El valor de <span class="math inline">\(\theta\)</span> es, en términos generales, $p(y= 1 x) $. En este sentido, la regresión logística es en realidad una regresión, solo que estamos <em>regresionando</em> la probabilidad de que un punto de datos pertenezca a la clase 1, dada una combinación lineal de características.</p></li>
<li><p>Estamos modelando la media de una variable dicotómica, es decir, un número en el intervalo [0-1]. Luego, introducimos una regla para convertir esta probabilidad en una asignación de dos clases. En este caso, si $p(y = 1) &gt;= 0.5 $ asignamos clase 1, de lo contrario clase 0.</p></li>
<li><p>No hay nada especial en el valor 0.5, aparte de que es el número en el medio entre 0 y 1. Podemos argumentar que este límite solo es razonable si estamos de acuerdo en cometer un error en una u otra dirección. En otras palabras, si es lo mismo para nosotros clasificar erróneamente una setosa como versicolor o una versicolor como setosa. Resulta que este no es siempre el caso, y el costo asociado a la clasificación errónea no tiene por qué ser simétrico, como recordarán del capítulo 2 cuando analizamos las funciones de pérdida.</p></li>
</ul>
</section>
</section>
</section>
<section id="regresión-logística-múltiple" class="level1">
<h1>Regresión logística múltiple</h1>
<p>De manera similar a la regresión lineal múltiple, la regresión logística múltiple consiste en utilizar más de una variable independiente. Intentemos combinar la longitud del sépalo y el ancho del sépalo. Recuerda que necesitamos preprocesar un poco los datos.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> iris.query(<span class="st">"species == ('setosa', 'versicolor')"</span>) </span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>y_1 <span class="op">=</span> pd.Categorical(df[<span class="st">'species'</span>]).codes </span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>x_n <span class="op">=</span> [<span class="st">'sepal_length'</span>, <span class="st">'sepal_width'</span>]</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co">#x_n = ['petal_length', 'petal_width']</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>x_1 <span class="op">=</span> df[x_n].values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="el-límite-de-decisión" class="level2">
<h2 class="anchored" data-anchor-id="el-límite-de-decisión">El límite de decisión</h2>
<p>No dudes en omitir esta sección y pasar directamente a la implementación del modelo si no estás demasiado interesado en cómo podemos obtener el límite de decisión.</p>
<p>Desde el modelo, tenemos:</p>
<p><span class="math display">\[\theta = logística(\alpha + \beta_1 x_1 + \beta_2 x_2) \tag{4.7}\]</span></p>
<p>Y a partir de la definición de la función logística, tenemos que <span class="math inline">\(\theta = 0.5\)</span>, cuando el argumento de la regresión logística es cero, es decir:</p>
<p><span class="math display">\[ 0.5 = logística(\alpha + \beta_1x_1 + \beta_2x_2) \Leftrightarrow 0 = \alpha + \beta_1x_1 + \beta_2x_2 \tag {4.8}\]</span></p>
<p>Reordenando, encontramos el valor de <span class="math inline">\(x_2\)</span> para el cual <span class="math inline">\(\theta = 0.5\)</span> el cual corresponde a la expresión:</p>
<p><span class="math display">\[ x_2 = -\frac{\alpha}{\beta_2} + \left (-\frac{\beta_1}{\beta_2} x_1 \right) \tag {4.9}\]</span></p>
<p>Esta expresión para el límite de decisión tiene la misma forma matemática que la ecuación de una línea, siendo el primer término el intercepto y el segundo la pendiente. Los paréntesis se utilizan para mayor claridad y podemos omitirlos si queremos. Que el límite sea una línea es totalmente razonable, ¿no es así? Si tenemos una sola variable, tenemos datos unidimensionales y podemos dividirla en dos grupos usando un punto; si tenemos dos variables, tenemos un espacio de datos bidimensional y podemos separarlo usando una línea; para las tres dimensiones, el límite será un plano y para dimensiones más altas hablaremos genéricamente acerca de los hiperplanos. Bueno, en realidad siempre podemos hablar de hyperplanos n-dimensionales.</p>
</section>
<section id="implementando-el-modelo" class="level2">
<h2 class="anchored" data-anchor-id="implementando-el-modelo">Implementando el modelo</h2>
<p>Para escribir el modelo de regresión logística múltiple utilizando PyMC, aprovechamos sus capacidades de vectorización, lo que nos permite introducir solo modificaciones menores respecto del modelo logístico simple:</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_1: </span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>) </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">2</span>, shape<span class="op">=</span><span class="bu">len</span>(x_n)) </span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> α <span class="op">+</span> pm.math.dot(x_1, β) </span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    θ <span class="op">=</span> pm.Deterministic(<span class="st">'θ'</span>, pm.math.sigmoid(μ)) </span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    bd <span class="op">=</span> pm.Deterministic(<span class="st">'bd'</span>, <span class="op">-</span>α<span class="op">/</span>β[<span class="dv">1</span>] <span class="op">-</span> β[<span class="dv">0</span>]<span class="op">/</span>β[<span class="dv">1</span>] <span class="op">*</span> x_1[:,<span class="dv">0</span>])</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    yl <span class="op">=</span> pm.Bernoulli(<span class="st">'yl'</span>, p<span class="op">=</span>θ, observed<span class="op">=</span>y_1) </span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    idata_1 <span class="op">=</span> pm.sample(<span class="dv">2000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="12000" class="" max="12000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [12000/12000 00:10&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 10 seconds.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>varnames <span class="op">=</span> [<span class="st">'α'</span>, <span class="st">'β'</span>] </span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>az.plot_forest(idata_1, var_names<span class="op">=</span>varnames, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Como hicimos para una única variable predictiva, vamos a graficar los datos y el límite de decisión.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>_, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.argsort(x_1[:,<span class="dv">0</span>]) </span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>bd <span class="op">=</span> idata_1.posterior[<span class="st">'bd'</span>].mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>))[idx] </span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_1[:,<span class="dv">0</span>], x_1[:,<span class="dv">1</span>], c<span class="op">=</span>[<span class="ss">f'C</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> x <span class="kw">in</span> y_0]) </span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>plt.plot(x_1[:,<span class="dv">0</span>][idx], bd, color<span class="op">=</span><span class="st">'k'</span>)<span class="op">;</span> </span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>az.plot_hdi(x_1[:,<span class="dv">0</span>], idata_1.posterior[<span class="st">'bd'</span>], color<span class="op">=</span><span class="st">"C8"</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(x_n[<span class="dv">0</span>]) </span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(x_n[<span class="dv">1</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-26-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>El límite de decisión es una línea recta, como ya hemos visto. No se confunda con el aspecto curvo de la banda del 94% de HDI. La curvatura aparente es el resultado de tener múltiples líneas que giran alrededor de una región central (aproximadamente alrededor de la media de <code>x</code> y la media de <code>y</code>).</p>
</section>
<section id="interpretación-de-los-coeficientes-de-una-regresión-logística" class="level2">
<h2 class="anchored" data-anchor-id="interpretación-de-los-coeficientes-de-una-regresión-logística">Interpretación de los coeficientes de una regresión logística</h2>
<p>Debemos tener cuidado al interpretar los coeficientes <span class="math inline">\(\beta\)</span> de una regresión logística. La interpretación no es tan sencilla como con los modelos lineales en el capítulo anterior. La función logística introduce una no linearidad, que debemos tener en cuenta. Si <span class="math inline">\(\beta\)</span> es positivo, aumentar <span class="math inline">\(x\)</span> aumentará <span class="math inline">\(p(y = 1)\)</span> en cierta cantidad, pero la cantidad no es una función lineal de <span class="math inline">\(x\)</span>, es en cambio una función no-lineal de <span class="math inline">\(x\)</span>. Podemos visualizar este hecho en la figura 4.4, en lugar de una línea con una pendiente constante, tenemos una línea en forma de S con una pendiente que cambia en función de <span class="math inline">\(x\)</span>. Un poco de álgebra nos puede dar una idea de cuánto cambia <span class="math inline">\(p(y=1)\)</span> con <span class="math inline">\(\beta\)</span>:</p>
<p>El modelo logístico básico es:</p>
<p><span class="math display">\[\theta = logistic (\alpha + X \beta) \tag{4.11} \]</span></p>
<p>El inverso de la logística es la función logit, que es:</p>
<p><span class="math display">\[ logit(z) = log \left (\frac{z}{1-z} \right) \tag{4.12}\]</span></p>
<p>Por lo tanto, si tomamos la primera ecuación en esta sección y aplicamos la función logit a ambos términos, obtenemos:</p>
<p><span class="math display">\[ logit(\theta) = \alpha + X \beta \tag{4.13}\]</span></p>
<p>O equivalente:</p>
<p><span class="math display">\[ log \left (\frac{\theta} {1-\theta} \right) = \alpha + X \beta \tag {4.14}\]</span></p>
<p>Recuerden que <span class="math inline">\(\theta\)</span> en nuestro modelo era la probabilidad de $y = 1 $, por lo tanto:</p>
<p><span class="math display">\[ log \left(\frac {p(y = 1)} {1-p (y = 1)} \right) = \alpha + X \beta \tag {4.15} \]</span></p>
<p>La cantidad <span class="math display">\[\frac{p (y = 1)} {1-p (y = 1)}\]</span> se conoce como <strong>odds</strong>. Los odds a favor se definen como la relación entre la probabilidad de éxito y la probabilidad de no éxito. Mientras que la probabilidad de obtener 2 tirando un dado es 1/6, los odds para el mismo evento son <span class="math inline">\(\frac{1/6}{5/6} \simeq 0.2\)</span> o dicho de otra forma 1 evento favorable frente a 5 eventos desfavorables. Los odds suelen ser utilizadas por los apostadores ya que proporcionan una herramienta más intuitiva que las probabilidades <em>en bruto</em> cuando se piensa en la forma correcta de apostar.</p>
<blockquote class="blockquote">
<p>En una regresión logística, el coeficiente <span class="math inline">\(\beta\)</span> codifica el aumento en unidades de log-odds por unidad de aumento de la variable <span class="math inline">\(x\)</span>.</p>
</blockquote>
<p>La transformación de probabilidad a odds es una transformación monotónica, lo que significa que las probabilidades aumentan a medida que aumenta la probabilidad. Mientras que las probabilidades están restringidas al intervalo <span class="math inline">\([0, 1]\)</span>, los odds viven en el intervalo <span class="math inline">\([0, \infty]\)</span>. El logaritmo es otra transformación monótonica y los log-odds están en el intervalo <span class="math inline">\([-\infty, \infty]\)</span>. La figura 4.6 muestra cómo la probabilidad está relacionada con los odds y los log-odds.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>probability <span class="op">=</span> np.linspace(<span class="fl">0.01</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>odds <span class="op">=</span> probability <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> probability)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>_, ax1 <span class="op">=</span> plt.subplots()</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> ax1.twinx()</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>ax1.plot(probability, odds, <span class="st">'C0'</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>ax2.plot(probability, np.log(odds), <span class="st">'C2'</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'probabilidad'</span>)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'odds'</span>, color<span class="op">=</span><span class="st">'C0'</span>)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'log-odds'</span>, color<span class="op">=</span><span class="st">'C2'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_16695/2677285095.py:2: RuntimeWarning: divide by zero encountered in divide
  odds = probability / (1 - probability)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-27-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Por lo tanto, los valores de los coeficientes proporcionados por <code>summary</code> están en la escala log-odds.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> az.summary(idata_1, var_names<span class="op">=</span>[<span class="st">'α'</span>, <span class="st">'β'</span>])</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>α</th>
      <td>-9.019</td>
      <td>4.745</td>
      <td>-18.156</td>
      <td>-0.685</td>
      <td>0.089</td>
      <td>0.066</td>
      <td>2918.0</td>
      <td>3083.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>β[0]</th>
      <td>4.642</td>
      <td>0.909</td>
      <td>3.036</td>
      <td>6.413</td>
      <td>0.018</td>
      <td>0.013</td>
      <td>2672.0</td>
      <td>2638.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>β[1]</th>
      <td>-5.179</td>
      <td>0.980</td>
      <td>-6.955</td>
      <td>-3.279</td>
      <td>0.018</td>
      <td>0.013</td>
      <td>2907.0</td>
      <td>2779.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Una forma muy empírica de entender los modelos es cambiar los parámetros y ver qué sucede. En el siguiente bloque de código, calculamos las log-odds en favor de versicolor como <span class="math inline">\(\text {log_odds_versicolor_i} = \alpha + beta_1 x1 + \beta_2 x2\)</span>, y luego la probabilidad de versicolor con la función logística. Luego repetimos el cálculo arreglando <span class="math inline">\(x_2\)</span> y aumentando <span class="math inline">\(x_1\)</span> en 1.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>x_1 <span class="op">=</span> <span class="fl">4.5</span>  <span class="co"># sepal_length</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>x_2 <span class="op">=</span> <span class="dv">3</span>   <span class="co"># sepal_width</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>log_odds_versicolor_i <span class="op">=</span> (df[<span class="st">'mean'</span>] <span class="op">*</span> [<span class="dv">1</span>, x_1, x_2]).<span class="bu">sum</span>()</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>probability_versicolor_i <span class="op">=</span> logistic(log_odds_versicolor_i)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>log_odds_versicolor_f <span class="op">=</span> (df[<span class="st">'mean'</span>] <span class="op">*</span> [<span class="dv">1</span>, x_1 <span class="op">+</span> <span class="dv">1</span>, x_2]).<span class="bu">sum</span>()</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>probability_versicolor_f <span class="op">=</span> logistic(log_odds_versicolor_f)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>(<span class="ss">f'</span><span class="sc">{</span>log_odds_versicolor_f <span class="op">-</span> log_odds_versicolor_i<span class="sc">:.2f}</span><span class="ss">'</span>, </span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a> <span class="ss">f'</span><span class="sc">{</span>probability_versicolor_f <span class="op">-</span> probability_versicolor_i<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>('4.64', '0.70')</code></pre>
</div>
</div>
<p>Si ejecutas el código, encontrarás que el aumento en las log-odds es de <span class="math inline">\(\approx 4.7\)</span>, que es exactamente el valor de <span class="math inline">\(\beta_0\)</span> (verifique el <code>summary</code> para <code>trace_1</code>). Esto está en línea con nuestro hallazgo anterior que muestra que los coeficientes <span class="math inline">\(\beta\)</span> indican el aumento en unidades log-odds por incremento unitario de la variable <span class="math inline">\(x\)</span>. El aumento en la probabilidad es <span class="math inline">\(\approx 0.70\)</span>.</p>
</section>
<section id="trabajando-con-variables-correlacionadas" class="level2">
<h2 class="anchored" data-anchor-id="trabajando-con-variables-correlacionadas">Trabajando con variables correlacionadas</h2>
<p>Sabemos por el capítulo anterior que trabajar con variables <em>muy</em> correlacionadas puede traernos problemas. Las variables correlacionadas se traducen en combinaciones más amplias de coeficientes que explican los datos o, desde el punto de vista complementario, variables correlacioadas tienen menos poder para restringir los modelos. Un problema similar ocurre cuando las clases se vuelven perfectamente separables, es decir, no hay superposición entre clases dada la combinación lineal de variables en nuestro modelo. Podemos visualizar un ejemplo de esto al usar el conjunto de datos iris con el <code>modelo_1</code>, pero esta vez utilizando las variables ancho de pétalo y largo de pétalo. Encontraras que los coeficientes <span class="math inline">\(\beta\)</span> son más amplios que antes y también el 94% HDI (banda gris en la figura 4.5) es mucho más amplia. La figura 4.7 muestra un <em>heatmap</em> para las variables sepal_length y sepal_width (usadas en el primer ejemplo) la correlación no es tan alta como la correlación entre las variables petal_length y petal_width (usada en el segundo ejemplo).</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> iris[iris[<span class="st">'species'</span>] <span class="op">!=</span> <span class="st">'virginica'</span>].corr() </span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.tri(<span class="op">*</span>corr.shape).T </span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr.<span class="bu">abs</span>(), mask<span class="op">=</span>mask, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-30-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Para generar la figura 4.7, hemos utilizado una máscara que elimina el triángulo superior y los elementos diagonales del <em>heatmap</em>, ya que estos son poco informativos o redundantes. Observe también que hemos graficado el valor absoluto de la correlación, ya que en este momento no nos importa el signo de la correlación entre las variables, solo su <em>fuerza</em>.</p>
<p>Una solución cuando se trabaja con variables (altamente) correlacionadas, es simplemente eliminar una (o más de una) de las variables correlacionadas. Otra opción es poner más información en el <em>a priori</em>, esto se puede lograr con <em>a prioris</em> informativos si es que contamos con información previa útil, o más general utilizando <em>a prioris</em> ligeramente informativos. Andrew Gelman y el equipo de Stan recomiendan usar el siguiente <em>a priori</em> al realizar una regresión logística:</p>
<p><span class="math display">\[ \beta \sim Student t (0, \nu, sd) \tag {4.10}\]</span></p>
<p>donde <code>sd</code> se elije de forma que informe débilmente sobre los valores esperados para la escala. Se sugiere que el parámetro de normalidad <span class="math inline">\(\nu\)</span> sea alrededor de 3-7. Lo que dice este <em>a priori</em> es que esperamos que el coeficiente sea pequeño, pero ponemos colas pesadas porque esto nos lleva a un modelo más robusto que el uso de una distribución gaussiana.</p>
</section>
<section id="tratando-con-clases-desequilibradas" class="level2">
<h2 class="anchored" data-anchor-id="tratando-con-clases-desequilibradas">Tratando con clases desequilibradas</h2>
<p>El conjunto de datos del iris está completamente equilibrado; en el sentido de que cada categoría tiene exactamente el mismo número de observaciones. Tenemos 50 setosas, 50 versicolores, y 50 virgininas. Por el contrario, muchos conjuntos de datos constan de datos no balanceados, es decir, hay muchos más datos de una clase que de la otra. Cuando esto sucede, la regresión logística puede generar problemas, es decir, el límite no se puede determinar con la misma precisión que cuando el conjunto de datos está más equilibrado.</p>
<p>Para ver un ejemplo de este comportamiento, vamos a usar el conjunto de datos del iris y vamos a eliminar arbitrariamente algunos puntos de datos de la clase setosa:</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> iris.query(<span class="st">"species == ('setosa', 'versicolor')"</span>) </span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[<span class="dv">45</span>:]  </span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>y_3 <span class="op">=</span> pd.Categorical(df[<span class="st">'species'</span>]).codes </span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>x_n <span class="op">=</span> [<span class="st">'sepal_length'</span>, <span class="st">'sepal_width'</span>] </span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>x_3 <span class="op">=</span> df[x_n].values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Y ahora ejecutamos una regresión logística múltiple, tal cual hicimos antes.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_3: </span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>) </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">2</span>, shape<span class="op">=</span><span class="bu">len</span>(x_n)) </span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> α <span class="op">+</span> pm.math.dot(x_3, β) </span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    θ <span class="op">=</span> pm.math.sigmoid(μ)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    bd <span class="op">=</span> pm.Deterministic(<span class="st">'bd'</span>, <span class="op">-</span>α<span class="op">/</span>β[<span class="dv">1</span>] <span class="op">-</span> β[<span class="dv">0</span>]<span class="op">/</span>β[<span class="dv">1</span>] <span class="op">*</span> x_3[:,<span class="dv">0</span>]) </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    yl <span class="op">=</span> pm.Bernoulli(<span class="st">'yl'</span>, p<span class="op">=</span>θ, observed<span class="op">=</span>y_3) </span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>    idata_3 <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:05&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 6 seconds.</code></pre>
</div>
</div>
<p>El límite de decisión se desplaza hacia la clase menos abundante y la incertidumbre es más grande que antes. Este es el comportamiento típico de un modelo logístico para datos no balanceados. ¡Pero espera un minuto! Bien podrías argumentar que te estoy engañando ya que la mayor incertidumbre es en realidad el producto de tener menos datos y no solo menos setosas que versicolores. Este es un punto totalmente válido, pero si realizas el ejercicio 2 podrás verificar que lo que explica esta gráfica son los datos desequilibrados.</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.argsort(x_3[:,<span class="dv">0</span>]) </span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>bd <span class="op">=</span> idata_3.posterior[<span class="st">'bd'</span>].mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>))[idx] </span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_3[:,<span class="dv">0</span>], x_3[:,<span class="dv">1</span>], c<span class="op">=</span> [<span class="ss">f'C</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> x <span class="kw">in</span> y_3]) </span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>plt.plot(x_3[:,<span class="dv">0</span>][idx], bd, color<span class="op">=</span><span class="st">'C8'</span>)<span class="op">;</span> </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>bd_hdi <span class="op">=</span> az.hdi(idata_3.posterior)[<span class="st">'bd'</span>][idx] </span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x_3[:,<span class="dv">0</span>][idx], bd_hdi[:,<span class="dv">0</span>], bd_hdi[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'C8'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span> </span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(x_n[<span class="dv">0</span>]) </span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(x_n[<span class="dv">1</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>¿Qué hacer si encontramos datos desequilibrados? Bueno, la solución obvia es obtener un conjunto de datos con aproximadamente la misma cantidad por clase. Este es un punto a tener en cuenta al recopilar o generar los datos. Si no tenés control sobre el conjunto de datos, debes tener cuidado al interpretar los resultados para datos no balanceados. Verifique la incertidumbre del modelo y ejecute algunas verificaciones predictivas posteriores para ver si los resultados son útiles para usted. Otra opción sería utilizar <em>priors</em> más informativos y/o ejecutar un modelo alternativo como se explica más adelante en este capítulo.</p>
</section>
<section id="regresión-softmax-o-multinomial" class="level2">
<h2 class="anchored" data-anchor-id="regresión-softmax-o-multinomial">Regresión softmax (o multinomial)</h2>
<p>Una forma de generalizar la regresión logística a más de dos clases es con la <strong>regresión softmax</strong>. Necesitamos introducir 2 cambios con respecto a la regresión logística, primero reemplazamos la función logística con la función softmax:</p>
<p><span class="math display">\[softmax (\mu_i) = \frac {exp (\mu_i)} {\sum exp (\mu_k)} \tag{4.16}\]</span></p>
<p>En palabras, para obtener la salida de la función softmax para el i-esimo elemento de un vector <span class="math inline">\(\mu\)</span>, tomamos la exponencial del valor i-esimo dividido por la suma de todos los valores del vector <span class="math inline">\(\mu\)</span> exponenciados.</p>
<p>La función softmax garantiza que obtendremos valores positivos que suman 1. La función softmax se reduce a la función logística cuando <span class="math inline">\(k=2\)</span>. Como nota al margen, la función softmax tiene la misma forma que la <strong>distribución de Boltzmann</strong>, distribución central en la mecánica estadística, una rama muy poderosa de la física que se ocupa de la descripción probabilística de los sistemas atómicos y moleculares. La distribución de Boltzmann (y a veces la función softmax) incluye un parámetro llamado temperatura (T) que divide <span class="math inline">\(\mu\)</span>; cuando $ T $ la distribución de probabilidad se vuelve plana y todos los estados son igualmente probables, y cuando <span class="math inline">\(T \rightarrow 0\)</span> solo se llena el estado más probable y, por lo tanto, el softmax se comporta como la función máximo.</p>
<p>El segundo cambio en la regresión softmax es que reemplazamos la distribución de Bernoulli por la distribución categórica. La distribución categórica es la generalización de Bernoulli a más de dos resultados. Además, como la distribución de Bernoulli (tirada de una sola moneda) es un caso especial de la Binomial (tiradas de <span class="math inline">\(n\)</span> monedas), la categórica (tirada de un dado de <span class="math inline">\(k\)</span> caras) es un caso especial de la distribución multinomial (<span class="math inline">\(n\)</span> tiradas de un dado de <span class="math inline">\(k\)</span> caras).</p>
<p>k-diagram</p>
<p>Para ejemplificar la regresión de softmax, continuaremos trabajando con el conjunto de datos iris, solo que esta vez usaremos sus 3 clases (setosa, versicolor y virginica) y sus cuatro características (largo sépalo, ancho sépalo, longitud del pétalo y ancho del pétalo). También vamos a estandarizar los datos, ya que esto ayudará a que el sampler se ejecute de manera más eficiente (también podríamos centrar los datos):</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>y_s <span class="op">=</span> pd.Categorical(iris[<span class="st">'species'</span>]).codes</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>x_n <span class="op">=</span> iris.columns[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>x_s <span class="op">=</span> iris[x_n].values</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>x_s <span class="op">=</span> (x_s <span class="op">-</span> x_s.mean(axis<span class="op">=</span><span class="dv">0</span>)) <span class="op">/</span> x_s.std(axis<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>El código de PyMC refleja los pocos cambios entre el modelo logístico y el modelo softmax. Presta atención a los valores de <code>shape</code> para los coeficientes $$ y <span class="math inline">\(\beta\)</span>. En el siguiente código usamos la función softmax de Theano. Hemos utilizado la expresión <code>import theano.tensor as tt</code>, que es la convención utilizada por los desarrolladores de PyMC:</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_s:</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">5</span>, shape<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">5</span>, shape<span class="op">=</span>(<span class="dv">4</span>,<span class="dv">3</span>))</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> pm.Deterministic(<span class="st">'μ'</span>, α <span class="op">+</span> pm.math.dot(x_s, β))</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    θ <span class="op">=</span> pm.math.softmax(μ)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    yl <span class="op">=</span> pm.Categorical(<span class="st">'yl'</span>, p<span class="op">=</span>θ, observed<span class="op">=</span>y_s)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    idata_s <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:27&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 28 seconds.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>az.plot_forest(idata_s, var_names<span class="op">=</span>[<span class="st">'α'</span>, <span class="st">'β'</span>], figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>), combined<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-36-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>¿Qué tan bien funciona nuestro modelo? Averigüemos cuántos casos podemos predecir correctamente. En el siguiente código, solo usamos la media de los parámetros para calcular la probabilidad de que cada punto de datos pertenezca a cada una de las tres clases, luego asignamos la clase usando la función <code>argmax</code>. Y comparamos el resultado con los valores observados:</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>data_pred <span class="op">=</span> idata_s.posterior[<span class="st">'μ'</span>].mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>))</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> [np.exp(point)<span class="op">/</span>np.<span class="bu">sum</span>(np.exp(point), axis<span class="op">=</span><span class="dv">0</span>) <span class="cf">for</span> point <span class="kw">in</span> data_pred]</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="ss">f'</span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(y_s <span class="op">==</span> np.argmax(y_pred, axis<span class="op">=</span><span class="dv">1</span>)) <span class="op">/</span> <span class="bu">len</span>(y_s)<span class="sc">:.2f}</span><span class="ss">'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>'0.95'</code></pre>
</div>
</div>
<p>El resultado es que clasificamos correctamente <span class="math inline">\(\approx 95 \%\)</span> de los datos. Ese es realmente un muy buen trabajo. Sin embargo, una verdadera prueba para evaluar el rendimiento de nuestro modelo sería verificarlo con un conjunto de datos no usado para ajustar al modelo. De lo contrario, es posible que estemos sobreestimando la capacidad <em>real</em> del modelo para generalizar a otros datos.</p>
<p>Es posible que hayas notado que las distribuciones marginales de cada parámetro son muy amplias. Este es el mismo problema de no identificabilidad que ya hemos encontrado para los datos correlacionados en otros modelos de regresión o con clases perfectamente separables. En este caso, el ancho posterior se debe a la condición de que todas las probabilidades deben sumar 1. Dada esta condición, estamos usando más parámetros de los que necesitamos para especificar completamente el modelo. En términos simples, si tenés 10 números que suman 1, solo necesitás darme 9 de ellos; el otro puedo calcularlo. Esto es precisamente lo que está pasando con este problema. Una solución es fijar los parámetros <em>extra</em> a algún valor, por ejemplo, cero. El siguiente código muestra cómo lograr esto usando PyMC:</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_sf:</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">2</span>, shape<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">2</span>, shape<span class="op">=</span>(<span class="dv">4</span>,<span class="dv">2</span>))</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    α_f <span class="op">=</span> pm.math.concatenate([[<span class="dv">0</span>] ,α])</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>    β_f <span class="op">=</span> pm.math.concatenate([np.zeros((<span class="dv">4</span>,<span class="dv">1</span>)) , β], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> α_f <span class="op">+</span> pm.math.dot(x_s, β_f)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>    θ <span class="op">=</span> pm.math.softmax(μ)</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>    yl <span class="op">=</span> pm.Categorical(<span class="st">'yl'</span>, p<span class="op">=</span>θ, observed<span class="op">=</span>y_s)</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>    idata_sf <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:08&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 8 seconds.</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="38">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>az.plot_forest(idata_sf, var_names<span class="op">=</span>[<span class="st">'α'</span>, <span class="st">'β'</span>], figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>), combined<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-39-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="linear-discriminant-analysis-lda" class="level2">
<h2 class="anchored" data-anchor-id="linear-discriminant-analysis-lda">Linear discriminant analysis (LDA)</h2>
<p>Hasta ahora hemos discutido la regresión logística y algunas extensiones de la misma. En todos estos casos, calculamos $p(y x) $, es decir, la probabilidad que una clase <span class="math inline">\(y\)</span> teniendo como dato una o más variables <span class="math inline">\(x\)</span>, luego usamos un umbral o límite para convertir la probabilidad computada en un límite discreto lo que nos permite asignar clases.</p>
<p>Este enfoque no es único. Una alternativa es modelar primero <span class="math inline">\(p(x \mid y)\)</span>. No vamos a entrar en mucho detalle aquí sobre este tipo de modelos para clasificación, pero vamos a ver un ejemplo que ilustra la idea central de este tipo de modelo. Lo haremos para dos clases y una sola variable, exactamente como el primer modelo que construimos en este capítulo, es más usaremos los mismos datos.</p>
<p>En el siguiente código se puede ver que ahora el límite de decisión se define como el promedio entre las medias de las Gaussianas. Este modelo es equivalente a lo que se conoce como análisis discriminante lineal (Linear Discriminar Analysis).</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_lda:</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> pm.Normal(<span class="st">'μ'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>, shape<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">'σ'</span>, <span class="dv">10</span>)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>    setosa <span class="op">=</span> pm.Normal(<span class="st">'setosa'</span>, mu<span class="op">=</span>μ[<span class="dv">0</span>], sigma<span class="op">=</span>σ, observed<span class="op">=</span>x_0[:<span class="dv">50</span>])</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    versicolor <span class="op">=</span> pm.Normal(<span class="st">'versicolor'</span>, mu<span class="op">=</span>μ[<span class="dv">1</span>], sigma<span class="op">=</span>σ, observed<span class="op">=</span>x_0[<span class="dv">50</span>:])</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    bd <span class="op">=</span> pm.Deterministic(<span class="st">'bd'</span>, (μ[<span class="dv">0</span>] <span class="op">+</span> μ[<span class="dv">1</span>]) <span class="op">/</span> <span class="dv">2</span>)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    idata_lda <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [μ, σ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.</code></pre>
</div>
</div>
<p>Ahora vamos a generar una figura que muestra las dos clases (<code>setosa = 0</code> y<code>versicolor = 1</code>) contra los valores de la longitud del sépalo, y también el límite de decisión como una línea turquesa y el intervalo del 94% de HDI como una banda turquesa semitransparente.</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>plt.axvline(idata_lda.posterior[<span class="st">'bd'</span>].mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>)), ymax<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'C1'</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>bd_hdi <span class="op">=</span> az.hdi(idata_lda.posterior)[<span class="st">'bd'</span>].values</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>plt.fill_betweenx([<span class="dv">0</span>, <span class="dv">1</span>], bd_hdi[<span class="dv">0</span>], bd_hdi[<span class="dv">1</span>], color<span class="op">=</span><span class="st">'C1'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>plt.plot(x_0, np.random.normal(y_0, <span class="fl">0.02</span>), <span class="st">'.'</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'θ'</span>, rotation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'sepal_length'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-41-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Como habrá notado, la figura 4.9 es bastante similar a la figura 4.4. Verifique también los valores de la decisión de límite en el siguiente <code>summary</code>:</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>az.summary(idata_lda)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>μ[0]</th>
      <td>5.005</td>
      <td>0.064</td>
      <td>4.889</td>
      <td>5.133</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>6084.0</td>
      <td>3292.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>μ[1]</th>
      <td>5.936</td>
      <td>0.064</td>
      <td>5.821</td>
      <td>6.059</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>5652.0</td>
      <td>3249.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>σ</th>
      <td>0.447</td>
      <td>0.032</td>
      <td>0.392</td>
      <td>0.510</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>5429.0</td>
      <td>3241.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>bd</th>
      <td>5.471</td>
      <td>0.046</td>
      <td>5.384</td>
      <td>5.554</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>5770.0</td>
      <td>2905.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Tanto el modelo LDA como la regresión logística proporcionan resultados similares. El modelo discriminante lineal puede extenderse a más de una característica al modelar las clases como Gaussianas multivariadas. Además, es posible relajar el supuesto de que las clases comparten una varianza común (o covarianza). Esto conduce a un modelo conocido como análisis discriminante cuadrático (QDA).</p>
<p>En general, los modelos LDA o QDA funcionarán mejor que una regresión logística cuando las características que estamos usando estén más o menos distribuidas como Gaussianas y la regresión logística funcionará mejor en el caso contrario. Una ventaja de modelos como LDA y QDA (o generalizaciones de esta idea) es que puede ser más fácil o más natural incorporar información previa.</p>
<p>Es importante tener en cuenta que los límites de decisión de LDA y QDA pueden ser calculados analíticamente y, por lo tanto, por lo general se calculan de esa manera. Para usar un LDA para dos clases y una característica, solo necesitamos calcular la media de cada distribución y promediar esos dos valores, y obtenemos la decisión de los límites. En el modelo anterior, lo hicimos, pero con un giro Bayesiano. Estimamos los parámetros de las dos Gaussianas y luego insertamos esas estimaciones en una fórmula predefinida.</p>
</section>
<section id="regresión-de-poisson" class="level2">
<h2 class="anchored" data-anchor-id="regresión-de-poisson">Regresión de Poisson</h2>
<p>Otro modelo lineal generalizado muy popular es la regresión de Poisson. Este modelo asume que los datos se distribuyen de acuerdo con la distribución de Poisson.</p>
<p>Un escenario en el que la distribución de Poisson es útil es cuando se analizan cosas, como la descomposición de un núcleo radioactivo, el número de hijos por pareja o el número de seguidores de Twitter. Lo que todos estos ejemplos tienen en común es que usualmente los modelamos usando números discretos no negativos {0, 1, 2, 3 …}. Este tipo de variable recibe el nombre de datos de conteo (count data).</p>
<section id="la-distribución-de-poisson" class="level3">
<h3 class="anchored" data-anchor-id="la-distribución-de-poisson">La distribución de Poisson</h3>
<p>Imagina que estamos contando la cantidad de autos rojos que pasan por una avenida por hora. Podríamos usar la distribución de Poisson para describir estos datos. La distribución de Poisson se utiliza generalmente para describir la probabilidad que ocurra un número determinado de eventos independientes entre si en un intervalo de tiempo o espacio fijo. Esta distribución discreta se parametriza utilizando solo un valor, <span class="math inline">\(\mu\)</span> (la tasa, también comúnmente representada con la letra griega <span class="math inline">\(\lambda\)</span>). <span class="math inline">\(\mu\)</span> corresponde a la media y también a la varianza de la distribución. La función de probabilidad de masa de la distribución de Poisson es:</p>
<p><span class="math display">\[ f(x \mid \mu) = \frac {e^{-\mu}\mu^x} {x!} \tag{4.17}\]</span></p>
<p>dónde: * <span class="math inline">\(\mu\)</span> es el número promedio de eventos por unidad de tiempo / espacio * <span class="math inline">\(x\)</span> es un valor entero positivo 0, 1, 2, … * <span class="math inline">\(x!\)</span> es el factorial de x, k! = k × (k - 1) × (k - 2) × … × 2 × 1</p>
<p>En la siguiente gráfica, podemos ver algunos ejemplos de la familia de distribución de Poisson, para diferentes valores de <span class="math inline">\(\mu\)</span>.</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>mu_params <span class="op">=</span> [<span class="fl">0.5</span>, <span class="fl">1.5</span>, <span class="dv">3</span>, <span class="dv">8</span>]</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="dv">0</span>, <span class="bu">max</span>(mu_params) <span class="op">*</span> <span class="dv">3</span>)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> mu <span class="kw">in</span> mu_params:</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> pz.Poisson(mu).rv_frozen.pmf(x)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>    plt.plot(x, y, <span class="st">'o-'</span>, label<span class="op">=</span><span class="ss">f'μ = </span><span class="sc">{</span>mu<span class="sc">:3.1f}</span><span class="ss">'</span>)</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'f(x)'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-43-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Es importante notar que <span class="math inline">\(\mu\)</span> puede ser un flotante, pero la distribución modela probabilidad de un número discreto de eventos. En la figura 4.10, los puntos representan los valores de la distribución, mientras que las líneas continuas son una ayuda visual que nos ayuda a comprender fácilmente la <em>forma</em> de la distribución. Recuerde, la distribución de Poisson es una distribución discreta.</p>
<p>La distribución de Poisson puede verse como un caso especial de la distribución binomial cuando la cantidad de intentos <span class="math inline">\(n\)</span> es muy grande pero la probabilidad de éxito <span class="math inline">\(p\)</span> es muy baja. Sin entrar en detalles matemáticos, tratemos de aclarar la afirmación anterior. Siguiendo el ejemplo del auto, podemos afirmar que o vemos el auto rojo o no, por lo que podemos usar una distribución binomial. En ese caso tenemos:</p>
<p><span class="math display">\[ x \sim Bin(n, p) \tag{4.18}\]</span></p>
<p>Entonces, la media de la distribución binomial es:</p>
<p><span class="math display">\[\mathbf{E}[x] = np \tag{4.19} \]</span></p>
<p>Y la varianza viene dada por:</p>
<p><span class="math display">\[ \mathbf {V}[x] = np (1 - p) \tag{4.20}\]</span></p>
<p>Pero tenga en cuenta que incluso si se encuentra en una avenida muy transitada, la posibilidad de ver un auto rojo en comparación con el número total de automóviles en una ciudad es muy pequeño y, por lo tanto, tenemos:</p>
<p><span class="math display">\[n &gt;&gt; p \Rightarrow np \simeq np (1-p) \tag{4.21}\]</span></p>
<p>Entonces, podemos hacer la siguiente aproximación:</p>
<p><span class="math display">\[\mathbf {V}[x] = np \tag{4.22}\]</span></p>
<p>Ahora la media y la varianza están representadas por el mismo número y podemos declarar con confianza que nuestra variable se distribuye como una distribución de Poisson:</p>
<p><span class="math display">\[x \sim Poisson(\mu = np) \tag{4.23}\]</span></p>
</section>
</section>
<section id="el-modelo-de-poisson-inflado-de-ceros" class="level2">
<h2 class="anchored" data-anchor-id="el-modelo-de-poisson-inflado-de-ceros">El modelo de Poisson inflado de ceros</h2>
<p>Al contar cosas, una posibilidad es no contar esas cosas, es decir obtener cero. El número cero puede ocurrir generalmente por muchas razones; obtuvimos un cero porque estábamos contando autos rojos y un auto rojo no pasó por la avenida o porque no logramos verlo (tal vez no vimos pasar un diminuto auto rojo detrás de un gran camión). Entonces, si usamos una distribución de Poisson, notaremos, por ejemplo, cuando realizamos una verificación predictiva posterior, que el modelo generó menos ceros en comparación con los datos.</p>
<p>¿Cómo arreglamos eso? Podemos tratar de abordar la causa exacta por la cual nuestro modelo predice menos ceros de los observados e incluir ese factor en el modelo. Sin embargo, suele ser el caso, que es suficiente y más fácil para nuestro propósito, asumir que simplemente tenemos una mezcla de dos procesos:</p>
<ul>
<li>Uno modelado por una distribución de Poisson con probabilidad <span class="math inline">\(\psi\)</span></li>
<li>Otra persona que da ceros adicionales con probabilidad <span class="math inline">\(1 - \psi\)</span>.</li>
</ul>
<p>Esto se conoce como modelo Poisson inflado de ceros (ZeroInflatedPoisson). En algunos textos, encontrarás que <span class="math inline">\(\psi\)</span> se usa para representar los ceros extra y <span class="math inline">\(1-\psi\)</span> la probabilidad de Poisson.</p>
<p>Básicamente una distribución ZIP nos dice que:</p>
<p><span class="math display">\[p(y_j = 0) = 1 - \psi + (\psi) e^{-\mu} \tag{4.24}\]</span></p>
<p><span class="math display">\[p(y_j = k_i ) = \psi \frac{\mu^x_i e^{-\mu}}{x_i!} \tag{4.25}\]</span></p>
<p>Donde <span class="math inline">\(1-\psi\)</span> es la probabilidad de ceros adicionales. Podríamos implementar fácilmente estas ecuaciones en un modelo PyMC. Sin embargo, podemos hacer algo aún más fácil y usar la distribución ZIP de PyMC.</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co">#np.random.seed(42)</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>θ_real <span class="op">=</span> <span class="fl">2.5</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>ψ <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate some data</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> np.array([(np.random.random() <span class="op">&gt;</span> (<span class="dv">1</span><span class="op">-</span>ψ)) <span class="op">*</span> np.random.poisson(θ_real)</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>                   <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> ZIP:</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    ψ <span class="op">=</span> pm.Beta(<span class="st">'ψ'</span>, <span class="fl">1.</span>, <span class="fl">1.</span>)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    θ <span class="op">=</span> pm.Gamma(<span class="st">'θ'</span>, <span class="fl">2.</span>, <span class="fl">0.1</span>)</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> pm.ZeroInflatedPoisson(<span class="st">'y'</span>, ψ, θ, observed<span class="op">=</span>counts)</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    idata <span class="op">=</span> pm.sample(<span class="dv">1000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [ψ, θ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>az.plot_trace(idata)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-46-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>az.summary(idata)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ψ</th>
      <td>0.131</td>
      <td>0.037</td>
      <td>0.069</td>
      <td>0.202</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>3599.0</td>
      <td>2480.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>θ</th>
      <td>2.445</td>
      <td>0.506</td>
      <td>1.473</td>
      <td>3.369</td>
      <td>0.008</td>
      <td>0.006</td>
      <td>3714.0</td>
      <td>2602.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="regresión-de-poisson-y-regresión-zip" class="level2">
<h2 class="anchored" data-anchor-id="regresión-de-poisson-y-regresión-zip">Regresión de Poisson y regresión ZIP</h2>
<p>El modelo ZIP puede parecer un poco aburrido, pero a veces necesitamos estimar distribuciones simples como esta u otra como las distribuciones de Poisson o Gaussianas. Además, podemos usar las distribuciones Poisson o ZIP como parte de un modelo lineal. Como vimos con la regresión logística (y softmax) podemos usar una función de enlace inverso para transformar el resultado de un modelo lineal en una variable adecuada para ser utilizada con otra distribución que no sea la normal. En la siguiente figura, vemos una posible implementación de una regresión ZIP. La regresión de Poisson será similar, pero sin la necesidad de incluir <span class="math inline">\(\phi\)</span> ya que no modelaremos un exceso de ceros. Observe que ahora usamos la función exponencial como la función de enlace inverso. Esta elección garantiza que los valores devueltos por el modelo lineal sean positivos.</p>
<p>Para ejemplificar la implementación de un modelo de regresión ZIP, vamos a trabajar con un conjunto de datos tomado del <a href="http://www.ats.ucla.edu/stat/data">Instituto de Investigación y Educación Digital</a>.</p>
<p>El problema es el siguiente: trabajamos en la administración de un parque y queremos mejorar la experiencia de los visitantes. Por lo tanto, decidimos realizar una breve encuesta a 250 grupos que visitan el parque. Parte de los datos que recopilamos (a nivel de grupo) consiste en:</p>
<ul>
<li>La cantidad de peces que capturaron (contar)</li>
<li>Cuántos niños había en el grupo (niño)</li>
<li>Ya sea que hayan traído o no una casa-rodante o “caravana” al parque (camper).</li>
</ul>
<p>Usando estos datos, vamos a construir un modelo que predice el número de peces capturados en función de las variables niño y caravana. Podemos usar Pandas para cargar los datos:</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>fish_data <span class="op">=</span> pd.read_csv(<span class="st">'datos/fish.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Lo dejo como un ejercicio para que explore el conjunto de datos utilizando gráficos y / o una función de Pandas, como <code>describe()</code>. Por ahora vamos a continuar traduciendo el diagrama de Kruschke anterior a PyMC3:</p>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> ZIP_reg:</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    ψ <span class="op">=</span> pm.Beta(<span class="st">'ψ'</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, <span class="dv">0</span>, <span class="dv">10</span>, shape<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    θ <span class="op">=</span> pm.math.exp(α <span class="op">+</span> β[<span class="dv">0</span>] <span class="op">*</span> fish_data[<span class="st">'child'</span>] <span class="op">+</span> β[<span class="dv">1</span>] <span class="op">*</span> fish_data[<span class="st">'camper'</span>])</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    yl <span class="op">=</span> pm.ZeroInflatedPoisson(<span class="st">'yl'</span>, ψ, θ, observed<span class="op">=</span>fish_data[<span class="st">'count'</span>])</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>    idata_ZIP_reg <span class="op">=</span> pm.sample()</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>az.plot_trace(idata_ZIP_reg)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [ψ, α, β]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-49-output-5.png" class="img-fluid"></p>
</div>
</div>
<p>Para entender mejor los resultados de nuestra inferencia, hagamos una gráfica.</p>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>children <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>fish_count_pred_0 <span class="op">=</span> []</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>fish_count_pred_1 <span class="op">=</span> []</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>post_ZIP_reg <span class="op">=</span> az.extract(idata_ZIP_reg)</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> children:</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>    without_camper <span class="op">=</span> post_ZIP_reg[<span class="st">'α'</span>] <span class="op">+</span> post_ZIP_reg[<span class="st">'β'</span>].sel({<span class="st">"β_dim_0"</span>:<span class="dv">0</span>}) <span class="op">*</span> n</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>    with_camper <span class="op">=</span> without_camper <span class="op">+</span> post_ZIP_reg[<span class="st">'β'</span>].sel({<span class="st">"β_dim_0"</span>:<span class="dv">1</span>})</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>    fish_count_pred_0.append(np.exp(without_camper))</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>    fish_count_pred_1.append(np.exp(with_camper))</span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>plt.plot(children, fish_count_pred_0, <span class="st">'C0.'</span>, alpha<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>plt.plot(children, fish_count_pred_1, <span class="st">'C1.'</span>, alpha<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a>plt.xticks(children)<span class="op">;</span></span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of children'</span>)</span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Fish caught'</span>)</span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>plt.plot([], <span class="st">'C0o'</span>, label<span class="op">=</span><span class="st">'without camper'</span>)</span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a>plt.plot([], <span class="st">'C1o'</span>, label<span class="op">=</span><span class="st">'with camper'</span>)</span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-50-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="regresión-por-cuantiles" class="level2">
<h2 class="anchored" data-anchor-id="regresión-por-cuantiles">Regresión por cuantiles</h2>
<p>En los ejemplos anteriores nos focalizamos en usar un modelo lineal para estimar la media de la variable respuesta, condicionada a una o más covariables. Quizá el caso más común sea usar la distribución Normal. Pero aprendimos que podemos aplicar la misma idea cambiando la distribución por otras como la Poisson, binomial, etc, según nuestras necesidades.</p>
<p>La regresión por cuantiles consiste en utilizar un modelo lineal para estimar un cuantil. Cuando el cuantil a estimar es la mediana, la motivación suele ser la necesidad de una regresión robusta. En ese caso la regresión por cuantiles cumpliría una función similar al modelo robusto donde reemplazamos la Gaussiana por una distribución t de Student. Otras veces la motivación surge del interés en modelar relaciones entre variables cuando no hay relación entre las medias de dichas variables, o cuando esta es muy debil. Una disciplina donde las regresiones por cuantiles son frecuentes es la ecología. Esto se debe posiblemente, a que la existencia de complejas interacciones entre variables, donde el efecto de una variable sobre otra es distinto para distintos rangos de la variable.</p>
<div class="cell" data-execution_count="467">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">2000</span>)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>quantiles <span class="op">=</span>  np.array([<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.8</span>])</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>kappas <span class="op">=</span> (quantiles<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>quantiles))<span class="op">**</span><span class="fl">0.5</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> q, m <span class="kw">in</span> <span class="bu">zip</span>(quantiles, [<span class="dv">0</span>, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>]):</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>    κ <span class="op">=</span> (q<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>q))<span class="op">**</span><span class="fl">0.5</span></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>    plt.plot(x, stats.laplace_asymmetric(κ, m, <span class="dv">1</span>).pdf(x), label<span class="op">=</span><span class="ss">f"q=</span><span class="sc">{</span>q<span class="sc">:}</span><span class="ss">, μ=</span><span class="sc">{</span>m<span class="sc">}</span><span class="ss">, σ=1"</span>)</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>plt.yticks([])<span class="op">;</span></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-51-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="418">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>quantiles <span class="op">=</span> np.array([<span class="fl">0.05</span>, <span class="fl">0.5</span>, <span class="fl">0.95</span>])</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>κ <span class="op">=</span> (quantiles<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>quantiles))<span class="op">**</span><span class="fl">0.5</span></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>y_con <span class="op">=</span> np.stack([data.Longitud.values]<span class="op">*</span> <span class="dv">3</span>).T</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>x_con <span class="op">=</span> np.stack([data.Meses.values]<span class="op">*</span> <span class="dv">3</span>).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="403">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_q:</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, <span class="dv">50</span>, <span class="dv">3</span>, shape<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, <span class="dv">0</span>, <span class="dv">5</span>, shape<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">'σ'</span>, <span class="dv">5</span>)</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> pm.Deterministic(<span class="st">'μ'</span>, α <span class="op">+</span> β <span class="op">*</span> x_con<span class="op">**</span><span class="fl">0.5</span>)</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> pm.AsymmetricLaplace(<span class="st">'y_pred'</span>,  κ, μ, σ, observed<span class="op">=</span>y_con)</span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>    idata_q <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β, σ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:11&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 11 seconds.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="404">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>az.summary(idata_q, var_names<span class="op">=</span><span class="st">"~μ"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="404">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>α[0]</th>
      <td>45.402</td>
      <td>0.230</td>
      <td>44.963</td>
      <td>45.833</td>
      <td>0.006</td>
      <td>0.004</td>
      <td>1727.0</td>
      <td>1965.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>α[1]</th>
      <td>47.954</td>
      <td>0.229</td>
      <td>47.504</td>
      <td>48.360</td>
      <td>0.005</td>
      <td>0.004</td>
      <td>1774.0</td>
      <td>1965.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>α[2]</th>
      <td>52.390</td>
      <td>0.185</td>
      <td>52.092</td>
      <td>52.763</td>
      <td>0.005</td>
      <td>0.003</td>
      <td>1557.0</td>
      <td>1939.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>β[0]</th>
      <td>6.658</td>
      <td>0.082</td>
      <td>6.517</td>
      <td>6.817</td>
      <td>0.002</td>
      <td>0.001</td>
      <td>1713.0</td>
      <td>2111.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>β[1]</th>
      <td>7.895</td>
      <td>0.078</td>
      <td>7.739</td>
      <td>8.035</td>
      <td>0.002</td>
      <td>0.001</td>
      <td>1706.0</td>
      <td>1849.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>β[2]</th>
      <td>8.825</td>
      <td>0.059</td>
      <td>8.714</td>
      <td>8.942</td>
      <td>0.002</td>
      <td>0.001</td>
      <td>1530.0</td>
      <td>1718.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>σ</th>
      <td>0.548</td>
      <td>0.011</td>
      <td>0.528</td>
      <td>0.568</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>2661.0</td>
      <td>2451.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="405">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>plt.plot(data.Meses, data.Longitud, <span class="st">"k."</span>)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, label <span class="kw">in</span> <span class="bu">enumerate</span>((<span class="st">"q=0.1"</span>, <span class="st">"q=0.5"</span>, <span class="st">"q=0.9"</span>)):</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>    plt.plot(data.Meses.values, idata_q.posterior[<span class="st">"μ"</span>].mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>))[:,idx],</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span>label, lw<span class="op">=</span><span class="dv">3</span>)<span class="op">;</span></span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-55-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="406">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_n:</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, <span class="dv">50</span>, <span class="dv">3</span>)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, <span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">'σ'</span>, <span class="dv">5</span>)</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> pm.Deterministic(<span class="st">'μ'</span>, α <span class="op">+</span> β <span class="op">*</span> data.Meses.values<span class="op">**</span><span class="fl">0.5</span>)</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> pm.Normal(<span class="st">'y_pred'</span>,  μ, σ, observed<span class="op">=</span>data.Longitud.values)</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>    idata_n <span class="op">=</span> pm.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β, σ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="425">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>plt.plot(data.Meses, data.Longitud, <span class="st">"."</span>, color<span class="op">=</span><span class="st">"0.8"</span>)</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, label <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="ss">f"</span><span class="sc">{</span>q<span class="op">=</span><span class="sc">:}</span><span class="ss">"</span> <span class="cf">for</span> q <span class="kw">in</span> quantiles]):</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    plt.plot(data.Meses.values, idata_q.posterior[<span class="st">"μ"</span>].mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>))[:,idx],</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span>label)<span class="op">;</span></span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>up <span class="op">=</span> (idata_n.posterior[<span class="st">"μ"</span>] <span class="op">+</span> idata_n.posterior[<span class="st">"σ"</span>]<span class="op">*</span><span class="fl">1.65</span>).mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>))</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>down <span class="op">=</span> (idata_n.posterior[<span class="st">"μ"</span>] <span class="op">-</span> idata_n.posterior[<span class="st">"σ"</span>]<span class="op">*</span><span class="fl">1.65</span>).mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>))</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>plt.plot(data.Meses.values, down, <span class="st">"C0"</span>, label<span class="op">=</span><span class="st">"μ - 1.65σ"</span>, ls<span class="op">=</span><span class="st">"--"</span>)<span class="op">;</span></span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>plt.plot(data.Meses.values, idata_n.posterior[<span class="st">"μ"</span>].mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>)), <span class="st">"C1"</span>, label<span class="op">=</span><span class="st">"μ"</span>,ls<span class="op">=</span><span class="st">"--"</span>)<span class="op">;</span></span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>plt.plot(data.Meses.values, up, <span class="st">"C2"</span>, label<span class="op">=</span><span class="st">"μ + 1.65σ"</span>, ls<span class="op">=</span><span class="st">"--"</span>)<span class="op">;</span></span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-16"><a href="#cb85-16" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="06_Generalizando_modelos_lineales_files/figure-html/cell-57-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="resumen" class="level2">
<h2 class="anchored" data-anchor-id="resumen">Resumen</h2>
</section>
<section id="ejercicios" class="level2">
<h2 class="anchored" data-anchor-id="ejercicios">Ejercicios</h2>
<ol type="1">
<li><p>Es conocido que para muchas especies el peso no escala con la altura/longitud, pero si lo hace con el logaritmo de peso. Use esa información para ajustar el conjunto de datos <code>howell</code> (sin distinción por edad). Repita el ajuste usando un polinomio de grado 2. Explique y compare ambos resultados.</p></li>
<li><p>Vuelva a correr el <code>modelo_0</code> pero esta vez usando las variables <code>petal_length</code> y <code>petal_width</code> ¿En que difieren los resultados? ¿Cuán ancho o angosto es el intervalo HDI 94%?</p></li>
<li><p>Repita el ejercicio 1, esta vez usando una distribución t de Student como <em>prior ligeramente informativo</em>. Pruebe con distintos valores de <span class="math inline">\(\nu\)</span>.</p></li>
<li><p>Use un modelo lineal (como los vistos en el capítulo anterior) para clasificar setosa o versicolor en función de <code>sepal_length</code>. ¿Cuán útil es este modelo comparado con una regresión logística?</p></li>
<li><p>En la sección <em>Interpretando los coeficientes de una regresion logística</em> vimos el efecto sobre el <code>log_odds</code> de cambiar la variable <code>sepal_length</code> en 1 unidad. Usando la figura 4.6 corrobore que el valor obtenido para <code>log_odds_versicolor_i</code> se corresponde con el valor de <code>probability_versicolor_i</code>. Haga lo mismo para <code>log_odds_versicolor_f</code> y <code>probability_versicolor_f</code>. Si solo sabemos que el valor de <code>log_odds_versicolor</code> es negativo que podemos decir de la probabilidad de versicolor, use la figura 4.6 como guía ¿Es este resultado evidente de la definición de log-odds?</p></li>
<li><p>Para <code>modelo_1</code> verifica cuanto cambian el valor de log-odd al incrementar <code>sepal_leght</code> de 5.5 a 6.5. ¿Cúal es el cambio en valores de probabilidad? ¿Cuál es el cambio en términos de log-odds y probabilidad al pasar de 4.5 a 5.5?</p></li>
<li><p>En el ejemplo de clases desbalanceadas cambie <code>df = df[45:]</code> por <code>df = df[22:78]</code>. Esto dejará más o menos el mismo número de datos, pero con las clases balanceadas. Compare con los resultados previos. ¿Cuál caso es más parecido a usar el conjunto de datos completo?</p></li>
<li><p>Suponga que en vez de usar una regresión softmax usamos un modelo lineal simple codificando <span class="math inline">\(\text{setosa}=0\)</span>, <span class="math inline">\(\text{versicolor}=1\)</span> y <span class="math inline">\(\text{virginica}=1\)</span>. Bajo el modelo lineal simple que pasaría si cambiáramos el orden del código.</p></li>
<li><p>Compara los likelihoods para el <code>modelo_0</code> y para el <code>modelo_lda</code>. Usa la función <code>pm.sample_posterior_predictive</code> para generar datos a partir de estos dos modelos. ¿En que difirien los datos predichos para ambos modelos?</p></li>
<li><p>Extienda el modelo <code>ZIP_reg</code> para incluir la variable <code>persons</code>. Usa esta variable para modelar el número de ceros extra. Deberás obtener un modelo que incluya dos modelos lineales, uno que conecte las variables <code>children</code> y <code>camper</code> a la tasa de Poisson y otro que conecte el número de personas con la variable <span class="math inline">\(\psi\)</span>. Presta atención si es necesario usar una función inversa de enlace.</p></li>
<li><p>Use los datos empleados en el ejemplo de la regresión logística robusta con un modelo de regresión logística simple. ¿Cuál es el efecto de los <em>outliers</em>? Pruebe agregando o eliminado <em>outliers</em>.</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>