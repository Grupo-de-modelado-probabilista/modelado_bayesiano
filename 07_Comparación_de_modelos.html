<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Comparación de modelos – Modelado Bayesiano</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./06_Regresión_lineal_con_Bambi.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-8ef56b68f8fa1e9d2ba328e99e439f80.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-72c03078af0861ca4e6c5a22356555be.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-2b66037661b4cf6b980b39a38e9fe92f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-72c03078af0861ca4e6c5a22356555be.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-B8PPDKVG6F"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-B8PPDKVG6F', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="[[8]{.chapter-number}&nbsp; [Comparación de modelos]{.chapter-title}]{#sec-model_comparison .quarto-section-identifier}">
<meta name="citation_publication_date" content="2025-05-29">
<meta name="citation_cover_date" content="2025-05-29">
<meta name="citation_year" content="2025">
<meta name="citation_fulltext_html_url" content="https://gmp.net.ar/modelado_bayesiano/">
<meta name="citation_doi" content="https://doi.org/10.5281/zenodo.7851296">
<meta name="citation_language" content="es">
<meta name="citation_book_title" content="Modelado Bayesiano">
</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./07_Comparación_de_modelos.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Comparación de modelos</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modelado Bayesiano</a> 
        <div class="sidebar-tools-main tools-wide">
    <div class="dropdown">
      <a href="" title="github" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="github"><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/Grupo-de-modelado-probabilista/Modelado_Bayesiano">
            Fuente
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/Grupo-de-modelado-probabilista/Modelado_Bayesiano/issues/new">
            Reportar errores
            </a>
          </li>
      </ul>
    </div>
    <a href="https://twitter.com/aloctavodia" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://bayes.club/@aloctavodia" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-mastodon"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Modo claro/oscuro"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Modo sin distracciones">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">‎</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_Probabilidad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probabilidad</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Inferencia_Bayesiana.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inferencia Bayesiana</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Programación_probabilística.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Programación probabilista</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Modelos_jerárquicos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Modelado Jerárquico</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Diagnóstico_MCMC.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Diagnóstico del muestreo</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Regresión_lineal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Regresión lineal</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_Regresión_lineal_con_Bambi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Regresión lineal con Bambi</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_Comparación_de_modelos.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Comparación de modelos</span></span></a>
  </div>
</li>
    </ul>
    </div>
<div class="quarto-sidebar-footer"><div class="sidebar-footer-item">
<center>
<br>¡Apoya la creación de contenido con una donación! (solo pagos Argentina)<a href="https://cafecito.app/aloctavodia" rel="noopener" target="_blank"><img srcset="https://cdn.cafecito.app/imgs/buttons/button_6.png 1x, https://cdn.cafecito.app/imgs/buttons/button_6_2x.png 2x, https://cdn.cafecito.app/imgs/buttons/button_6_3.75x.png 3.75x" src="https://cdn.cafecito.app/imgs/buttons/button_6.png" alt="Invitame un café en cafecito.app"></a><br><br>Support content creation with a donation! (Pay from everywhere)<a href="https://ko-fi.com/B0B5SN6SD" target="_blank"><img height="36" style="border:0px;height:36px;" src="https://storage.ko-fi.com/cdn/kofi1.png?v=3" border="0" alt="Buy Me a Coffee at ko-fi.com"></a>
</center>
</div></div></nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#pruebas-predictivas-a-posteriori" id="toc-pruebas-predictivas-a-posteriori" class="nav-link active" data-scroll-target="#pruebas-predictivas-a-posteriori"><span class="header-section-number">8.1</span> Pruebas predictivas a posteriori</a></li>
  <li><a href="#el-equilibro-entre-simplicidad-y-exactitud" id="toc-el-equilibro-entre-simplicidad-y-exactitud" class="nav-link" data-scroll-target="#el-equilibro-entre-simplicidad-y-exactitud"><span class="header-section-number">8.2</span> El equilibro entre simplicidad y exactitud</a>
  <ul class="collapse">
  <li><a href="#muchos-parámetros-pueden-conducir-a-sobreajuste" id="toc-muchos-parámetros-pueden-conducir-a-sobreajuste" class="nav-link" data-scroll-target="#muchos-parámetros-pueden-conducir-a-sobreajuste"><span class="header-section-number">8.2.1</span> Muchos parámetros (pueden) conducir a sobreajuste</a></li>
  <li><a href="#muy-pocos-parámetros-conducen-a-un-subajuste" id="toc-muy-pocos-parámetros-conducen-a-un-subajuste" class="nav-link" data-scroll-target="#muy-pocos-parámetros-conducen-a-un-subajuste"><span class="header-section-number">8.2.2</span> Muy pocos parámetros conducen a un subajuste</a></li>
  </ul></li>
  <li><a href="#medidas-de-exactitud-predictiva" id="toc-medidas-de-exactitud-predictiva" class="nav-link" data-scroll-target="#medidas-de-exactitud-predictiva"><span class="header-section-number">8.3</span> Medidas de exactitud predictiva</a>
  <ul class="collapse">
  <li><a href="#validación-cruzada" id="toc-validación-cruzada" class="nav-link" data-scroll-target="#validación-cruzada"><span class="header-section-number">8.3.1</span> Validación cruzada</a></li>
  <li><a href="#criterios-de-información" id="toc-criterios-de-información" class="nav-link" data-scroll-target="#criterios-de-información"><span class="header-section-number">8.3.2</span> Criterios de información</a></li>
  </ul></li>
  <li><a href="#calculo-de-exactitud-predictiva-usando-arviz" id="toc-calculo-de-exactitud-predictiva-usando-arviz" class="nav-link" data-scroll-target="#calculo-de-exactitud-predictiva-usando-arviz"><span class="header-section-number">8.4</span> Calculo de exactitud predictiva usando ArviZ</a></li>
  <li><a href="#promedio-de-modelos" id="toc-promedio-de-modelos" class="nav-link" data-scroll-target="#promedio-de-modelos"><span class="header-section-number">8.5</span> Promedio de modelos</a></li>
  <li><a href="#factores-de-bayes" id="toc-factores-de-bayes" class="nav-link" data-scroll-target="#factores-de-bayes"><span class="header-section-number">8.6</span> Factores de Bayes</a></li>
  <li><a href="#algunas-observaciones" id="toc-algunas-observaciones" class="nav-link" data-scroll-target="#algunas-observaciones"><span class="header-section-number">8.7</span> Algunas observaciones</a></li>
  <li><a href="#cálculo-de-los-fb" id="toc-cálculo-de-los-fb" class="nav-link" data-scroll-target="#cálculo-de-los-fb"><span class="header-section-number">8.8</span> Cálculo de los FB</a>
  <ul class="collapse">
  <li><a href="#analiticamente" id="toc-analiticamente" class="nav-link" data-scroll-target="#analiticamente"><span class="header-section-number">8.8.1</span> Analiticamente</a></li>
  <li><a href="#sequential-monte-carlo" id="toc-sequential-monte-carlo" class="nav-link" data-scroll-target="#sequential-monte-carlo"><span class="header-section-number">8.8.2</span> Sequential Monte Carlo</a></li>
  </ul></li>
  <li><a href="#factores-de-bayes-e-inferencia" id="toc-factores-de-bayes-e-inferencia" class="nav-link" data-scroll-target="#factores-de-bayes-e-inferencia"><span class="header-section-number">8.9</span> Factores de bayes e inferencia</a></li>
  <li><a href="#cociente-de-savage-dickey" id="toc-cociente-de-savage-dickey" class="nav-link" data-scroll-target="#cociente-de-savage-dickey"><span class="header-section-number">8.10</span> Cociente de Savage-Dickey</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-model_comparison" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Comparación de modelos</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="cell-1" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">from</span> matplotlib.ticker <span class="im">import</span> FormatStrFormatter</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> preliz <span class="im">as</span> pz</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="im">from</span> scipy.special <span class="im">import</span> betaln</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-2" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>az.style.use(<span class="st">'arviz-doc'</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<blockquote class="blockquote">
<p>“Un mapa no es el territorio que representa, pero si es correcto, tiene una estructura similar a la del territorio” - Alfred Korzybski</p>
</blockquote>
<p>Todos los modelos son erróneos, en el sentido de que solo son aproximaciones que se utilizan para intentar comprender un problema a través de datos y no una copia literal del <em>mundo real</em>. Si bien todos los modelos son incorrectos, no todos los modelos son igualmente incorrectos; algunos modelos serán mejores que otros al describir los mismos datos. Incluso algunos modelos serán mejores que otros solo para cierto rango o subconjunto de los datos.</p>
<p>En los capítulos anteriores, centramos nuestra atención en el problema de inferencia, es decir, cómo <em>aprender</em> el valor de los parámetros a partir de los datos. En este capítulo, nos centraremos en un problema complementario: cómo comparar dos o más modelos utilizados para explicar los mismos datos. Como veremos, este no es un problema trivial y, al mismo tiempo, es un problema central en el análisis de datos.</p>
<p>En el presente capítulo, exploraremos los siguientes temas:</p>
<ul>
<li><em>Overfitting</em> y <em>underfitting</em></li>
<li>Validación cruzada</li>
<li>Factores de Bayes</li>
<li>Regularización</li>
</ul>
<section id="pruebas-predictivas-a-posteriori" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="pruebas-predictivas-a-posteriori"><span class="header-section-number">8.1</span> Pruebas predictivas a posteriori</h2>
<p>Previamente hemos presentado y discutido las pruebas predictivas a posteriori como una forma de evaluar qué tan bien los modelos explican los mismos datos que se usan para ajustar al modelo. El propósito de este tipo de pruebas no es el de dictaminar que un modelo es incorrecto; ¡Esto ya lo sabemos! El objetivo del ejercicio es comprender qué tan bien estamos capturando los datos. Es frecuente que capturemos diferentes aspectos de los datos de diferentes maneras. Al realizar pruebas predictivas a posteriori, esperamos comprender mejor las limitaciones de un modelo, ya sea para tenerlas en cuenta o para intentar mejorar el modelo. Es esperable que un modelo no sea capaz de reproducir todos los aspectos de un problema y, por lo general, esto no es un problema ya que los modelos se construyen con un propósito en mente. Una prueba predictiva a posteriori es una forma de evaluar ese propósito, por lo tanto, si tenemos más de un modelo, podemos compararlos mediante pruebas predictivas a posteriori.</p>
<p>Veamos un ejemplo sencillo. Tenemos un conjunto de datos <code>x</code> e <code>y</code>. Vamos a ajustar estos datos con un modelo lineal:</p>
<p><span class="math display">\[
y = \alpha + \beta x
\]</span></p>
<p>Y un polinomio de orden 2:</p>
<p><span class="math display">\[
y = \alpha + \beta_0 x + \beta_1 x^2
\]</span></p>
<p>En el siguiente bloque de código cargamos los datos en las variables <code>x</code> e <code>y</code> “apilamos” <code>x, x**2</code> y estandarizamos.</p>
<div id="cell-5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>dummy_data <span class="op">=</span> np.loadtxt(<span class="st">'datos/dummy.csv'</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a>x <span class="op">=</span> dummy_data[:,<span class="dv">0</span>]</span>
<span id="cb3-3"><a href="#cb3-3"></a>y <span class="op">=</span> dummy_data[:,<span class="dv">1</span>]</span>
<span id="cb3-4"><a href="#cb3-4"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a>order <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-6"><a href="#cb3-6"></a>x_p <span class="op">=</span> np.vstack([x<span class="op">**</span>i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, order<span class="op">+</span><span class="dv">1</span>)])</span>
<span id="cb3-7"><a href="#cb3-7"></a>x_c <span class="op">=</span> (x_p <span class="op">-</span> x_p.mean(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)) <span class="op">/</span> x_p.std(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-8"><a href="#cb3-8"></a>y_c <span class="op">=</span> (y <span class="op">-</span> y.mean()) <span class="op">/</span> y.std()</span>
<span id="cb3-9"><a href="#cb3-9"></a>plt.scatter(x_c[<span class="dv">0</span>], y_c)</span>
<span id="cb3-10"><a href="#cb3-10"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb3-11"><a href="#cb3-11"></a>plt.ylabel(<span class="st">'y'</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Ahora, vamos a ajustar estos datos con dos modelos ligeramente diferentes, uno lineal y el otro un polinomio de orden 2, también conocido como modelo parabólico o cuadrático:</p>
<div id="cell-7" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_l:</span>
<span id="cb4-2"><a href="#cb4-2"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb4-4"><a href="#cb4-4"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">'σZ'</span>, <span class="dv">5</span>)</span>
<span id="cb4-5"><a href="#cb4-5"></a></span>
<span id="cb4-6"><a href="#cb4-6"></a>    μ <span class="op">=</span> α <span class="op">+</span> β <span class="op">*</span> x_c[<span class="dv">0</span>]</span>
<span id="cb4-7"><a href="#cb4-7"></a>    </span>
<span id="cb4-8"><a href="#cb4-8"></a>    y_pred <span class="op">=</span> pm.Normal(<span class="st">'y_pred'</span>, mu<span class="op">=</span>μ, sigma<span class="op">=</span>σ, observed<span class="op">=</span>y_c)</span>
<span id="cb4-9"><a href="#cb4-9"></a></span>
<span id="cb4-10"><a href="#cb4-10"></a>    idata_l <span class="op">=</span> pm.sample(<span class="dv">2000</span>, idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>: <span class="va">True</span>})</span>
<span id="cb4-11"><a href="#cb4-11"></a>    idata_l.extend(pm.sample_posterior_predictive(idata_l))</span>
<span id="cb4-12"><a href="#cb4-12"></a></span>
<span id="cb4-13"><a href="#cb4-13"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_p:</span>
<span id="cb4-14"><a href="#cb4-14"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-15"><a href="#cb4-15"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>, shape<span class="op">=</span>order)</span>
<span id="cb4-16"><a href="#cb4-16"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">'σ'</span>, <span class="dv">5</span>)</span>
<span id="cb4-17"><a href="#cb4-17"></a></span>
<span id="cb4-18"><a href="#cb4-18"></a>    μ <span class="op">=</span> α <span class="op">+</span> pm.math.dot(β, x_c)</span>
<span id="cb4-19"><a href="#cb4-19"></a>    </span>
<span id="cb4-20"><a href="#cb4-20"></a>    y_pred <span class="op">=</span> pm.Normal(<span class="st">'y_pred'</span>, mu<span class="op">=</span>μ, sigma<span class="op">=</span>σ, observed<span class="op">=</span>y_c)</span>
<span id="cb4-21"><a href="#cb4-21"></a></span>
<span id="cb4-22"><a href="#cb4-22"></a>    idata_p <span class="op">=</span> pm.sample(<span class="dv">2000</span>, idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>: <span class="va">True</span>})</span>
<span id="cb4-23"><a href="#cb4-23"></a>    idata_p.extend(pm.sample_posterior_predictive(idata_p))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β, ϵ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="12000" class="" max="12000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [12000/12000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 2 seconds.
Sampling: [y_pred]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:00&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β, ϵ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="12000" class="" max="12000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [12000/12000 00:04&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 5 seconds.
Sampling: [y_pred]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:00&lt;00:00]
    </div>
    
</div>
</div>
<p>Ahora, vamos a visualizar el ajuste para ambos modelos:</p>
<div id="cell-9" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>x_new <span class="op">=</span> np.linspace(x_c[<span class="dv">0</span>].<span class="bu">min</span>(), x_c[<span class="dv">0</span>].<span class="bu">max</span>(), <span class="dv">100</span>)</span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a>posterior_l <span class="op">=</span> az.extract(idata_l)</span>
<span id="cb9-4"><a href="#cb9-4"></a>posterior_p <span class="op">=</span> az.extract(idata_p)</span>
<span id="cb9-5"><a href="#cb9-5"></a></span>
<span id="cb9-6"><a href="#cb9-6"></a>α_l_post <span class="op">=</span> posterior_l[<span class="st">'α'</span>].mean().item()</span>
<span id="cb9-7"><a href="#cb9-7"></a>β_l_post <span class="op">=</span> posterior_l[<span class="st">'β'</span>].mean().item()</span>
<span id="cb9-8"><a href="#cb9-8"></a>y_l_post <span class="op">=</span> α_l_post <span class="op">+</span> β_l_post <span class="op">*</span>  x_new</span>
<span id="cb9-9"><a href="#cb9-9"></a></span>
<span id="cb9-10"><a href="#cb9-10"></a>plt.plot(x_new, y_l_post, <span class="st">'C0'</span>, label<span class="op">=</span><span class="st">'modelo lineal'</span>)</span>
<span id="cb9-11"><a href="#cb9-11"></a></span>
<span id="cb9-12"><a href="#cb9-12"></a>α_p_post <span class="op">=</span> posterior_p[<span class="st">'α'</span>].mean().item()</span>
<span id="cb9-13"><a href="#cb9-13"></a>β_p_post <span class="op">=</span> posterior_p[<span class="st">'β'</span>].mean(<span class="st">"sample"</span>)</span>
<span id="cb9-14"><a href="#cb9-14"></a>idx <span class="op">=</span> np.argsort(x_c[<span class="dv">0</span>])</span>
<span id="cb9-15"><a href="#cb9-15"></a>y_p_post <span class="op">=</span> α_p_post <span class="op">+</span> np.dot(β_p_post, x_c)</span>
<span id="cb9-16"><a href="#cb9-16"></a></span>
<span id="cb9-17"><a href="#cb9-17"></a>plt.plot(x_c[<span class="dv">0</span>][idx], y_p_post[idx], <span class="st">'C1'</span>, label<span class="op">=</span><span class="ss">f'polinomio de orden </span><span class="sc">{</span>order<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-18"><a href="#cb9-18"></a></span>
<span id="cb9-19"><a href="#cb9-19"></a>plt.plot(x_c[<span class="dv">0</span>], y_c, <span class="st">"k."</span>)</span>
<span id="cb9-20"><a href="#cb9-20"></a>plt.legend()<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Ambos modelos parecen brindar ajustes razonables, aunque el modelo de orden 2 parece estar haciendo un mejor trabajo, pero el modelo lineal no es tan malo.</p>
<p>En el mismo sentido la siguiente figura muestra un mejor acuerdo del ajuste polinomial sobre el lineal</p>
<div id="cell-11" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-2"><a href="#cb10-2"></a>az.plot_ppc(idata_l, num_pp_samples<span class="op">=</span><span class="dv">100</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>], legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'modelo lineal'</span>)</span>
<span id="cb10-4"><a href="#cb10-4"></a>az.plot_ppc(idata_p, num_pp_samples<span class="op">=</span><span class="dv">100</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>])<span class="op">;</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>axes[<span class="dv">1</span>].set_title(<span class="ss">f'polinomio de orden </span><span class="sc">{</span>order<span class="sc">}</span><span class="ss">'</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>En vez de comparar directamente la distribución de datos observados versus la distribución predicha podemos comparar estadísticos sumarios.</p>
<p>En el panel superior de la siguiente figura se muestra 2 KDEs, representando la distribución de las medias predichas por los modelos. El punto sobre eje x indica el valor observado.</p>
<p>En el segundo panel lo mismo pero para el rango intercuartil.</p>
<div id="cell-13" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>), sharey<span class="op">=</span><span class="st">"row"</span>)</span>
<span id="cb11-2"><a href="#cb11-2"></a>colors <span class="op">=</span> [<span class="st">"C0"</span>, <span class="st">"C1"</span>]</span>
<span id="cb11-3"><a href="#cb11-3"></a>titles <span class="op">=</span> [<span class="st">"media"</span>, <span class="st">"rango intercuartil"</span>]</span>
<span id="cb11-4"><a href="#cb11-4"></a>modelos <span class="op">=</span> [<span class="st">"lineal"</span>, <span class="ss">f'orden </span><span class="sc">{</span>order<span class="sc">}</span><span class="ss">'</span>]</span>
<span id="cb11-5"><a href="#cb11-5"></a>idatas <span class="op">=</span> [idata_l, idata_p]</span>
<span id="cb11-6"><a href="#cb11-6"></a></span>
<span id="cb11-7"><a href="#cb11-7"></a><span class="kw">def</span> iqr(x, a<span class="op">=-</span><span class="dv">1</span>):</span>
<span id="cb11-8"><a href="#cb11-8"></a>    <span class="cf">return</span> np.subtract(<span class="op">*</span>np.percentile(x, [<span class="dv">75</span>, <span class="dv">25</span>], axis<span class="op">=</span>a))</span>
<span id="cb11-9"><a href="#cb11-9"></a></span>
<span id="cb11-10"><a href="#cb11-10"></a><span class="cf">for</span> idata, c <span class="kw">in</span> <span class="bu">zip</span>(idatas, colors):</span>
<span id="cb11-11"><a href="#cb11-11"></a>    az.plot_bpv(idata, kind<span class="op">=</span><span class="st">"t_stat"</span>, t_stat<span class="op">=</span><span class="st">"mean"</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>], color<span class="op">=</span>c)</span>
<span id="cb11-12"><a href="#cb11-12"></a>    </span>
<span id="cb11-13"><a href="#cb11-13"></a></span>
<span id="cb11-14"><a href="#cb11-14"></a><span class="cf">for</span> idata, c <span class="kw">in</span> <span class="bu">zip</span>(idatas, colors):</span>
<span id="cb11-15"><a href="#cb11-15"></a>    az.plot_bpv(idata, kind<span class="op">=</span><span class="st">"t_stat"</span>, t_stat<span class="op">=</span>iqr, ax<span class="op">=</span>axes[<span class="dv">1</span>], color<span class="op">=</span>c)</span>
<span id="cb11-16"><a href="#cb11-16"></a></span>
<span id="cb11-17"><a href="#cb11-17"></a><span class="cf">for</span> ax, title, <span class="kw">in</span> <span class="bu">zip</span>(axes, titles):</span>
<span id="cb11-18"><a href="#cb11-18"></a>    ax.set_title(title)</span>
<span id="cb11-19"><a href="#cb11-19"></a>    <span class="cf">for</span> idx, (c, modelo) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(colors, modelos)):</span>
<span id="cb11-20"><a href="#cb11-20"></a>        ax.legend_.legend_handles [idx]._alpha <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-21"><a href="#cb11-21"></a>        ax.legend_.legend_handles [idx]._color <span class="op">=</span> c</span>
<span id="cb11-22"><a href="#cb11-22"></a>        ax.legend_._loc <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-23"><a href="#cb11-23"></a>        ax.legend_.texts[idx]._text <span class="op">=</span> modelo <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> ax.legend_.texts[idx]._text</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>En la figura anterior también se incluyen unos valores llamados bpv, por Bayesian p-value. Los bpv son una forma numérica de resumir una comparación entre datos simulados y datos reales. Para obtenerlos se elige un estadístico sumario <span class="math inline">\(T\)</span>, como por ejemplo la la media, mediana, desviación estándar etc. Luego se calcula <span class="math inline">\(T\)</span> para los datos observados <span class="math inline">\(T_{\text{obs}}\)</span> y para los datos simulados <span class="math inline">\(T_{\text{sim}}\)</span>. Luego podemos hacernos dos preguntas:</p>
<ol type="1">
<li>Cual es la probabilidad que <span class="math inline">\(T_{\text{sim}}\)</span> sea menor o igual a <span class="math inline">\(T_{\text{obs}}\)</span>?. Si los valores observados concuerdan con los predichos, el valor esperado será 0.5. Es decir la mitad de las predicciones están por debajo y la mitad por encima de lo observado. Esta cantidad es lo que se conoce como <em>valor p Bayesiano</em>.</li>
</ol>
<p><span class="math display">\[\text{valor p Bayesiano} \triangleq p(T_{\text{sim}} \le T_{\text{obs}}  \mid \tilde Y)\]</span></p>
<p>Para quienes estén familiarizados con los <em>valores p</em> y su uso en estadística frecuentista van un par de aclaraciones. Lo <strong>Bayesiano</strong> de estos <em>valores p</em> es que NO estamos usando una distribución de muestreo sino <em>la distribución predictiva a posteriori</em>. Y una diferencia importante con la versión frecuentista es que en este caso no estamos haciendo una prueba de hipótesis nula, ni intentando declarar que una diferencia es “significativa”.</p>
<p>En la figura anterior <span class="math inline">\(T\)</span> es la media (panel superior) o el rango interquartil (panel inferior). En este ejemplo es razonable que la media <em>de bien</em> ya que el modelo lineal está construido para capturar la media. Si <span class="math inline">\(T\)</span> fuese la mediana, observaríamos diferencias algo más grandes. En general un estadístico que sea <em>ortogonal</em> a lo que el modelo ajusta de forma directa será más informativo para evaluar al modelo. Ante la duda puede ser conveniente evaluar más de un estadístico. En general es útil preguntarse que aspectos de los datos nos interesa capturar mejor.</p>
<ol start="2" type="1">
<li>Otra forma de usar los bpv, es preguntar para <strong>cada valor</strong> observado, cual es la probabilidad de predecir un valor menor o igual. Si el modelo está bien calibrado la probabilidad debería ser la misma para todos los valores. Es decir para cualquier observación que tomemos deberíamos encontrar tantas simulaciones por encima como por debajo de ese valor. En definitiva deberíamos esperar una distribución uniforme. En la siguiente figura se muestran las distribuciones para el modelo lineal y polinomio de orden 2. La linea blanca indica la distribución uniforme esperada y la banda gris indica las desviaciones esperadas dado el tamaño finito de la muestra. Se puede ver que ambos modelos son muy similares.</li>
</ol>
<div id="cell-15" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>))</span>
<span id="cb12-2"><a href="#cb12-2"></a></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="cf">for</span> idata, c <span class="kw">in</span> <span class="bu">zip</span>(idatas, colors):</span>
<span id="cb12-4"><a href="#cb12-4"></a>    az.plot_bpv(idata, color<span class="op">=</span>c, ax<span class="op">=</span>ax)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Las pruebas predictivas <em>a posteriori</em> ofrecen un marco muy flexible para evaluar y comparar modelos, ya sea utilizando gráficos o resúmenes numéricos como los <em>valores p bayesianos</em>, o incluso una combinación de ambos. El concepto es lo suficientemente general para permitir que una analista use su imaginación para encontrar diferentes formas de explorar la distribución predictiva <em>a posteriori</em> y use las que mejor se ajusten a los fines de poder interpretar los datos y modelos.</p>
<p>En las siguientes secciones vamos a explorar otros métodos para comparar modelos.</p>
</section>
<section id="el-equilibro-entre-simplicidad-y-exactitud" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="el-equilibro-entre-simplicidad-y-exactitud"><span class="header-section-number">8.2</span> El equilibro entre simplicidad y exactitud</h2>
<p>Al elegir entre explicaciones alternativas, existe un principio conocido como la navaja de Occam. En lineas muy generales este principio establece que dadas dos o más explicaciones equivalentes para el mismo fenómeno, la más simple es la explicación preferida. Un criterio común de simplicidad es la cantidad de parámetros de un modelo.</p>
<p>Hay muchas justificaciones para esta heurística, no vamos a discutir ninguna simplemente vamos a aceptarla como una guía razonable.</p>
<p>Otro factor que generalmente debemos tener en cuenta al comparar modelos es su exactitud, es decir, qué tan bueno es un modelo ajustando los datos. Según este criterio si tenemos dos (o más) modelos y uno de ellos explica los datos mejor que el otro, entonces ese es el modelo preferido.</p>
<p>Intuitivamente, parece que al comparar modelos, tendemos a preferir aquellos que mejor ajusten los datos y aquellos que sean más simples. ¿Pero que hacer si estos dos principios se contraponen? O de forma más general, ¿Existe una forma cuantitativa de contemplar ambas contribuciones? La respuesta corta es que si, de hecho hay más de una forma de hacerlo. Pero antes veamos un ejemplo a fin de generar mayor intuición.</p>
<section id="muchos-parámetros-pueden-conducir-a-sobreajuste" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="muchos-parámetros-pueden-conducir-a-sobreajuste"><span class="header-section-number">8.2.1</span> Muchos parámetros (pueden) conducir a sobreajuste</h3>
<p>Vamos a comenzar por combinar polinomios cada vez más complejos en un conjunto de datos muy simple. En lugar de utilizar la maquinaria Bayesiana, usaremos la aproximación de mínimos cuadrados para ajustar modelos lineales.</p>
<div id="cell-19" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a>_, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb13-2"><a href="#cb13-2"></a></span>
<span id="cb13-3"><a href="#cb13-3"></a></span>
<span id="cb13-4"><a href="#cb13-4"></a>x0 <span class="op">=</span> np.array([<span class="fl">4.</span>, <span class="fl">5.</span>, <span class="fl">6.</span>, <span class="fl">9.</span>, <span class="dv">12</span>, <span class="fl">14.</span>])</span>
<span id="cb13-5"><a href="#cb13-5"></a>y0 <span class="op">=</span> np.array([<span class="fl">4.2</span>, <span class="fl">6.1</span>, <span class="fl">5.</span>, <span class="fl">10.</span>, <span class="dv">10</span>, <span class="fl">14.</span>])</span>
<span id="cb13-6"><a href="#cb13-6"></a></span>
<span id="cb13-7"><a href="#cb13-7"></a>order <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>]</span>
<span id="cb13-8"><a href="#cb13-8"></a>ax.plot(x0, y0, <span class="st">'ko'</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb13-9"><a href="#cb13-9"></a></span>
<span id="cb13-10"><a href="#cb13-10"></a></span>
<span id="cb13-11"><a href="#cb13-11"></a>ax.set_yticks([])</span>
<span id="cb13-12"><a href="#cb13-12"></a>ax.set_xticks([])</span>
<span id="cb13-13"><a href="#cb13-13"></a></span>
<span id="cb13-14"><a href="#cb13-14"></a>x_n <span class="op">=</span> np.linspace(x0.<span class="bu">min</span>(), x0.<span class="bu">max</span>(), <span class="dv">100</span>)</span>
<span id="cb13-15"><a href="#cb13-15"></a>ps <span class="op">=</span> []</span>
<span id="cb13-16"><a href="#cb13-16"></a><span class="cf">for</span> i <span class="kw">in</span> order:</span>
<span id="cb13-17"><a href="#cb13-17"></a>    p <span class="op">=</span> np.polynomial.Polynomial.fit(x0, y0, deg<span class="op">=</span>i)</span>
<span id="cb13-18"><a href="#cb13-18"></a>    ps.append(p)</span>
<span id="cb13-19"><a href="#cb13-19"></a>    yhat <span class="op">=</span> p(x0)</span>
<span id="cb13-20"><a href="#cb13-20"></a>    ybar <span class="op">=</span> np.mean(y0)</span>
<span id="cb13-21"><a href="#cb13-21"></a>    ss_regression <span class="op">=</span> np.<span class="bu">sum</span>((yhat<span class="op">-</span>y0)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb13-22"><a href="#cb13-22"></a>    ss_total <span class="op">=</span> np.<span class="bu">sum</span>((ybar<span class="op">-</span>y0)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb13-23"><a href="#cb13-23"></a>    r2 <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> ss_regression <span class="op">/</span> ss_total</span>
<span id="cb13-24"><a href="#cb13-24"></a>    ax.plot(x_n, p(x_n), label<span class="op">=</span><span class="ss">f'orden </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, $R^2$= </span><span class="sc">{</span>r2<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb13-25"><a href="#cb13-25"></a></span>
<span id="cb13-26"><a href="#cb13-26"></a>    </span>
<span id="cb13-27"><a href="#cb13-27"></a>ax.legend(loc<span class="op">=</span><span class="dv">2</span>, fontsize<span class="op">=</span><span class="dv">12</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>De la figura anterior podemos ver que el aumento de la complejidad del modelo se acompaña de una mayor exactitud reflejada en el coeficiente de determinación R². De hecho, podemos ver que el polinomio de orden 5 se ajusta perfectamente a los datos, obteniendo un R²=1.</p>
<p>¿Por qué el polinomio de grado 5 puede capturar los datos sin perder uno solo de ellos? La razón es que tenemos el mismo número de parámetros que de datos es decir 6. Por lo tanto, el modelo está actuando simplemente como una forma alternativa de expresar los datos. El modelo no está aprendiendo algo sobre los datos, ¡Está memorizando los datos! A partir de este simple ejemplo, podemos ver que un modelo con mayor ajuste no siempre es lo ideal.</p>
<p>Ahora agregaremos dos datos nuevos y sin volver a ajustar los modelos veremos como cambia el R². Se puede ver que al modelo lineal le va mejor en este caso que al polinomial.</p>
<div id="cell-21" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>_, ax <span class="op">=</span> plt.subplots( figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb14-2"><a href="#cb14-2"></a>x_ <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">10</span>])</span>
<span id="cb14-3"><a href="#cb14-3"></a>y_ <span class="op">=</span> np.array([<span class="dv">7</span>, <span class="dv">10</span>])</span>
<span id="cb14-4"><a href="#cb14-4"></a></span>
<span id="cb14-5"><a href="#cb14-5"></a>ax.plot(x0, y0, <span class="st">'ko'</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb14-6"><a href="#cb14-6"></a>ax.plot(x_, y_, <span class="st">'ks'</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb14-7"><a href="#cb14-7"></a></span>
<span id="cb14-8"><a href="#cb14-8"></a>ax.set_yticks([])</span>
<span id="cb14-9"><a href="#cb14-9"></a>ax.set_xticks([])</span>
<span id="cb14-10"><a href="#cb14-10"></a></span>
<span id="cb14-11"><a href="#cb14-11"></a>x1 <span class="op">=</span> np.concatenate((x0, x_))</span>
<span id="cb14-12"><a href="#cb14-12"></a>y1 <span class="op">=</span> np.concatenate((y0, y_))</span>
<span id="cb14-13"><a href="#cb14-13"></a></span>
<span id="cb14-14"><a href="#cb14-14"></a><span class="cf">for</span> idx, i <span class="kw">in</span> <span class="bu">enumerate</span>(order):</span>
<span id="cb14-15"><a href="#cb14-15"></a>    yhat <span class="op">=</span> ps[idx](x1)</span>
<span id="cb14-16"><a href="#cb14-16"></a>    ybar <span class="op">=</span> np.mean(y1)</span>
<span id="cb14-17"><a href="#cb14-17"></a>    ss_regression <span class="op">=</span> np.<span class="bu">sum</span>((yhat<span class="op">-</span>y1)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb14-18"><a href="#cb14-18"></a>    ss_total <span class="op">=</span> np.<span class="bu">sum</span>((ybar<span class="op">-</span>y1)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb14-19"><a href="#cb14-19"></a>    r2 <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> ss_regression <span class="op">/</span> ss_total</span>
<span id="cb14-20"><a href="#cb14-20"></a>    ax.plot(x_n, ps[idx](x_n), label<span class="op">=</span><span class="ss">f'orden </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, $R^2$= </span><span class="sc">{</span>r2<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb14-21"><a href="#cb14-21"></a></span>
<span id="cb14-22"><a href="#cb14-22"></a>    </span>
<span id="cb14-23"><a href="#cb14-23"></a>ax.legend(loc<span class="op">=</span><span class="dv">2</span>, fontsize<span class="op">=</span><span class="dv">12</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Cuando un modelo ajusta muy bien, el conjunto de datos utilizado para aprender los parámetros de ese modelo, pero muy mal otros conjuntos de datos, decimos que tenemos sobreajuste (overfitting). Este es un problema muy común al analizar datos.</p>
<p>Una forma muy útil de pensar el sobreajuste es considerar que un conjunto de datos tiene dos componentes; la señal y el ruido. La señal es lo que queremos capturar (o aprender) de los datos. Si usamos un conjunto de datos es porque creemos que hay una señal allí, de lo contrario será un ejercicio fútil. El ruido, en cambio, no es útil y es el producto de los errores de medición, las limitaciones en la forma en que se generaron o capturaron los datos, la presencia de datos corruptos, etc. Un modelo sobreajusta cuando es tan flexible (para un conjunto de datos) que es capaz de <em>aprender</em> el ruido. Esto tiene como consecuencia que la señal queda oculta.</p>
<p>Esta es una justificación práctica para la navaja de Occam. Y nos advierte que al menos en principio, siempre es posible crear un modelo tan complejo que explique todos los detalles, incluso los más irrelevantes. Tal como en el Imperio descripto por Borges, donde los cartógrafos alcanzaron tal nivel de sofisticación que crearon un mapa del Imperio cuyo tamaño era el del propio Imperio, y que coincidía punto por punto con él.</p>
</section>
<section id="muy-pocos-parámetros-conducen-a-un-subajuste" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="muy-pocos-parámetros-conducen-a-un-subajuste"><span class="header-section-number">8.2.2</span> Muy pocos parámetros conducen a un subajuste</h3>
<p>Continuando con el mismo ejemplo pero en el otro extremo de complejidad, tenemos el modelo de orden 0. Este modelo es simplemente una Gaussiana disfrazada de modelo lineal. Este modelo solo es capaz de capturar el valor de la media de <span class="math inline">\(Y\)</span>, y es por lo tanto totalente indiferente a los valores de <span class="math inline">\(x\)</span>. Decimos que este modelo ha subajustado los datos.</p>
</section>
</section>
<section id="medidas-de-exactitud-predictiva" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="medidas-de-exactitud-predictiva"><span class="header-section-number">8.3</span> Medidas de exactitud predictiva</h2>
<p><em>Todo debe hacerse tan simple como sea posible, pero no más simple</em> es una cita que a menudo se atribuye a Einstein. Al igual que en una dieta saludable, al modelar tenemos que mantener un balance. Idealmente, nos gustaría tener un modelo que ni sub-ajuste ni sobre-ajuste los datos. De alguna forma hay que balancear simplicidad y bondad de ajuste.</p>
<p>En el ejemplo previo, es relativamente facil de ver que el modelo de orden 0 es <em>demasiado</em> simple mientras que el modelo de orde 5 es <em>demasiado</em> complejo. Pero que podemos decir de los otros dos modelos? Cómo podríamos establecer un ranking numérico de estos modelos? Para poder hacer esto necesitamos formalizar nuestra intuición sobre este balance entre simplicidad y exactitud</p>
<p>Veamos un par de términos que nos serán de utilidad.</p>
<ul>
<li><strong>Exactitud dentro de la muestra</strong> (within-sample accuracy). La exactitud medida con los mismos datos usado para ajustar el modelo.</li>
<li><strong>Exactitud fuera de la muestra</strong> (out-of-sample accuracy). La exactitud medida con datos no usados para ajustar el modelo.</li>
</ul>
<p>La exactitud dentro de la muestra será, en promedio, menor a la exactitud fuera de la muestra. Es por ello que usar la exactitud dentro de la muestra para evaluar un modelo en general conducirá a pensar que tenemos un mejor modelo de lo que realmente es. Utilizar la exactitud fuera de la muestra es por lo tanto una mejor idea para evitar engañarnos a nosotros mismos. Sin embargo, esta aproximación requiere dejar datos fuera del ajuste, lo cual es un lujo que en general no nos podemos dar. Ya que este es un problema central en el análisis de datos existen varias propuestas para abordarlo. Dos aproximaciones muy populares son:</p>
<ul>
<li><p>Validación cruzada: esta es una estrategia empírica basada en dividir los datos disponibles en subconjuntos separados que se utilizan para ajustar y evaluar de forma alternativa</p></li>
<li><p>Criterios de información: este es un término general usado para referirse a varias expresiones que aproximan la exactitud fuera de la muestra como la exactitud dentro de la muestra más un término que penaliza la complejidad del modelo.</p></li>
</ul>
<section id="validación-cruzada" class="level3" data-number="8.3.1">
<h3 data-number="8.3.1" class="anchored" data-anchor-id="validación-cruzada"><span class="header-section-number">8.3.1</span> Validación cruzada</h3>
<p>La validación cruzada es una solución simple y, en la mayoría de los casos, efectiva para comparar modelos. Tomamos nuestros datos y los dividimos en K porciones. Intentamos mantener las porciones más o menos iguales (en tamaño y, a veces, también en otras características, como, por ejemplo, un número igual de clases). Luego usamos K-1 porciones para entrenar el modelo y el resto para evaluarlo. Este proceso se repite sistemáticamente dejando, por cada iteración, una porción diferente fuera del conjunto de entrenamiento y usando esa porción como el conjunto de evaluación. Esto se repite hasta que hayamos completado K rondas de ajuste-evaluación. La exactitud del modelo será la del promedio a lo largo de las K rondas. Esto se conoce como validación cruzada K-fold. Por último, una vez que hemos relizado la validación cruzada, usamos todos los datos para ajustar por última vez nuestro modelo y este es el modelo que se utiliza para hacer predicciones o para cualquier otro fin.</p>
<p><img src="img/cv.png" width="500"></p>
<p>Cuando K es igual a la cantidad de puntos de datos, obtenemos lo que se conoce como <em>validación cruzada dejando uno afuera</em> (LOOCV del inglés leave-one-out cross-validation).</p>
<p>La validación cruzada es una práctica de rutina en <em>machine learning</em>. Y apenas hemos descripto los aspectos más esenciales de esta práctica. Para mayor información pueden leer <a href="http://themlbook.com/">The Hundred-Page Machine Learning Book</a> o <a href="https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow-ebook/dp/B0742K7HYF/ref=dp_ob_title_def">Python Machine Learning</a>, by Sebastian Raschka, o <a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science Handbook</a> by Jake Vanderplas.</p>
<p>La validación cruzada es una idea muy simple y útil, pero para algunos modelos o para grandes cantidades de datos, el costo computacional de la validación cruzada puede estar más allá de nuestras posibilidades. Muchas personas han tratado de encontrar cantidades más simples de calcular que se aproximen a los resultados obtenidos con la validación cruzada o que funcionen en escenarios donde la validación cruzada no puede ser tan fácil de realizar. Y ese es el tema de la siguiente sección.</p>
</section>
<section id="criterios-de-información" class="level3" data-number="8.3.2">
<h3 data-number="8.3.2" class="anchored" data-anchor-id="criterios-de-información"><span class="header-section-number">8.3.2</span> Criterios de información</h3>
<p>Los criterios de información son una colección de herramientas estrechamente relacionadas que se utilizan para comparar modelos en términos de la bondad del ajuste y de la complejidad del modelo. En otras palabras, los criterios de información formalizan la intuición que desarrollamos al comienzo del capítulo. La forma exacta en que se derivan estas cantidades tiene que ver con un campo conocido como <a href="http://www.inference.org.uk/mackay/itila/book.html">Teoría de la Información</a>.</p>
<p>Una forma intuitiva de medir qué tan bien un modelo se ajusta a los datos es calcular el error cuadrático medio entre los datos y las predicciones realizadas por el modelo:</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^{n}  (y_i - \operatorname{E} (y_i \mid \theta))^2\]</span></p>
<p><span class="math inline">\(\operatorname{E} (y_i \mid \theta)\)</span> es el valor predicho dados los parámetros estimados. Es importante notar que esto es esencialmente el promedio de la diferencia entre los datos observados y los predichos. Tomar el cuadrado de los errores asegura que las diferencias no se cancelen y enfatiza grandes errores comparado con otros alternativas como por ejemplo calcular el valor absoluto.</p>
<p>El error cuadrático medio, puede resultarnos familiar ya que es muy popular. Pero si nos detenemos a reflexionar sobre esta cantidad veremos que en principio no tiene nada de especial y bien podríamos idear otras expresiones similares. Cuando adoptamos una aproximación probabilista vemos que una expresión más general (y <em>natural</em>) es la siguiente:</p>
<p><span class="math display">\[ \sum_{i=1}^{n} \log p(y_i \mid \theta)\]</span></p>
<p>Esto es, la suma (sobre <span class="math inline">\(n\)</span> datos) de los <em>likelihoods</em> (en escala logarítmica). Esto es <em>natural</em> por que al elegir un likelihood en un modelo estamos eligiendo implícitamente una métrica para evaluar el ajuste del modelo. Cuando <span class="math inline">\(p(y_i \mid \theta)\)</span> es una gaussiana entonces la suma de log-likelihood será proporcional al error cuadrático medio.</p>
<section id="criterio-de-información-de-akaike" class="level4" data-number="8.3.2.1">
<h4 data-number="8.3.2.1" class="anchored" data-anchor-id="criterio-de-información-de-akaike"><span class="header-section-number">8.3.2.1</span> Criterio de información de Akaike</h4>
<p>Este es un criterio de información muy conocido y ampliamente utilizado fuera del universo Bayesiano y se define como:</p>
<p><span class="math display">\[AIC = -2 \sum_{i=1}^{n} \log p(y_i \mid \hat{\theta}_{mle}) + 2 k \]</span></p>
<p>Donde, k es el número de parámetros del modelo y <span class="math inline">\(\hat{\theta}_{mle}\)</span> es la estimación por máxima verosimilitud para <span class="math inline">\(\theta\)</span>.</p>
<p>La estimación de máxima verosimilitud es una práctica común para los no-bayesianos y, en general, es equivalente a la estimación Bayesiana del máximo a posteriori (MAP) cuando se usan priors <em>planos</em>. Es importante notar que <span class="math inline">\(\hat{\theta}_{mle}\)</span> es una estimación puntual y no una distribución.</p>
<p>El factor <span class="math inline">\(-2\)</span> es tan solo una constante, y podríamos omitirla pero usualmente no se hace. Lo importante, desde el punto de vista práctico, es que el primer término toma en cuenta cuan bien el modelo ajusta los datos, mientras que el segundo término penaliza la complejidad del modelo. Por lo tanto si dos modelos ajustan los datos igualmente bien. AIC dice que deberemos elegir aquel modelo con el menor número de parámetros.</p>
<p>AIC funciona bien en enfoques no-bayesianos, pero de lo contrario es problemático. Una de las razones es que no utiliza la distribución a posteriori de <span class="math inline">\(\theta\)</span> y, por lo tanto, descarta información sobre la incertidumbre en la estimación. Además AIC, desde una pespectiva Bayesiana, asume que los priors son <em>planos</em> y, por lo tanto, AIC es incompatible con priors informativos y ligeramente informativos como los utilizados en este libro. Además, la cantidad de parámetros de un modelo no es una buena medida de la complejidad del mismo cuando se usan priors informativos o estructuras como la jerárquica ya que estas son formas de reducir la <em>cantidad efectiva de parámetros</em>, algo también conocido como <em>regularización</em>. Más adelante volveremos sobre esta idea de regularización.</p>
</section>
<section id="widely-applicable-information-criterion" class="level4" data-number="8.3.2.2">
<h4 data-number="8.3.2.2" class="anchored" data-anchor-id="widely-applicable-information-criterion"><span class="header-section-number">8.3.2.2</span> Widely applicable information criterion</h4>
<p>WAIC es algo así como la versión Bayesiana de AIC, al igual que este último WAIC se compone de dos términos uno que mide el ajuste y otro que penaliza. La siguiente expresión asume que la distribución a posteriori está representada como una muestra de tamaño S (como la obtenida de un método MCMC).</p>
<p><span class="math display">\[WAIC = -2 \sum_i^n \log \left(\frac{1}{S} \sum_{s=1}^S p(y_i \mid \theta^s) \right) + 2 \sum_i^n  \left( V_{s=1}^S \log p(y_i \mid \theta^s) \right)\]</span></p>
<p>El primer término es similar al criterio de Akaike, solo que evaluado para todas las observaciones y todas las muestras del posterior. El segundo término es un poco más difícil de justificar sin entrar en tecnicismos. Pero es también una forma de penalizar la complejidad del modelo. Lo importante desde el punto de vista práctico es que WAIC usa todo el posterior (y no una estimación puntual) para el cálculo de ambos términos, por lo que WAIC puede ser aplicado virtualmente a cualquier modelo Bayesiano.</p>
</section>
<section id="validación-cruzada-aproximada" class="level4" data-number="8.3.2.3">
<h4 data-number="8.3.2.3" class="anchored" data-anchor-id="validación-cruzada-aproximada"><span class="header-section-number">8.3.2.3</span> Validación cruzada (aproximada)</h4>
<p>El problema clave con la validación cruzada dejando uno fuera es que es muy costosa ya que tenemos que reajustar el modelo tantas veces como datos tengamos. Por suerte, es posible aproximarla con un solo ajuste a los datos! El método para hacer esto se llama “muestreo de importancia usando un suavizado de Pareto”. El nombre es tan poco agraciado que en la práctica le decimos LOO. Conceptualmente lo que estamos tratando de calcular es:</p>
<p><span class="math display">\[
\text{ELPD}_\text{LOO-CV} = \sum_{i=1}^{n} \log
    \int \ p(y_i \mid \theta) \; p(\theta \mid y_{-i}) d\theta
\]</span></p>
<p><span class="math display">\[
\sum_{i}^{n} \log
    \left( \frac{1}{s}\sum_j^s \mathbin{\color{#E9692C}{p(y_i \mid \theta_{-i}^j)}} \right)
\]</span></p>
<p>donde <span class="math inline">\(_{-i}\)</span> quiere decir que dejamos la observación <span class="math inline">\(i\)</span> afuera. Es posible aproximar <span class="math inline">\(\color{#E9692C}{p(y_i \mid \theta_{-i}^j})\)</span> usando importance sampling, que es una forma de aproximar una distribución repesando valores obtenidos a partir de otra distribución. En nuestro caso la distribución conocida, una vez ajustado un modelo, es el log-likelihood para todas las observaciones. Y queremos aproximar el log-likelihood si hubieramos eliminado una observación. Para ello necesitamos estimar la “importancia” (o peso) que cada observación tiene en determinar la distribución a posteriori. Una observación será más “importante” (o pesada) mientras más cambie el posterior al eliminar esa observación. Intuitivamente una observación relativamente poco probable es más importante (o tiene más peso) que una esperada. Por suerte estos pesos se puede estimar sin necesidad de reajustar el modelo, de hecho el peso de la observación <span class="math inline">\(i\)</span> para la muestra del posterior <span class="math inline">\(s\)</span> es:</p>
<p><span class="math display">\[
w_s = \frac{1}{p(y_i \mid \theta_s)}
\]</span></p>
<p>El problema es que bajo ciertas condiciones estos pesos puede no ser confiables. El principal problema es que unos pocos <span class="math inline">\(w_s\)</span> podrían ser tan grandes que dominan el cálculo, y es aquí donde entra el suavizado de Pareto que basicamente consiste en reemplazar algunos de estos pesos por pesos obtenidos a partir de ajustar una distribución de Pareto ¿por qué una distribución de Pareto? Por que la teoría indica que los pesos deberían seguir esta distribución. Entonces para cada observation <span class="math inline">\(y_i\)</span> , los pesos más grandes se usan para estimar una distribución de Pareto y esa distribución se usa para reemplazar esos pesos por pesos “suavizados”. Este procedimiento le da robustez a la estimación del ELPD y además provee de un diagóstico ya que valores de <span class="math inline">\(k\)</span> (uno de los parámetros de la distribución de Pareto) mayores a 0.7 indican que posiblemente tengamos observaciones “muy influyentes”.</p>
</section>
<section id="otros-criterios-de-información" class="level4" data-number="8.3.2.4">
<h4 data-number="8.3.2.4" class="anchored" data-anchor-id="otros-criterios-de-información"><span class="header-section-number">8.3.2.4</span> Otros criterios de información</h4>
<p>Otro criterio de información muy usado es DIC, si usamos el <em>bayesómetro™</em>, DIC es más bayesiano que AIC pero menos que WAIC. Aunque aún es popular, WAIC y principalmentete LOO han demostrado ser más útiles tanto teóricamente como empíricamente que DIC. Por lo cual NO recomendamos su uso.</p>
<p>Otro criterio muy usado es BIC (del inglés Bayesian Information Criteria), al igual que la regresión logística y la <em>sopa seca</em> de mi madre, este nombre puede ser engañoso. BIC se propuso como una forma de corregir algunos de los problemas con AIC y el autor propuso una justificación Bayesiana para ello. Pero BIC no es realmente Bayesiano en el sentido que al igual que AIC asume priors <em>planos</em> y utiliza una estimación por máxima verosimilitud.</p>
<p>Pero lo que es más importante, es que BIC difiere de AIC y WAIC en su objetivo. AIC y WAIC intentan reflejar cual modelo generaliza mejor a otros datos (exactitud predictiva) mientras que BIC intenta identificar cual es el modelo <em>correcto</em> y por lo tanto está más relacionado los factores de Bayes que con WAIC. Más adelante discutiremos Factores de Bayes y veremos como se diferencia de criterios como WAIC y LOO.</p>
</section>
</section>
</section>
<section id="calculo-de-exactitud-predictiva-usando-arviz" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="calculo-de-exactitud-predictiva-usando-arviz"><span class="header-section-number">8.4</span> Calculo de exactitud predictiva usando ArviZ</h2>
<p>Afortunadamente, calcular los criterios de información con ArviZ es muy simple. Veamos:</p>
<div id="cell-32" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>waic_l <span class="op">=</span> az.waic(idata_l)</span>
<span id="cb15-2"><a href="#cb15-2"></a>waic_l</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>Computed from 8000 posterior samples and 33 observations log-likelihood matrix.

          Estimate       SE
elpd_waic   -14.29     2.67
p_waic        2.38        -</code></pre>
</div>
</div>
<div id="cell-33" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>waic_p <span class="op">=</span> az.waic(idata_p)</span>
<span id="cb17-2"><a href="#cb17-2"></a>waic_p</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>Computed from 8000 posterior samples and 33 observations log-likelihood matrix.

          Estimate       SE
elpd_waic    -4.54     2.31
p_waic        2.61        -</code></pre>
</div>
</div>
<p>Lo mismo para LOO.</p>
<div id="cell-35" class="cell" data-scrolled="true" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>loo_l <span class="op">=</span> az.loo(idata_l)</span>
<span id="cb19-2"><a href="#cb19-2"></a>loo_l</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>Computed from 8000 posterior samples and 33 observations log-likelihood matrix.

         Estimate       SE
elpd_loo   -14.31     2.67
p_loo        2.40        -
------

Pareto k diagnostic values:
                         Count   Pct.
(-Inf, 0.5]   (good)       33  100.0%
 (0.5, 0.7]   (ok)          0    0.0%
   (0.7, 1]   (bad)         0    0.0%
   (1, Inf)   (very bad)    0    0.0%</code></pre>
</div>
</div>
<div id="cell-36" class="cell" data-scrolled="true" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>loo_p <span class="op">=</span> az.loo(idata_p)</span>
<span id="cb21-2"><a href="#cb21-2"></a>loo_p</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>Computed from 8000 posterior samples and 33 observations log-likelihood matrix.

         Estimate       SE
elpd_loo    -4.58     2.32
p_loo        2.65        -
------

Pareto k diagnostic values:
                         Count   Pct.
(-Inf, 0.5]   (good)       33  100.0%
 (0.5, 0.7]   (ok)          0    0.0%
   (0.7, 1]   (bad)         0    0.0%
   (1, Inf)   (very bad)    0    0.0%</code></pre>
</div>
</div>
<p>Tanto <code>az.waic</code> como <code>az.loo</code> devuelven 3 valores</p>
<ol type="1">
<li>Una estimación puntual del ELPD.</li>
<li>El error estándar de esa estimación</li>
<li>El número efectivo de parámetros</li>
</ol>
<p>Además LOO devuelve un diagnóstico basado en el parámetro k, correspondiente al ajuste de la distribución de Pareto.</p>
<p>Los valores de WAIC o LOO no tienen sentido por si mismos, y deben ser interpretados de forma relativa. Es por ello que ArviZ ofrece dos funciones auxiliares para facilitar esta comparación veamos primero a <code>az.compare</code>.</p>
<div id="cell-38" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>cmp_df <span class="op">=</span> az.compare({<span class="st">'modelo_l'</span>:idata_l, <span class="st">'modelo_p'</span>:idata_p})</span>
<span id="cb23-2"><a href="#cb23-2"></a>cmp_df</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">rank</th>
<th data-quarto-table-cell-role="th">elpd_loo</th>
<th data-quarto-table-cell-role="th">p_loo</th>
<th data-quarto-table-cell-role="th">elpd_diff</th>
<th data-quarto-table-cell-role="th">weight</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">dse</th>
<th data-quarto-table-cell-role="th">warning</th>
<th data-quarto-table-cell-role="th">scale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">modelo_p</td>
<td>0</td>
<td>-4.575778</td>
<td>2.646204</td>
<td>0.000000</td>
<td>1.000000e+00</td>
<td>2.318739</td>
<td>0.00000</td>
<td>False</td>
<td>log</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">modelo_l</td>
<td>1</td>
<td>-14.309050</td>
<td>2.399241</td>
<td>9.733272</td>
<td>3.215206e-13</td>
<td>2.673219</td>
<td>2.68794</td>
<td>False</td>
<td>log</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>En las filas tenemos los modelos comparados y en la columnas tenemos</p>
<ul>
<li>rank : el orden de los modelos (de mejor a peor)</li>
<li>elpd : la estimación puntual del elpd usando</li>
<li>p : los parámetros efectivos</li>
<li>elpd_diff : la diferencia entre el ELPD del mejor modelo y los demás modelos</li>
<li>weight : el peso relativo de cada modelo. Si quisieramos hacer predicciones combinando los distintos modelos, en vez de elegir uno solo, este sería el peso que deberíamos asignar a cada modelo. En este caso vemos que el modelo polinomial se lleva todo el peso.</li>
<li>se : el error estándard del ELPD</li>
<li>dse : el error estándard de las difencias</li>
<li>warning : una advertencia sobre valores de k altos</li>
<li>scale : la escala en la que se calcula el ELPD</li>
</ul>
<p>También podemos obtener más o menos la misma información de forma gráfica usando la función <code>az.compareplot</code>.</p>
<div id="cell-40" class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>az.plot_compare(cmp_df)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Los círculos vacíos representan los valores del ELPD y lineas negras el error estándar.</li>
<li>El valor más alto del ELPD se indica con una línea gris discontinua vertical para facilitar la comparación con otros valores.</li>
<li>Para todos los modelos, excepto <em>el mejor</em>, también obtenemos un triángulo que indica el valor de la diferencia del ELPD entre cada modelo y el <em>mejor</em> modelo. La barra de error gris que indica el error estándar de las diferencias entre las estimaciones puntuales.</li>
</ul>
<p>La forma más sencilla de utilizar los criterios de información es elegir un único modelo. Simplemente elija el modelo con el valor más alto de ELPD. Si seguimos esta regla tendremos que aceptar que el modelo cuadrático es el mejor. Incluso si tenemos en cuenta los errores estandar podemos ver que estos no se solapan. Lo que nos da cierta seguridad que efectivamente los modelos son <em>diferentes</em> entre si. Si, en cambio, los errores estándar se superpusieran, deberíamos proporcionar una respuesta más matizada.</p>
</section>
<section id="promedio-de-modelos" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="promedio-de-modelos"><span class="header-section-number">8.5</span> Promedio de modelos</h2>
<p>La selección de modelos es atractiva por su simplicidad, pero podríamos estar descartando información sobre la incertidumbre en nuestros modelos. Esto es de alguna manera similar a calcular el posterior completo y luego solo mantener la media del posterior; esto puede conducirnos a confiar <em>demasiado</em> en lo que creemos saber.</p>
<p>Una alternativa es seleccionar un solo modelo, pero informar y analizar los diferentes modelos junto con los valores de los criterios de información calculados, sus valores de error estándar y quizás también las pruebas predictivas a posteriori. Es importante poner todos estos números y pruebas en el contexto de nuestro problema para que nosotros y nuestra audiencia podamos tener una mejor idea de las posibles limitaciones y deficiencias de los modelos. Para quienes trabajan en el mundo académico, estos elementos se pueden utilizar para agregar elementos a la sección de discusión de un paper, presentación, tesis, etc. Y en la industria esto puede ser útil para informar a clientes sobre las ventajas y limitaciones de las predicciones o conclusiones del modelado.</p>
<p>Otra posibilidad es promediar los modelos. De esta forma estamos introduciendo la incertidumbre que tenemos sobre la bondad de cada modelo, y podemos generar un metamodelo (y meta-predicciones) usando un promedio pesado de cada modelo.</p>
<div id="cell-43" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>idata_w <span class="op">=</span> az.weight_predictions(idatas, weights<span class="op">=</span>[<span class="fl">0.35</span>, <span class="fl">0.65</span>])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-44" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>_, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb26-2"><a href="#cb26-2"></a>az.plot_kde(idata_l.posterior_predictive[<span class="st">'y_pred'</span>].values, plot_kwargs<span class="op">=</span>{<span class="st">'color'</span>:<span class="st">'C0'</span>}, label<span class="op">=</span><span class="st">'modelo lineal'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb26-3"><a href="#cb26-3"></a>az.plot_kde(idata_p.posterior_predictive[<span class="st">'y_pred'</span>].values, plot_kwargs<span class="op">=</span>{<span class="st">'color'</span>:<span class="st">'C1'</span>}, label<span class="op">=</span><span class="st">'orden 2'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb26-4"><a href="#cb26-4"></a>az.plot_kde(idata_w.posterior_predictive[<span class="st">'y_pred'</span>].values, plot_kwargs<span class="op">=</span>{<span class="st">'color'</span>:<span class="st">'C2'</span>}, label<span class="op">=</span><span class="st">'modelo pesado'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb26-5"><a href="#cb26-5"></a></span>
<span id="cb26-6"><a href="#cb26-6"></a>plt.plot(y_c, np.zeros_like(y_c), <span class="st">'k|'</span>, label<span class="op">=</span><span class="st">'observed data'</span>)</span>
<span id="cb26-7"><a href="#cb26-7"></a>plt.yticks([])</span>
<span id="cb26-8"><a href="#cb26-8"></a>plt.legend()<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Hay otras formas de promediar modelos, como, por ejemplo, construir explícitamente un metamodelo que incluya todos los modelos de interés como casos particulares. Por ejemplo un polinomio de grado 2 contiene como caso particular un modelo lineal, o un modelo jerárquico es la versión continua entre dos extremos un modelo agrupado y uno desagrupado.</p>
</section>
<section id="factores-de-bayes" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="factores-de-bayes"><span class="header-section-number">8.6</span> Factores de Bayes</h2>
<p>Una alternativa a LOO, la validación cruzada y los criterios de información son los factores de Bayes. Es común que los factores de Bayes aparezcan en la literatura como una alternativa Bayesiana al contraste de hipótesis frecuentista.</p>
<p>La “manera Bayesiana” de comparar <span class="math inline">\(k\)</span> modelos es calcular la <em>verosimilitud marginal</em> de cada modelo <span class="math inline">\(p(y \mid M_k)\)</span>, es decir, la probabilidad de los datos observados <span class="math inline">\(Y\)</span> dado el modelo <span class="math inline">\(M_k\)</span>. Esta cantidad, la <em>verosimilitud marginal</em>, es simplemente la constante de normalización del teorema de Bayes. Podemos ver esto si escribimos el teorema de Bayes y hacemos explícito el hecho de que todas las inferencias dependen del modelo.</p>
<p><span class="math display">\[p (\theta \mid Y, M_k ) = \frac{p(Y \mid \theta, M_k) p(\theta \mid M_k)}{p(Y \mid M_k)}\]</span></p>
<p>dónde:</p>
<ul>
<li><span class="math inline">\(y\)</span> son los datos</li>
<li><span class="math inline">\(\theta\)</span> los parámetros</li>
<li><span class="math inline">\(M_k\)</span> un modelo de k modelos competidores</li>
</ul>
<p>Si nuestro objetivo principal es elegir solo un modelo, el <em>mejor</em>, de un conjunto de modelos podemos elegir el que tiene el mayor valor de <span class="math inline">\(p(y \mid M_k)\)</span>. Esto está bien si asumimos que <strong>todos los modelos</strong> tienen la misma probabilidad <em>a priori</em>. De lo contrario debemos calcular:</p>
<p><span class="math display">\[p(M_k \mid y) \propto p(y \mid M_k) p(M_k)\]</span></p>
<p>Si en cambio, nuestro objetivo principal es comparar modelos para determinar cuáles son más probables y en qué medida. Esto se puede lograr utilizando los factores de Bayes:</p>
<p><span class="math display">\[FB_{01} = \frac{p(y \mid M_0)}{p(y \mid M_1)}\]</span></p>
<p>es decir, el cociente entre la verosimilitud marginal de dos modelos. Cuanto mayor sea el FB, <em>mejor</em> el modelo en el numerador (<span class="math inline">\(M_0\)</span> en este ejemplo). Para facilitar la interpretación de los FB, Harold Jeffreys propuso una escala para la interpretación de los Factores de Bayes con niveles de <em>apoyo</em> o <em>fuerza</em>. Esta es solo una manera de poner números en palabras.</p>
<ul>
<li>1-3: anecdótico</li>
<li>3-10: moderado</li>
<li>10-30: fuerte</li>
<li>30-100: muy fuerte</li>
<li><span class="math inline">\(&gt;\)</span> 100: extremo</li>
</ul>
<p>Hay que tener en cuenta que si se obtiene números por debajo de 1, entonces el soporte es para el modelo en el denominador, también hay tablas disponibles para esos casos. O simplemente podemos tomar la inversa del valor obtenido.</p>
<p>Es muy importante recordar que estas reglas son solo convenciones, guías simples en el mejor de los casos. Los resultados siempre deben ponerse en el contexto de nuestros problemas y deben ir acompañados de suficientes detalles para que otros puedan evaluar por sí mismos si están de acuerdo con nuestras conclusiones. No es lo mismo la prueba necesaria para asegurar algo en física de partículas, o en un juzgado, o para decidir realizar una evacuación frente a una catástrofe natural que se avecina.</p>
</section>
<section id="algunas-observaciones" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="algunas-observaciones"><span class="header-section-number">8.7</span> Algunas observaciones</h2>
<p>Ahora discutiremos brevemente algunos hechos clave sobre la <em>verosimilitud marginal</em></p>
<ul>
<li>El bueno
<ul>
<li><strong>Navaja de Occam incluida</strong>: Los modelos con más parámetros tienen una penalización mayor que los modelos con menos parámetros. La razón intuitiva es que cuanto mayor es el número de parámetros, más se <em>extiende</em> el <em>prior</em> con respecto al likelihood. Un ejemplo donde es facil ver esto es con los modelos anidados, por ej un polinomio de orden 2 “contiene” a los modelos modelos “polinomio de orden 1” y polinimo de orden 0.</li>
</ul></li>
<li>El malo
<ul>
<li>Para muchos problemas la verosimilitud marginal no puede ser calculada analiticamente. Y aproximarla numéricamente suele ser una tarea difícil que en el mejor de los casos requiere de métodos especializados y en el peor las estimaciones o no son prácticas o no son confiables. De hecho la popularidad de los métodos MCMC es que permiten obtener la distribución a posteriori sin necesidad de calcular esta cantidad.</li>
</ul></li>
<li>El feo
<ul>
<li>La probabilidad marginal depende <strong>muy sensiblemente</strong> de la distribución a priori de los parámetros en cada modelo <span class="math inline">\(p(\theta_k \mid M_k)\)</span>.</li>
</ul></li>
</ul>
<p>Es importante notar que <em>lo bueno</em> y <em>lo feo</em> están relacionados. Usar la verosimilitud marginal para comparar modelos es una buena idea por que ya incluye una penalización para modelos complejos (lo que nos ayuda a prevenir el sobreajuste) y, al mismo tiempo, un cambio en el prior afectará los cálculos de la verosimilitud marginal. Al principio esto suena un poco tonto; ya sabemos que los priors afectan los cálculos (de lo contrario, simplemente podríamos evitarlos), pero el punto aquí es la palabra <strong>sensiblemente</strong>. Estamos hablando que cambios en el prior que apenas tendrían efecto en el posterior tendrán un gran impacto en el valor de la verosimilitud marginal.</p>
<p>El uso de los FB suele ser una divisoria de aguas entre Bayesianos. La dificultad de su cálculo y la sensibilidad a los priors son algunos de los argumentos en contra. Otra razón es que al igual que lo p-valores y en general las pruebas de hipótesis los BF favorecen el pensamiento dicotómico por sobre la estimación del “tamaño del efecto”. Es decir en vez de hacernos preguntas del estilo ¿Cuantos años más de vida puede proporcionar, en promedio, un tratamiento oncológico? Terminamos preguntando si la diferencia entre tratar y no tratar a un paciente es “estadísticamente significativa”. Ojo que esta última pregunta puede ser útil en algunos contextos, el punto es que en muchos otros contextos, ese tipo de preguntas no es la pregunta que nos interesa, solo la que nos enseñaron a contestar.</p>
</section>
<section id="cálculo-de-los-fb" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="cálculo-de-los-fb"><span class="header-section-number">8.8</span> Cálculo de los FB</h2>
<p>Como ya mencionamos la verosimilitud marginal (y los factores de Bayes derivadas de ella) generalmente no está disponible en forma cerrada, excepto para algunos modelos. Por esta razón, se han ideado muchos métodos numéricos para su cálculo. Algunos de estos métodos son tan simples e <a href="https://radfordneal.wordpress.com/2008/08/17/the-harmonic-mean-of-the-likelihood-worst-monte-carlo-method-ever/">ingenuos</a> que funciona muy mal en la práctica.</p>
<section id="analiticamente" class="level3" data-number="8.8.1">
<h3 data-number="8.8.1" class="anchored" data-anchor-id="analiticamente"><span class="header-section-number">8.8.1</span> Analiticamente</h3>
<p>Para algunos modelos, como el modelo beta-binomial, podemos calcular la verosimilitud marginal analíticamente. Si escribimos este modelo como:</p>
<p><span class="math display">\[\theta \sim Beta(\alpha, \beta)\]</span> <span class="math display">\[y \sim Bin(n=1, p=\theta)\]</span></p>
<p>la <em>verosimilitud marginal</em> será:</p>
<p><span class="math display">\[p(y) = \binom {n}{h} \frac{B(\alpha + h,\ \beta + n - h)} {B(\alpha, \beta)}\]</span></p>
<p>dónde:</p>
<ul>
<li><span class="math inline">\(B\)</span> es la <a href="https://en.wikipedia.org/wiki/Beta_function">función beta</a> no confundirse con la distribución <span class="math inline">\(Beta\)</span></li>
<li><span class="math inline">\(n\)</span> es el número de intentos</li>
<li><span class="math inline">\(h\)</span> es el número de éxito</li>
</ul>
<p>Como solo nos importa el valor relativo de la <em>verosimilitud marginal</em> bajo dos modelos diferentes (para los mismos datos), podemos omitir el coeficiente binomial <span class="math inline">\(\binom {n}{h}\)</span>, por lo que podemos escribir:</p>
<p><span class="math display">\[p(y) \propto \frac{B(\alpha + h,\ \beta + n - h)} {B(\alpha, \beta)}\]</span></p>
<p>Esta expresión ha sido codificada en la siguiente celda, pero con un giro. Usaremos la función <code>betaln</code>, que devuelve el logaritmo natural de la función <code>beta</code>, es común en estadística hacer cálculos en escala logaritmica, esto reduce problemas numéricos al trabajar con probabilidades.</p>
<div id="cell-50" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="kw">def</span> beta_binom(prior, y):</span>
<span id="cb27-2"><a href="#cb27-2"></a>    <span class="co">"""</span></span>
<span id="cb27-3"><a href="#cb27-3"></a><span class="co">    Calcula la probabilidad marginal, analíticamente, para un modelo beta-binomial.</span></span>
<span id="cb27-4"><a href="#cb27-4"></a></span>
<span id="cb27-5"><a href="#cb27-5"></a><span class="co">     prior : tupla</span></span>
<span id="cb27-6"><a href="#cb27-6"></a><span class="co">         tupla de parámetro alfa y beta para el prior (distribución beta)</span></span>
<span id="cb27-7"><a href="#cb27-7"></a><span class="co">     y : array</span></span>
<span id="cb27-8"><a href="#cb27-8"></a><span class="co">         array con "1" y "0" correspondientes al éxito y falla respectivamente</span></span>
<span id="cb27-9"><a href="#cb27-9"></a><span class="co">    """</span></span>
<span id="cb27-10"><a href="#cb27-10"></a>    alpha, beta <span class="op">=</span> prior</span>
<span id="cb27-11"><a href="#cb27-11"></a>    h <span class="op">=</span> np.<span class="bu">sum</span>(y)</span>
<span id="cb27-12"><a href="#cb27-12"></a>    n <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb27-13"><a href="#cb27-13"></a>    p_y <span class="op">=</span> np.exp(betaln(alpha <span class="op">+</span> h, beta <span class="op">+</span> n <span class="op">-</span> h) <span class="op">-</span> betaln(alpha, beta))</span>
<span id="cb27-14"><a href="#cb27-14"></a>    <span class="cf">return</span> p_y</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nuestros datos para este ejemplo consisten en 100 “lanzamientos de una moneda” y el mismo número de “caras” y cecas” observadas. Compararemos dos modelos uno con un prior uniforme y otro con un a priori <em>más concentrado</em> alrededor de <span class="math inline">\(\theta = 0.5\)</span></p>
<div id="cell-52" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a>y <span class="op">=</span> np.repeat([<span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">50</span>, <span class="dv">50</span>])  <span class="co"># 50 "caras" y 50 "cecas"</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>priors <span class="op">=</span> ((<span class="dv">1</span>, <span class="dv">1</span>), (<span class="dv">30</span>, <span class="dv">30</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-53" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a><span class="cf">for</span> a, b <span class="kw">in</span> priors:</span>
<span id="cb29-2"><a href="#cb29-2"></a>    x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">300</span>)</span>
<span id="cb29-3"><a href="#cb29-3"></a>    x_pdf <span class="op">=</span> pz.Beta(a, b).pdf(x)</span>
<span id="cb29-4"><a href="#cb29-4"></a>    plt.plot(x, x_pdf, label<span class="op">=</span><span class="vs">rf"</span><span class="dv">$</span><span class="ch">\a</span><span class="vs">lpha</span><span class="dv">$</span><span class="vs"> = </span><span class="sc">{</span>a<span class="sc">:d}</span><span class="vs">, </span><span class="dv">$\b</span><span class="vs">eta</span><span class="dv">$</span><span class="vs"> = </span><span class="sc">{</span>b<span class="sc">:d}</span><span class="vs">"</span>)</span>
<span id="cb29-5"><a href="#cb29-5"></a>    plt.yticks([])</span>
<span id="cb29-6"><a href="#cb29-6"></a>    plt.xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">theta$"</span>)</span>
<span id="cb29-7"><a href="#cb29-7"></a>    plt.legend()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>La siguiente celda devuelve el factor de Bayes</p>
<div id="cell-55" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a>BF <span class="op">=</span> beta_binom(priors[<span class="dv">1</span>], y) <span class="op">/</span> beta_binom(priors[<span class="dv">0</span>], y)</span>
<span id="cb30-2"><a href="#cb30-2"></a><span class="bu">print</span>(<span class="bu">round</span>(BF))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5</code></pre>
</div>
</div>
<p>Vemos que el modelo con el prior <span class="math inline">\(\text{beta}(30, 30)\)</span>, más concentrado, tiene <span class="math inline">\(\approx 5\)</span> veces más apoyo que el modelo con el <span class="math inline">\(\text{beta}(1, 1)\)</span>. Esto es esperable ya que el prior para el primer caso se concentra alrededor de <span class="math inline">\(\theta = 0.5\)</span> y los datos <span class="math inline">\(Y\)</span> tienen el mismo número de caras y cruces, es decir acuerdan con un valor de <span class="math inline">\(\theta\)</span> alrededor de 0.5.</p>
</section>
<section id="sequential-monte-carlo" class="level3" data-number="8.8.2">
<h3 data-number="8.8.2" class="anchored" data-anchor-id="sequential-monte-carlo"><span class="header-section-number">8.8.2</span> Sequential Monte Carlo</h3>
<p>El método Sequential Monte Carlo es un método de muestreo que básicamente progresa mediante una serie de secuencias sucesivas desde el prior al posterior. Un subproducto de este proceso es la estimación de la verosimilitud marginal. En realidad, por razones numéricas, el valor devuelto es el logaritmo de la verosimilitud marginal.</p>
<div id="cell-58" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a>models <span class="op">=</span> []</span>
<span id="cb32-2"><a href="#cb32-2"></a>idatas <span class="op">=</span> []</span>
<span id="cb32-3"><a href="#cb32-3"></a><span class="cf">for</span> alpha, beta <span class="kw">in</span> priors:</span>
<span id="cb32-4"><a href="#cb32-4"></a>    <span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb32-5"><a href="#cb32-5"></a>        a <span class="op">=</span> pm.Beta(<span class="st">"a"</span>, alpha, beta)</span>
<span id="cb32-6"><a href="#cb32-6"></a>        yl <span class="op">=</span> pm.Bernoulli(<span class="st">"yl"</span>, a, observed<span class="op">=</span>y)</span>
<span id="cb32-7"><a href="#cb32-7"></a>        idata <span class="op">=</span> pm.sample_smc(random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb32-8"><a href="#cb32-8"></a>        models.append(model)</span>
<span id="cb32-9"><a href="#cb32-9"></a>        idatas.append(idata)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Initializing SMC sampler...
Sampling 4 chains in 4 jobs</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="100" class="" max="100" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [100/100 00:00&lt;?  Stage: 2 Beta: 1.000]
    </div>
    
</div>
<div class="cell-output cell-output-stdout">
<pre><code>    </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/osvaldo/anaconda3/envs/pymc/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (4) than draws (3). Passed array should have shape (chains, draws, *shape)
  warnings.warn(
Initializing SMC sampler...
Sampling 4 chains in 4 jobs</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="100" class="" max="100" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [100/100 00:00&lt;?  Stage: 0 Beta: 1.000]
    </div>
    
</div>
<div class="cell-output cell-output-stdout">
<pre><code>    </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/osvaldo/anaconda3/envs/pymc/lib/python3.10/site-packages/arviz/data/base.py:221: UserWarning: More chains (4) than draws (1). Passed array should have shape (chains, draws, *shape)
  warnings.warn(</code></pre>
</div>
</div>
<div id="cell-59" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a>BF_smc <span class="op">=</span> np.exp(</span>
<span id="cb38-2"><a href="#cb38-2"></a>    idatas[<span class="dv">1</span>].sample_stats[<span class="st">"log_marginal_likelihood"</span>].mean()</span>
<span id="cb38-3"><a href="#cb38-3"></a>    <span class="op">-</span> idatas[<span class="dv">0</span>].sample_stats[<span class="st">"log_marginal_likelihood"</span>].mean()</span>
<span id="cb38-4"><a href="#cb38-4"></a>)</span>
<span id="cb38-5"><a href="#cb38-5"></a>np.<span class="bu">round</span>(BF_smc).item()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>5.0</code></pre>
</div>
</div>
<p>Como podemos ver en la celda anterior, ¡SMC da esencialmente la misma respuesta que el cálculo analítico!</p>
<p>Nota: En la celda de arriba calculamos una diferencia (en lugar de una división) porque estamos en la escala logarítmica, por la misma razón tomamos la exponencial antes de devolver el resultado. Finalmente, la razón por la que calculamos la media es porque obtenemos un valor logarítmico de probabilidad marginal por cadena.</p>
<p>La ventaja de usar SMC para calcular la verosimilitud marginal es que podemos usarlo para una gama más amplia de modelos, ya que ya no necesitamos conocer una expresión en forma cerrada. El costo que pagamos por esta flexibilidad es un cálculo más costoso. Además hay que tener en cuenta que SMC (con un kernel Metropolis independiente implementado en PyMC) no es tan eficiente como NUTS. A medida que aumenta la dimensionalidad del problema, una estimación más precisa de la posterior y la <em>verosimilitud marginal</em> requerirá un mayor número de muestras del posterior.</p>
</section>
</section>
<section id="factores-de-bayes-e-inferencia" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="factores-de-bayes-e-inferencia"><span class="header-section-number">8.9</span> Factores de bayes e inferencia</h2>
<p>Hasta ahora hemos usado los factores de Bayes para juzgar qué modelo parece ser mejor para explicar los datos, y obtenemos que uno de los modelos es <span class="math inline">\(\approx 5\)</span> veces <em>mejor</em> que el otro.</p>
<p>Pero, ¿qué pasa con el posterior que obtenemos de estos modelos? ¿Qué tan diferentes son?</p>
<div id="cell-62" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a>az.summary(idatas[<span class="dv">0</span>], var_names<span class="op">=</span><span class="st">"a"</span>, kind<span class="op">=</span><span class="st">"stats"</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">a</td>
<td>0.5</td>
<td>0.05</td>
<td>0.4</td>
<td>0.59</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-63" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a>az.summary(idatas[<span class="dv">1</span>], var_names<span class="op">=</span><span class="st">"a"</span>, kind<span class="op">=</span><span class="st">"stats"</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">sd</th>
<th data-quarto-table-cell-role="th">hdi_3%</th>
<th data-quarto-table-cell-role="th">hdi_97%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">a</td>
<td>0.5</td>
<td>0.04</td>
<td>0.42</td>
<td>0.57</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Podemos argumentar que los resultados son bastante similares, tenemos el mismo valor medio para <span class="math inline">\(\theta\)</span> y un posterior ligeramente más ancho para <code>model_0</code>, como se esperaba ya que este modelo tiene un prior más amplio. También podemos verificar la distribución predictiva posterior para ver qué tan similares son.</p>
<div id="cell-65" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a>ppc_0 <span class="op">=</span> pm.sample_posterior_predictive(idatas[<span class="dv">0</span>], model<span class="op">=</span>models[<span class="dv">0</span>]).posterior_predictive</span>
<span id="cb42-2"><a href="#cb42-2"></a>ppc_1 <span class="op">=</span> pm.sample_posterior_predictive(idatas[<span class="dv">1</span>], model<span class="op">=</span>models[<span class="dv">1</span>]).posterior_predictive</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [yl]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:00&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [yl]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:00&lt;00:00]
    </div>
    
</div>
</div>
<div id="cell-66" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a>_, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">6</span>))</span>
<span id="cb45-2"><a href="#cb45-2"></a></span>
<span id="cb45-3"><a href="#cb45-3"></a>bins <span class="op">=</span> np.linspace(<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="dv">8</span>)</span>
<span id="cb45-4"><a href="#cb45-4"></a>ax <span class="op">=</span> az.plot_dist(</span>
<span id="cb45-5"><a href="#cb45-5"></a>    ppc_0[<span class="st">"yl"</span>].mean(<span class="st">"yl_dim_2"</span>),</span>
<span id="cb45-6"><a href="#cb45-6"></a>    label<span class="op">=</span><span class="st">"model_0"</span>,</span>
<span id="cb45-7"><a href="#cb45-7"></a>    kind<span class="op">=</span><span class="st">"hist"</span>,</span>
<span id="cb45-8"><a href="#cb45-8"></a>    hist_kwargs<span class="op">=</span>{<span class="st">"alpha"</span>: <span class="fl">0.5</span>, <span class="st">"bins"</span>: bins},</span>
<span id="cb45-9"><a href="#cb45-9"></a>)</span>
<span id="cb45-10"><a href="#cb45-10"></a>ax <span class="op">=</span> az.plot_dist(</span>
<span id="cb45-11"><a href="#cb45-11"></a>    ppc_1[<span class="st">"yl"</span>].mean(<span class="st">"yl_dim_2"</span>),</span>
<span id="cb45-12"><a href="#cb45-12"></a>    label<span class="op">=</span><span class="st">"model_1"</span>,</span>
<span id="cb45-13"><a href="#cb45-13"></a>    color<span class="op">=</span><span class="st">"C1"</span>,</span>
<span id="cb45-14"><a href="#cb45-14"></a>    kind<span class="op">=</span><span class="st">"hist"</span>,</span>
<span id="cb45-15"><a href="#cb45-15"></a>    hist_kwargs<span class="op">=</span>{<span class="st">"alpha"</span>: <span class="fl">0.5</span>, <span class="st">"bins"</span>: bins},</span>
<span id="cb45-16"><a href="#cb45-16"></a>    ax<span class="op">=</span>ax,</span>
<span id="cb45-17"><a href="#cb45-17"></a>)</span>
<span id="cb45-18"><a href="#cb45-18"></a>ax.legend()</span>
<span id="cb45-19"><a href="#cb45-19"></a>ax.set_xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">theta$"</span>)</span>
<span id="cb45-20"><a href="#cb45-20"></a>ax.xaxis.set_major_formatter(FormatStrFormatter(<span class="st">"</span><span class="sc">%0.1f</span><span class="st">"</span>))</span>
<span id="cb45-21"><a href="#cb45-21"></a>ax.set_yticks([])<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>En este ejemplo, los datos observados son más consistentes con el <code>modelo_1</code>, por que el prior se concentra en torno al valor correcto de <span class="math inline">\(\theta\)</span>, mientras que el <code>modelo_0</code>, asigna la misma probabilidad a todos los valores posibles de <span class="math inline">\(\theta\)</span>. Esta diferencia entre los modelos es capturada por el factor de Bayes. Podríamos decir que los factores de Bayes miden qué modelo, en su conjunto, es mejor para explicar los datos. Y esto incluye los detalles del prior, sin importar cuan similares son las predicciones de los modelos. En muchos escenarios lo que nos interesa al comparar modelos es cuan similares son las predicciones. Que es lo que estima LOO o validación cruzada.</p>
</section>
<section id="cociente-de-savage-dickey" class="level2" data-number="8.10">
<h2 data-number="8.10" class="anchored" data-anchor-id="cociente-de-savage-dickey"><span class="header-section-number">8.10</span> Cociente de Savage-Dickey</h2>
<p>Para los ejemplos anteriores hemos comparado dos modelos beta-binomiales, podríamos haber comparado dos modelos completamente diferentes. Pero hay veces que queremos comparar una hipótesis nula H_0 (o modelo nulo) contra una alternativa H_1. Por ejemplo, para responder a la pregunta <em>¿Está sesgada esta moneda?</em>, podríamos comparar el valor <span class="math inline">\(\theta = 0.5\)</span> (que representa el no-sesgo) con el resultado de un modelo en el que permitimos que <span class="math inline">\(\theta\)</span> varíe. Para este tipo de comparación, el modelo nulo está anidado dentro de la alternativa, lo que significa que el valor nulo es un valor particular del modelo que estamos construyendo. En esos casos, calcular el factor de Bayes es muy fácil y no requiere ningún método especial. Solo necesitamos comparar el prior y el posterior evaluados en el valor nulo (por ejemplo <span class="math inline">\(\theta = 0.5\)</span> ), bajo el modelo alternativo. Podemos ver que esto es cierto a partir de la siguiente expresión:</p>
<p><span class="math display">\[
BF_{01} = \frac{p(y \mid H_0)}{p(y \mid H_1)} \frac{p(\theta=0.5 \mid y, H_1)}{p(\theta=0.5 \mid H_1)}
\]</span></p>
<p>Que es cierta <a href="https://statproofbook.github.io/P/bf-sddr">solo</a> cuando H_0 es un caso particular de H_1.</p>
<p>Hagámoslo con PyMC y ArviZ. Solo necesitamos obtener muestras del prior y del posterior para un modelo. Probemos con el modelo beta-binomial con prior uniforme.</p>
<div id="cell-69" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_uni:</span>
<span id="cb46-2"><a href="#cb46-2"></a>    a <span class="op">=</span> pm.Beta(<span class="st">"a"</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb46-3"><a href="#cb46-3"></a>    yl <span class="op">=</span> pm.Bernoulli(<span class="st">"yl"</span>, a, observed<span class="op">=</span>y)</span>
<span id="cb46-4"><a href="#cb46-4"></a>    idata_uni <span class="op">=</span> pm.sample(<span class="dv">2000</span>, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb46-5"><a href="#cb46-5"></a>    idata_uni.extend(pm.sample_prior_predictive(<span class="dv">8000</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [a]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="12000" class="" max="12000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [12000/12000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 2 seconds.
Sampling: [a, yl]</code></pre>
</div>
</div>
<p>Y ahora llamamos a la función de ArviZ <code>az.plot_bf</code></p>
<div id="cell-71" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1"></a>az.plot_bf(idata_uni, var_name<span class="op">=</span><span class="st">"a"</span>, ref_val<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-31-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>El gráfico muestra un KDE para el prior (azul) y otro para el posterior (turquesa). Los dos puntos negros muestran que evaluamos ambas distribuciones en el valor 0.5. Podemos ver que el factor de Bayes a favor de la hipótesis nula, BF_01, es <span class="math inline">\(\approx 8\)</span>, lo que podemos interpretar como una <em>evidencia moderada</em> a favor de la hipótesis nula (ver la escala de Jeffreys que discutimos antes).</p>
<p>Como ya comentamos, los factores de Bayes miden qué modelo, en su conjunto, es mejor para explicar los datos. Y esto incluye el prior, incluso si el prior tiene un impacto relativamente bajo en el cómputo del posterior. También podemos ver este efecto del prior al comparar un segundo modelo con el modelo nulo.</p>
<p>Si en cambio nuestro modelo fuera un beta-binomial con beta prior (30, 30), el BF_01 sería más bajo (<em>anecdótico</em> en la escala de Jeffrey). Esto se debe a que, según este modelo, el valor de <span class="math inline">\(\theta=0.5\)</span> es mucho más probable priori que para un prior uniforme y, por lo tanto, el posterior y el prior serán mucho más similares. Es decir, no hay demasiada <em>sorpresa</em> al ver la que el posterior se concentra alrededor de 0.5 después de recopilar datos.</p>
<p>Vamos a calcularlo para verlo por nosotros mismos.</p>
<div id="cell-73" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_conc:</span>
<span id="cb50-2"><a href="#cb50-2"></a>    a <span class="op">=</span> pm.Beta(<span class="st">"a"</span>, <span class="dv">30</span>, <span class="dv">30</span>)</span>
<span id="cb50-3"><a href="#cb50-3"></a>    yl <span class="op">=</span> pm.Bernoulli(<span class="st">"yl"</span>, a, observed<span class="op">=</span>y)</span>
<span id="cb50-4"><a href="#cb50-4"></a>    idata_conc <span class="op">=</span> pm.sample(<span class="dv">2000</span>, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb50-5"><a href="#cb50-5"></a>    idata_conc.extend(pm.sample_prior_predictive(<span class="dv">8000</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [a]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="12000" class="" max="12000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [12000/12000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 2 seconds.
Sampling: [a, yl]</code></pre>
</div>
</div>
<div id="cell-74" class="cell" data-scrolled="true" data-execution_count="32">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1"></a>az.plot_bf(idata_conc, var_name<span class="op">=</span><span class="st">"a"</span>, ref_val<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-33-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./06_Regresión_lineal_con_Bambi.html" class="pagination-link" aria-label="Regresión lineal con Bambi">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Regresión lineal con Bambi</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Licencia Creative Commons" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png"></a><br>Este obra está bajo <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">licencia Creative Commons Reconocimiento 4.0 Internacional</a>.</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>