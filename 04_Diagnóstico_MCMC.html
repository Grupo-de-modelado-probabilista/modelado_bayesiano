<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Modelado Bayesiano - 5&nbsp; Diagn√≥stico del muestreo</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./05_Regresi√≥n_lineal.html" rel="next">
<link href="./03_Modelos_jer√°rquicos.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la b√∫squeda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-CYV0K39WW5"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-CYV0K39WW5', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="citation_title" content="[5]{.chapter-number}&nbsp; [Diagn√≥stico del muestreo]{.chapter-title}">
<meta name="citation_publication_date" content="2023-04-21">
<meta name="citation_cover_date" content="2023-04-21">
<meta name="citation_year" content="2023">
<meta name="citation_fulltext_html_url" content="https://gmp.net.ar/modelado_bayesiano/">
<meta name="citation_doi" content="https://doi.org/10.5281/zenodo.7851296">
<meta name="citation_language" content="es">
<meta name="citation_book_title" content="Modelado Bayesiano">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04_Diagn√≥stico_MCMC.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Diagn√≥stico del muestreo</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modelado Bayesiano</a> 
        <div class="sidebar-tools-main tools-wide">
    <div class="dropdown">
      <a href="" title="github" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="github"><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/Grupo-de-modelado-probabilista/Modelado_Bayesiano">
            Fuente
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/Grupo-de-modelado-probabilista/Modelado_Bayesiano/issues/new">
            Reportar errores
            </a>
          </li>
      </ul>
    </div>
    <a href="https://twitter.com/aloctavodia" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://bayes.club/@aloctavodia" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-mastodon"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Modo claro/oscuro"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Modo sin distracciones">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">‚Äé</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_Probabilidad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probabilidad</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Inferencia_Bayesiana.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inferencia Bayesiana</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Programaci√≥n_probabil√≠stica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Programaci√≥n probabilista</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Modelos_jer√°rquicos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Modelado Jer√°rquico</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Diagn√≥stico_MCMC.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Diagn√≥stico del muestreo</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Regresi√≥n_lineal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Regresi√≥n lineal</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_Regresi√≥n_lineal_con_Bambi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Regresi√≥n lineal con Bambi</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_Comparaci√≥n_de_modelos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Comparaci√≥n de modelos</span></span></a>
  </div>
</li>
    </ul>
    </div>
<div class="quarto-sidebar-footer"><div class="sidebar-footer-item">
<center>
<br>¬°Apoya la creaci√≥n de contenido con una donaci√≥n! (solo pagos Argentina)<a href="https://cafecito.app/aloctavodia" rel="noopener" target="_blank"><img srcset="https://cdn.cafecito.app/imgs/buttons/button_6.png 1x, https://cdn.cafecito.app/imgs/buttons/button_6_2x.png 2x, https://cdn.cafecito.app/imgs/buttons/button_6_3.75x.png 3.75x" src="https://cdn.cafecito.app/imgs/buttons/button_6.png" alt="Invitame un caf√© en cafecito.app"></a><br><br>Support content creation with a donation! (Pay from everywhere)<a href="https://ko-fi.com/B0B5SN6SD" target="_blank"><img height="36" style="border:0px;height:36px;" src="https://storage.ko-fi.com/cdn/kofi1.png?v=3" border="0" alt="Buy Me a Coffee at ko-fi.com"></a>
</center>
</div></div></nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#revisitando-el-teorema-de-bayes" id="toc-revisitando-el-teorema-de-bayes" class="nav-link active" data-scroll-target="#revisitando-el-teorema-de-bayes"><span class="header-section-number">5.1</span> Revisitando el teorema de Bayes</a></li>
  <li><a href="#calculando-la-distribuci√≥n-a-posteriori" id="toc-calculando-la-distribuci√≥n-a-posteriori" class="nav-link" data-scroll-target="#calculando-la-distribuci√≥n-a-posteriori"><span class="header-section-number">5.2</span> Calculando la distribuci√≥n a posteriori</a>
  <ul class="collapse">
  <li><a href="#m√©todo-de-la-grilla" id="toc-m√©todo-de-la-grilla" class="nav-link" data-scroll-target="#m√©todo-de-la-grilla"><span class="header-section-number">5.2.1</span> M√©todo de la grilla</a></li>
  <li><a href="#markov-chain-monte-carlo-mcmc" id="toc-markov-chain-monte-carlo-mcmc" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-mcmc"><span class="header-section-number">5.2.2</span> Markov Chain Monte Carlo (MCMC)</a></li>
  <li><a href="#metropolis-hastings" id="toc-metropolis-hastings" class="nav-link" data-scroll-target="#metropolis-hastings"><span class="header-section-number">5.2.3</span> Metropolis-Hastings</a></li>
  <li><a href="#mh-adaptativo" id="toc-mh-adaptativo" class="nav-link" data-scroll-target="#mh-adaptativo"><span class="header-section-number">5.2.4</span> MH adaptativo</a></li>
  <li><a href="#montecarlo-hamiltoniano-hmc" id="toc-montecarlo-hamiltoniano-hmc" class="nav-link" data-scroll-target="#montecarlo-hamiltoniano-hmc"><span class="header-section-number">5.2.5</span> Montecarlo Hamiltoniano (HMC)</a></li>
  </ul></li>
  <li><a href="#diagn√≥sticos-generales" id="toc-diagn√≥sticos-generales" class="nav-link" data-scroll-target="#diagn√≥sticos-generales"><span class="header-section-number">5.3</span> Diagn√≥sticos generales</a>
  <ul class="collapse">
  <li><a href="#en-la-teor√≠a-confiamos" id="toc-en-la-teor√≠a-confiamos" class="nav-link" data-scroll-target="#en-la-teor√≠a-confiamos"><span class="header-section-number">5.3.1</span> En la teor√≠a confiamos</a></li>
  <li><a href="#trace-plots" id="toc-trace-plots" class="nav-link" data-scroll-target="#trace-plots"><span class="header-section-number">5.3.2</span> Trace plots</a></li>
  <li><a href="#rank-plots" id="toc-rank-plots" class="nav-link" data-scroll-target="#rank-plots"><span class="header-section-number">5.3.3</span> Rank plots</a></li>
  <li><a href="#hat-r-r-sombrero" id="toc-hat-r-r-sombrero" class="nav-link" data-scroll-target="#hat-r-r-sombrero"><span class="header-section-number">5.3.4</span> <span class="math inline">\(\hat R\)</span> (R sombrero)</a></li>
  <li><a href="#gr√°fico-de-autocorrelaci√≥n" id="toc-gr√°fico-de-autocorrelaci√≥n" class="nav-link" data-scroll-target="#gr√°fico-de-autocorrelaci√≥n"><span class="header-section-number">5.3.5</span> Gr√°fico de autocorrelaci√≥n</a></li>
  <li><a href="#tama√±o-de-muestra-efectivo-ess" id="toc-tama√±o-de-muestra-efectivo-ess" class="nav-link" data-scroll-target="#tama√±o-de-muestra-efectivo-ess"><span class="header-section-number">5.3.6</span> Tama√±o de muestra efectivo (ESS)</a></li>
  <li><a href="#error-est√°ndard-del-monte-carlo-mcse" id="toc-error-est√°ndard-del-monte-carlo-mcse" class="nav-link" data-scroll-target="#error-est√°ndard-del-monte-carlo-mcse"><span class="header-section-number">5.3.7</span> Error est√°ndard del Monte Carlo (MCSE)</a></li>
  </ul></li>
  <li><a href="#diagn√≥stico-de-algoritmos-basados-en-gradiente" id="toc-diagn√≥stico-de-algoritmos-basados-en-gradiente" class="nav-link" data-scroll-target="#diagn√≥stico-de-algoritmos-basados-en-gradiente"><span class="header-section-number">5.4</span> Diagn√≥stico de algoritmos basados en gradiente</a>
  <ul class="collapse">
  <li><a href="#energ√≠a-de-transici√≥n-vs-energ√≠a-marginal" id="toc-energ√≠a-de-transici√≥n-vs-energ√≠a-marginal" class="nav-link" data-scroll-target="#energ√≠a-de-transici√≥n-vs-energ√≠a-marginal"><span class="header-section-number">5.4.1</span> Energ√≠a de transici√≥n vs energ√≠a marginal</a></li>
  <li><a href="#divergencias" id="toc-divergencias" class="nav-link" data-scroll-target="#divergencias"><span class="header-section-number">5.4.2</span> Divergencias</a></li>
  </ul></li>
  <li><a href="#qu√©-hacer-cuando-los-diagn√≥sticos-no-dan-bien" id="toc-qu√©-hacer-cuando-los-diagn√≥sticos-no-dan-bien" class="nav-link" data-scroll-target="#qu√©-hacer-cuando-los-diagn√≥sticos-no-dan-bien"><span class="header-section-number">5.5</span> Qu√© hacer cuando los diagn√≥sticos no dan bien?</a></li>
  <li><a href="#ejercicios" id="toc-ejercicios" class="nav-link" data-scroll-target="#ejercicios"><span class="header-section-number">5.6</span> Ejercicios</a></li>
  <li><a href="#para-seguir-leyendo" id="toc-para-seguir-leyendo" class="nav-link" data-scroll-target="#para-seguir-leyendo"><span class="header-section-number">5.7</span> Para seguir leyendo</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Diagn√≥stico del muestreo</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell" data-execution_count="1">
<details>
<summary>C√≥digo</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> preliz <span class="im">as</span> pz</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="im">from</span> ipywidgets <span class="im">import</span> interact</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="im">import</span> ipywidgets <span class="im">as</span> ipyw</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="im">from</span> IPython.display <span class="im">import</span> IFrame</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>C√≥digo</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>az.style.use(<span class="st">'arviz-doc'</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Los objetivos de este cap√≠tulo son:</p>
<ul>
<li><p>Obtener nociones b√°sicas de m√©todos de Markov Chain Monte Carlo y su rol en estad√≠stica Bayesiana</p></li>
<li><p>Discutir algunos de los m√©todos de diagn√≥stico del muestreo m√°s usados</p></li>
</ul>
<section id="revisitando-el-teorema-de-bayes" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="revisitando-el-teorema-de-bayes"><span class="header-section-number">5.1</span> Revisitando el teorema de Bayes</h2>
<p>El teorema de Bayes, tiene una formulaci√≥n que a primera vista parece muy inocente. Tan solo cuatro t√©rminos relacionados por una multiplicaci√≥n y una divisi√≥n.</p>
<p><span class="math display">\[
\underbrace{p(\boldsymbol{\theta} \mid \boldsymbol{Y})}_{\text{posterior}} = \frac{\overbrace{p(\boldsymbol{Y} \mid \boldsymbol{\theta})}^{\text{likelihood}}\; \overbrace{p(\boldsymbol{\theta})}^{\text{prior}}}{\underbrace{{p(\boldsymbol{Y})}}_{\text{marginal likelihood}}}
\]</span></p>
<p>Pareciera que no sirve de mucho y que es f√°cil de calcular. Sin embargo, ambas apreciaciones son incorrectas. El resto de los cap√≠tulos se centran en mostrar contra ejemplos a la primera aseveraci√≥n, as√≠ que veamos por que a veces su c√°lculo puede ser dif√≠cil y se requieren m√©todos num√©ricos.</p>
<p>La raz√≥n est√° en el c√°lculo del likelihood marginal. El cual toma la forma de una integral.</p>
<p><span class="math display">\[
{p(\boldsymbol{Y}) = \int_{\boldsymbol{\Theta}} p(\boldsymbol{Y} \mid \boldsymbol{\theta})p(\boldsymbol{\theta}) d\boldsymbol{\theta}}
\]</span></p>
<p>Esta integral suele ser dif√≠cil de resolver. Veamos, esta expresi√≥n nos dice que debemos evaluar el likelihood para cada uno de los posibles valores del prior <span class="math inline">\(\theta\)</span>. En la pr√°ctica esa tarea no siempre es sencilla o barata de realizar. Si <span class="math inline">\(\theta\)</span> representa un solo par√°metro desconocido (como en el modelo beta-binomial) entonces solo hay que resolver una integral, pero si <span class="math inline">\(\theta\)</span> representa dos par√°metros (como en el modelo Gaussiano) entonces la integral ser√° doble. En definitiva la integral tendr√° tantas dimensiones como par√°metros el modelo. En general las integrales en grandes dimensiones no son simples de resolver.</p>
<p>Algo que puede ser poco intuitivo es que esto se contrapone con el c√°lculo de la distribuci√≥n a posteriori. Para obtener una buena aproximaci√≥n a la distribuci√≥n a posteriori bastar√≠a con concentrarse en las regiones donde tanto la contribuci√≥n del prior como del likelihood son <em>relativamente grandes</em> (√°rea gris en la siguiente figura), en general esto es lo que hacen la mayor√≠a de los m√©todos num√©ricos. En cambio esta misma aproximaci√≥n puede conducir a errores en el c√°lculo del likelihood marginal</p>
<center>
<img src="img/grid.png" width="800">
</center>
<p>Para algunos problemas es posible calcular la distribuci√≥n a posteriori de forma anal√≠tica. Esto ya lo vimos para el modelo beta-binomial donde la posterior es:</p>
<p><span class="math display">\[
p(\theta \mid y) \propto \operatorname{Beta}(\alpha_{a priori} + y, \beta_{a priori} + N - y)
\]</span></p>
<p>Para esos casos suele ser posible tambi√©n calcular el marginal likelihood de forma anal√≠tica.</p>
<p>Pero en general no tenemos expresiones anal√≠ticas y entonces debemos confiar en m√©todos num√©ricos.</p>
</section>
<section id="calculando-la-distribuci√≥n-a-posteriori" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="calculando-la-distribuci√≥n-a-posteriori"><span class="header-section-number">5.2</span> Calculando la distribuci√≥n a posteriori</h2>
<p>Hay muchas formas de calcular la distribuci√≥n a posteriori</p>
<ul>
<li><font color="gray"> Conjugaci√≥n </font></li>
<li><font color="gray"> M√©todo de Laplace </font></li>
<li><font color="gray"> Aproximaci√≥n de Laplace Anidada Integrada (INLA) </font></li>
<li><font color="gray"> Inferencia Variacional (VI) </font></li>
<li>Markov Chain Monte Carlo (MCMC)</li>
<li><font color="gray"> Sequential Monte Carlo </font></li>
<li>‚Ä¶</li>
</ul>
<p>Por ahora solo hablaremos de los m√©todos MCMC ya que, por el momento, son los m√©todos m√°s generales. Pero para entender de forma m√°s simple que es lo que hacen estos m√©todos conviene empezar desde otro m√©todo, conocido como m√©todo de la grilla.</p>
<section id="m√©todo-de-la-grilla" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="m√©todo-de-la-grilla"><span class="header-section-number">5.2.1</span> M√©todo de la grilla</h3>
<p>El m√©todo de grilla es un enfoque simple de fuerza bruta. La idea central es que incluso si no somos capaces de calcular todo la distribuci√≥n a posteriori, en general si somos capaces de evaluar el a priori y el likelihood punto-a-punto.</p>
<p>Para un modelo con un solo par√°metro el m√©todo de la grilla se puede resumir de la siguiente forma:</p>
<ul>
<li><p>Encuentre un intervalo razonable para el par√°metro (el prior debe dar algunas pistas).</p></li>
<li><p>Defina una grilla de puntos (generalmente equidistantes) en ese intervalo.</p></li>
<li><p>Para cada punto de la grilla, eval√∫e el prior y el likelihood en ese punto y multiplique</p></li>
</ul>
<p>La siguiente figura ilustra este m√©todo</p>
<center>
<img src="img/grid.gif" width="800">
</center>
<p>El siguiente bloque de c√≥digo (que ya usamos antes) implementa un m√©todo de la grilla interactivo</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">def</span> a_posteriori_grilla(grilla<span class="op">=</span><span class="dv">10</span>, a<span class="op">=</span><span class="dv">1</span>, b<span class="op">=</span><span class="dv">1</span>, caras<span class="op">=</span><span class="dv">6</span>, tiradas<span class="op">=</span><span class="dv">9</span>):</span>
<span id="cb3-2"><a href="#cb3-2"></a>    grid <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, grilla)</span>
<span id="cb3-3"><a href="#cb3-3"></a>    prior <span class="op">=</span> pz.Beta(a, b).rv_frozen.pdf(grid)</span>
<span id="cb3-4"><a href="#cb3-4"></a>    likelihood <span class="op">=</span> pz.Binomial(n<span class="op">=</span>tiradas, p<span class="op">=</span>grid).rv_frozen.pmf(caras)</span>
<span id="cb3-5"><a href="#cb3-5"></a>    posterior <span class="op">=</span> likelihood <span class="op">*</span> prior</span>
<span id="cb3-6"><a href="#cb3-6"></a>    posterior <span class="op">/=</span> posterior.<span class="bu">sum</span>()</span>
<span id="cb3-7"><a href="#cb3-7"></a>    _, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, sharex<span class="op">=</span><span class="va">True</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">3</span>))</span>
<span id="cb3-8"><a href="#cb3-8"></a>    ax[<span class="dv">0</span>].set_title(<span class="st">'caras = </span><span class="sc">{}</span><span class="ch">\n</span><span class="st">tiradas = </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(caras, tiradas))</span>
<span id="cb3-9"><a href="#cb3-9"></a>    <span class="cf">for</span> i, (e, e_n) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>([prior, likelihood, posterior], [<span class="st">'a priori'</span>, <span class="st">'likelihood'</span>, <span class="st">'a posteriori'</span>])):</span>
<span id="cb3-10"><a href="#cb3-10"></a>        ax[i].set_yticks([])</span>
<span id="cb3-11"><a href="#cb3-11"></a>        ax[i].plot(grid, e, <span class="st">'o-'</span>, label<span class="op">=</span>e_n)</span>
<span id="cb3-12"><a href="#cb3-12"></a>        ax[i].legend()</span>
<span id="cb3-13"><a href="#cb3-13"></a></span>
<span id="cb3-14"><a href="#cb3-14"></a></span>
<span id="cb3-15"><a href="#cb3-15"></a>interact(a_posteriori_grilla, grilla<span class="op">=</span>ipyw.IntSlider(<span class="bu">min</span><span class="op">=</span><span class="dv">2</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">100</span>, step<span class="op">=</span><span class="dv">1</span>, value<span class="op">=</span><span class="dv">15</span>), a<span class="op">=</span>ipyw.FloatSlider(<span class="bu">min</span><span class="op">=</span><span class="dv">1</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">7</span>, step<span class="op">=</span><span class="dv">1</span>, value<span class="op">=</span><span class="dv">1</span>), b<span class="op">=</span>ipyw.FloatSlider(</span>
<span id="cb3-16"><a href="#cb3-16"></a>    <span class="bu">min</span><span class="op">=</span><span class="dv">1</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">7</span>, step<span class="op">=</span><span class="dv">1</span>, value<span class="op">=</span><span class="dv">1</span>), caras<span class="op">=</span>ipyw.IntSlider(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">20</span>, step<span class="op">=</span><span class="dv">1</span>, value<span class="op">=</span><span class="dv">6</span>), tiradas<span class="op">=</span>ipyw.IntSlider(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">20</span>, step<span class="op">=</span><span class="dv">1</span>, value<span class="op">=</span><span class="dv">9</span>))<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_Diagn√≥stico_MCMC_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f5512610ed19496a81d42b7d84cfe73b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<p>Utilizando la funci√≥n <code>a_posteriori_grilla</code> podemos comprobar que para obtener una mejor aproximaci√≥n se puede aumentar el n√∫mero de puntos de la cuadr√≠cula. Esta estrategia puede ser √∫til en unas pocas dimensiones (par√°metros). Pero no escala. En la siguiente figura vemos que si necesitamos 4 puntos en 1D, para mantener ese mismo grado de precisi√≥n necesitaremos 16 puntos en 2D y 64 en 3D. La velocidad con la que crecen la cantidad de evaluaciones necesarias crece demasiado r√°pido, una grilla de 100 en 10 dimensiones requerir√≠a de 1e+20 puntos!</p>
<center>
<img src="img/grid_dimensions.png" width="800">
</center>
<p>Como si eso no fuera poco, la cosa es m√°s complicada. En espacios de alta dimensi√≥n se dan una serie de fen√≥memos conocidos como <strong>concentraci√≥n de la medida</strong> o en versi√≥n marketinera la <strong>maldici√≥n de la dimensionalidad</strong> üëª. Por ejemplo:</p>
<ul>
<li><p>En una hiper-esfera casi todo el volumen est√° en la superficie. Es decir, si uno pelara una hiper-naranja se quedar√≠a con hambre!</p></li>
<li><p>En un hiper-cubo la masa se concentra en las esquinas</p></li>
<li><p>En una Gaussiana hiper-dimensional casi toda la masa est√° lejos de la moda</p></li>
</ul>
<p>La idea de estimar la distribuci√≥n a posteriori evaluando, punto a punto, likelihood y prior es muy buena, pero la idea de construir una grilla predefinida solo funciona en muy bajas dimensiones.</p>
<p>Pero no todo est√° perdido, que tal si mantenemos la idea de la evaluaci√≥n puntual, pero nos concentramos en las <em>regiones que importan</em>?</p>
</section>
<section id="markov-chain-monte-carlo-mcmc" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="markov-chain-monte-carlo-mcmc"><span class="header-section-number">5.2.2</span> Markov Chain Monte Carlo (MCMC)</h3>
<p>Esta es una familia muy extensa de m√©todos utilizados para resolver muchos problemas, entre los que se encuentra el c√°lculo de la distribuci√≥n a posteriori. Conceptualmente se puede pensar a estos m√©todos como generalizaciones del m√©todo de la grilla, ya que tambi√©n se basan en la posibilidad de realizar evaluaciones punto a punto del prior y likelihood. La diferencia crucial es que en vez de utilizar una grilla predefinida el m√©todo realiza evaluaciones que progresivamente se concentran en regiones de alta probabilidad. No solo eso si no que eventualmente el m√©todo devolver√° muestras de forma proporcional a la probabilidad a posteriori. Es decir si una regi√≥n es 3 veces m√°s probable que otra obtendremos 3 veces m√°s muestras de esa regi√≥n que de la otra.</p>
<p>A muy grandes rasgos, y dado un punto inicial arbitrario, los m√©todos MCMC, constan de dos pasos.</p>
<ol type="1">
<li>Generar un nuevo punto a partir de perturbar uno preexistente.</li>
<li>Aceptar o rechazar ese nuevo punto de forma probabilista y comparando la probabilidad del punto preexistente y del nuevo punto.</li>
</ol>
<p>Esta es esencialmente la receta, la forma exacta en que hacemos cada uno de estos pasos define los distintos m√©todos dentro de la familia MCMC. Veamos uno de los m√°s sencillos de entender y de implementar.</p>
</section>
<section id="metropolis-hastings" class="level3" data-number="5.2.3">
<h3 data-number="5.2.3" class="anchored" data-anchor-id="metropolis-hastings"><span class="header-section-number">5.2.3</span> Metropolis-Hastings</h3>
<p>Metropolis-Hastings no es un algoritmo muy moderno o particularmente eficiente, pero Metropolis-Hastings es simple de entender y tambi√©n proporciona una base para comprender m√©todos m√°s sofisticados y poderosos.</p>
<p>El algoritmo Metropolis-Hasting se define de la siguiente manera:</p>
<ol type="1">
<li>Inicialice el valor del par√°metro <span class="math inline">\(\boldsymbol{X}\)</span> en <span class="math inline">\(x_i\)</span></li>
<li>Utilice una distribuci√≥n de propuesta <span class="math inline">\(q(x_{i + 1} \mid x_i)\)</span> para generar un nuevo valor <span class="math inline">\(x_{i + 1}\)</span></li>
<li>Calcule la probabilidad de aceptar el nuevo valor como:</li>
</ol>
<p><span class="math display">\[
p_a (x_{i + 1} \mid x_i) = \min \left(1, \frac{p(x_{i + 1}) \; q(x_i \mid x_{i + 1})} {p(x_i) \; q (x_{i + 1} \mid x_i)} \right)
\]</span></p>
<ol start="4" type="1">
<li>Si <span class="math inline">\(p_a &gt; R\)</span> donde <span class="math inline">\(R \sim \mathcal{U}(0, 1)\)</span>, guarde el nuevo valor; de lo contrario, guarde el anterior.</li>
<li>Iterar de 2 a 4 hasta que se haya generado una muestra <em>suficientemente grande</em></li>
</ol>
<p>El algoritmo Metropolis es muy general y se puede usar en aplicaciones no Bayesianas, pero para la presente discusi√≥n, <span class="math inline">\(p(x_i)\)</span> es la densidad del posterior evaluada en el valor del par√°metro <span class="math inline">\(x_i\)</span>. Una forma de simplificar un poco el m√©todo es notar que si <span class="math inline">\(q\)</span> es una distribuci√≥n sim√©trica, los t√©rminos <span class="math inline">\(q(x_i \mid x_{i + 1})\)</span> y <span class="math inline">\(q(x_{i + 1} \mid x_i)\)</span> se cancelar√°n (conceptualmente significa que es igualmente probable que vayamos de <span class="math inline">\(x_{i+1}\)</span> a <span class="math inline">\(x_i\)</span> o de <span class="math inline">\(x_{i}\)</span> a <span class="math inline">\(x_{i+1}\)</span>), dejando solo un cociente entre el posterior evaluado en dos puntos. Este algoritmo siempre aceptar√° moverse de una regi√≥n de baja probabilidad a una m√°s alta y aceptar√° probabil√≠sticamente moverse de una regi√≥n de alta a una baja probabilidad.</p>
<p>¬°Otra observaci√≥n importante es que el algoritmo Metropolis-Hastings no es un m√©todo de optimizaci√≥n! No nos importa encontrar el valor del par√°metro con la m√°xima probabilidad, queremos <em>explorar</em> la distribuci√≥n <span class="math inline">\(p\)</span>. Es decir a√∫n si el m√©todo encuentra un m√°ximo a√∫n puede moverse a regiones de probabilidades m√°s bajas.</p>
<p>Para hacer las cosas m√°s concretas, intentemos resolver el modelo Beta-Binomial.</p>
<span class="math display">\[\begin{aligned}
    \theta \sim &amp;\; \text{Beta}(\alpha, \beta) \\
    Y \sim &amp;\; \text{Bin}(n=1, p=\theta)
\end{aligned}\]</span>
<p>Este modelo tiene una soluci√≥n anal√≠tica. Pero supongamos que no sabemos c√≥mo calcular el posterior y, por lo tanto, implementaremos el algoritmo Metropolis-Hastings usando Python.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">def</span> post(Œ∏, Y, Œ±<span class="op">=</span><span class="dv">1</span>, Œ≤<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb4-2"><a href="#cb4-2"></a>    <span class="cf">if</span> <span class="dv">0</span> <span class="op">&lt;=</span> Œ∏ <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb4-3"><a href="#cb4-3"></a>        prior <span class="op">=</span> stats.beta(Œ±, Œ≤).pdf(Œ∏)</span>
<span id="cb4-4"><a href="#cb4-4"></a>        like  <span class="op">=</span> stats.bernoulli(Œ∏).pmf(Y).prod()</span>
<span id="cb4-5"><a href="#cb4-5"></a>        prob <span class="op">=</span> like <span class="op">*</span> prior</span>
<span id="cb4-6"><a href="#cb4-6"></a>    <span class="cf">else</span>:</span>
<span id="cb4-7"><a href="#cb4-7"></a>        prob <span class="op">=</span> <span class="op">-</span>np.inf</span>
<span id="cb4-8"><a href="#cb4-8"></a>    <span class="cf">return</span> prob</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Tambi√©n necesitamos datos, por lo que generaremos algunos datos falsos aleatorios para este prop√≥sito.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>Y <span class="op">=</span> stats.bernoulli(<span class="fl">0.7</span>).rvs(<span class="dv">20</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Y finalmente ejecutamos nuestra implementaci√≥n del algoritmo Metropolis-Hastings:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>n_iters <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>can_sd <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb6-3"><a href="#cb6-3"></a>Œ± <span class="op">=</span> Œ≤ <span class="op">=</span>  <span class="dv">1</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>Œ∏ <span class="op">=</span> <span class="fl">0.5</span> </span>
<span id="cb6-5"><a href="#cb6-5"></a>trace <span class="op">=</span> {<span class="st">"Œ∏"</span>:np.zeros(n_iters)}</span>
<span id="cb6-6"><a href="#cb6-6"></a>p2 <span class="op">=</span> post(Œ∏, Y, Œ±, Œ≤)</span>
<span id="cb6-7"><a href="#cb6-7"></a></span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(n_iters):</span>
<span id="cb6-9"><a href="#cb6-9"></a>    Œ∏_can <span class="op">=</span> stats.norm(Œ∏, can_sd).rvs(<span class="dv">1</span>)</span>
<span id="cb6-10"><a href="#cb6-10"></a>    p1 <span class="op">=</span> post(Œ∏_can, Y, Œ±, Œ≤)  </span>
<span id="cb6-11"><a href="#cb6-11"></a>    pa <span class="op">=</span> p1 <span class="op">/</span> p2</span>
<span id="cb6-12"><a href="#cb6-12"></a></span>
<span id="cb6-13"><a href="#cb6-13"></a>    <span class="cf">if</span> pa <span class="op">&gt;</span> stats.uniform(<span class="dv">0</span>, <span class="dv">1</span>).rvs(<span class="dv">1</span>):</span>
<span id="cb6-14"><a href="#cb6-14"></a>        Œ∏ <span class="op">=</span> Œ∏_can</span>
<span id="cb6-15"><a href="#cb6-15"></a>        p2 <span class="op">=</span> p1</span>
<span id="cb6-16"><a href="#cb6-16"></a></span>
<span id="cb6-17"><a href="#cb6-17"></a>    trace[<span class="st">"Œ∏"</span>][<span class="bu">iter</span>] <span class="op">=</span> Œ∏</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>En la l√≠nea 9 del bloque de c√≥digo anterior generamos una propuesta muestreando una distribuci√≥n Normal con desviaci√≥n est√°ndar <code>can_sd</code>. En la l√≠nea 10 evaluamos el posterior en el nuevo valor generado <code>Œ∏_can</code> y en la l√≠nea 11 calculamos la probabilidad de aceptaci√≥n. En la l√≠nea 17 guardamos un valor de <code>Œ∏</code> en el array <code>trace</code>. Dependiendo del resultado de la comparaci√≥n en la l√≠nea 13, el valor guardado ser√° nuevo o repetiremos el anterior.</p>
<p>El primer panel de la siguiente figura muestra cada valor muestreado en cada paso, y el panel de la derecha el histograma de esos valores. El resultado parece razonable. Nada mal para unas pocas lineas de c√≥digo!</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-2"><a href="#cb7-2"></a>axes[<span class="dv">0</span>].plot(trace[<span class="st">'Œ∏'</span>])</span>
<span id="cb7-3"><a href="#cb7-3"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Œ∏'</span>, rotation<span class="op">=</span><span class="dv">0</span>, labelpad<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb7-4"><a href="#cb7-4"></a>axes[<span class="dv">1</span>].hist(trace[<span class="st">'Œ∏'</span>], orientation<span class="op">=</span><span class="st">"horizontal"</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-5"><a href="#cb7-5"></a>axes[<span class="dv">1</span>].set_xticks([])<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_Diagn√≥stico_MCMC_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><a href="https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&amp;target=banana">Ac√°</a> pueden ver una versi√≥n interactiva de un Metropolis-Hastings</p>
</section>
<section id="mh-adaptativo" class="level3" data-number="5.2.4">
<h3 data-number="5.2.4" class="anchored" data-anchor-id="mh-adaptativo"><span class="header-section-number">5.2.4</span> MH adaptativo</h3>
<p>En teor√≠a, y si tomaramos infinitas muestras, cualquier distribuci√≥n de propuesta ser√≠a √∫til. Sin embargo, en la pr√°ctica la eficiencia cambia dr√°sticamente de acuerdoa la distribuci√≥n de propuesta que utilicemos. Es por ello que para obtener un MH realmente eficiente es necesario ajustar hiperpar√°metros como la distribuci√≥n de propuesta para cada problema. Esto se puede hacer dedicando una cierta cantidad de pasos (tuning), estos pasos luego se descartan</p>
<ul>
<li>A√∫n el RWMH adaptativo puede tener problemas para ciertas problemas
<ul>
<li>Par√°metros muy correlacionados</li>
<li>Alta dimensi√≥n (muchos par√°metros)</li>
<li>Geometr√≠as complejas</li>
</ul></li>
</ul>
<p>Existen otras formas de generar a√∫n mejores propuestas</p>
</section>
<section id="montecarlo-hamiltoniano-hmc" class="level3" data-number="5.2.5">
<h3 data-number="5.2.5" class="anchored" data-anchor-id="montecarlo-hamiltoniano-hmc"><span class="header-section-number">5.2.5</span> Montecarlo Hamiltoniano (HMC)</h3>
<p>En vez de proponer nuevos puntos al azar podemos usar una analog√≠a f√≠sica. Simulamos una particula sin fricci√≥n que se mueve por la distribuci√≥n a posteriori. Esto se puede hacer si conocemos el Hamiltoniano del sistema. En t√©rminos simples, un hamiltoniano es una descripci√≥n de la energ√≠a total de un sistema f√≠sico.</p>
<p><span class="math display">\[
\underbrace{H(\overbrace{\mathbf{q}}^{\text{posici√≥n}}, \overbrace{\mathbf{p}}^{\text{momemtum}})}_{\text{Hamiltoniano}}  = \underbrace{K(\mathbf{p}, \mathbf{q})}_{\text{Energ√≠a cin√©tica}} + \underbrace{V(\mathbf{q})}_{\text{Energ√≠a potencial}}
\]</span></p>
<p>La posici√≥n <span class="math inline">\(q\)</span> se corresponde con los valores que puedan tomar los par√°metros del modelo probabilista y la energ√≠a potencial es la probabilidad a posteriori de esos valores. El momentum, en cambio, lo sacamos de la galera. Es simplemente una variable auxiliar que nos permite calcular el hamiltoniano y ‚Äúmover‚Äù el sistema.</p>
<p>Entonces, a grandes rasgos un HMC tiene dos pasos que se repiten hasta obtener la cantidad de muestras necesarias:</p>
<ol type="1">
<li>Generar un nuevo punto a partir del hamiltoniano</li>
<li>Aceptar o rechazar ese nuevo punto de forma probabilista y comparando la probabilidad del punto preexistente y del nuevo punto.</li>
</ol>
<p>Por qu√© es buena idea usar el hamiltoniano? En un MH la propuesta es aleatoria, es como querer encontrar algo en una habitaci√≥n desconocida a oscuras, hay que ir a tientas. Mientras que con el Hamiltoniano es como tener una linterna, ahora podemos ver que hay en la habitaci√≥n, al menos localmente a donde apuntemos con la linterna. Veamos, una explicaci√≥n un poco m√°s matem√°tica. Resolver el hamiltoniano implica calcular derivadas, las derivadas nos dan informaci√≥n sobre la curvatura de una funci√≥n, por ejemplo el c√°lculo de la primer derivada en un punto nos dice hacia donde (de)crece una funci√≥n. Si siquieramos la derivada buscando, hacia donde crece la funci√≥n, eventualmente llegariamos a un m√°ximo (asumiendo que este existe). Esto se llama maximizar una funci√≥n. Al agregar el <em>momemtum</em> podemos hacer algo m√°s interesante, podemos simular un trayectoria que explore la distribuci√≥n a posteriori. Esto es importante en estad√≠stica Bayesiana, ya que no solo queremos el m√°ximo, si no una descripci√≥n de toda la distribuci√≥n a posteriori.</p>
<center>
<img src="diapo/img/hmc_landscape.gif" width="700">
</center>
<p>Un HMC tiene varios hipepar√°metros, por ejemplo para simular una trayectoria tenemos que hacerlo de a pasos discretos, mientras m√°s peque√±os los pasos m√°s fidedigna la simulaci√≥n, pero tambi√©n m√°s costosa. Otro hiperpar√°metro es la longitud de cada simulaci√≥n si esta es muy corta demoraremos mucho tiempo en explorar la distribuci√≥n a posteriori, pero si est√° es muy larga corremos el riesgo de volver al mismo lugar.</p>
<p>En la siguiente figura se muestran tres ejemplos. A la izquierda el paso es muy corto, por lo que la exploraci√≥n no es eficiente, en el centro el paso es correcto pero la simulaci√≥n demasiado larga, tanto que volvemos al punto de partida, a la derecha tanto el paso como el tiempo de simulaci√≥n son adecuamos y la propuesta genera un punto alejado en el espacio de los par√°metros, pero con alta probabilidad de aceptaci√≥n. De hecho en este ejemplo la probabilidad de aceptaci√≥n es 1, ya que la pdf es la misma para el punto de partida que para el punto final.</p>
<center>
<img src="img/hmc_1D.gif" width="900">
</center>
<p>Este es otro ejemplo, en cada caso se muestra una densidad de probabilidad que va de m√°s probable (amarillo) a menos probable (violeta), las flechas naranjas indican la trayectoria calculada de a pasos. En en el primero caso vemos una trayectoria el√≠ptica tan larga que vuelve al punto de partida. En el segundo ejemplo vemos que el paso no es adecuado, esto produce una simulaci√≥n inestable que se manifiesta en <strong>divergencias</strong> de la trayectoria correcta. En este √∫ltimo caso, y como en el ejemplo anterior, vemos que tanto el paso como el tiempo de simulaci√≥n son adecuamos y la propuesta genera un punto alejado en el espacio de los par√°metros, pero con alta probabilidad de aceptaci√≥n (1 en este caso).</p>
<center>
<img src="diapo/img/HMC_trayectoria.png" width="900">
</center>
<p>Cuando los hiper-par√°metros de un HMC son adecuados, el muestreo es muy eficiente, mucho m√°s eficiente que un MH. Los valores de los hiper-par√°metros dependen esencialmente de la geometr√≠a de la distribuci√≥n a posteriori, por lo que no existe un solo conjunto de hiper-par√°metros mejor que los dem√°s. Es por ello que en la pr√°ctica estos se calculan de forma adaptativa corriendo una cantidad de pasos de HMC los cuales se utilizan para ajustar eso hiper-par√°metros autom√°ticamente y luego se descartan. NUTS (No U-Turn sampler), el sampler por defecto en PyMC es un HMC din√°mico y adaptativo. El nombre proviene de una rutina del m√©todo que evita que las trayectorias den vueltas en U.</p>
</section>
</section>
<section id="diagn√≥sticos-generales" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="diagn√≥sticos-generales"><span class="header-section-number">5.3</span> Diagn√≥sticos generales</h2>
<p>Asint√≥ticamente los MCMC ofrencen la respuesta correcta, el problema es que asint√≥ticamente estamos todos muertos! En la pr√°ctica se hace necesario contar con m√©todos de diagn√≥stico que permitan evaluar si el muestreo es correcto para muestras finitas. Si nos ponemos en pesimistas este es un problema sin soluci√≥n, ya que es imposible demostrar que una muestra es correcta, solo podemos probar que NO lo es. Entonces lo que buscamos es poder recolectar evidencia a favor de la ausencia de problemas. Esto nos va a conducir a establecer algunos valores umbrales, es decir si el diagnositico <span class="math inline">\(D\)</span> da un valor superior a <span class="math inline">\(m\)</span>, tenemos un problema con nuestra muestra. Esto tambi√©n es problem√°tico, ya que establecer umbrales estrictos es en general arbitrario, salvo para casos triviales. Supongamos que yo me invento un diagn√≥stico para la calvice. El m√©todo es simple, hay que contar pelos. Es claro que 0 pelos corresponde a un pelado y 150.000 no, ya que esto se estima como la cantidad de pelos promedio en una cabeza promedio (sea lo que eso sea). Pero que pasa si alguien tiene 122 o 4126 pelos? A continuaci√≥n veremos algunos valores umbrales, es importante entonces tomarlos con pinzas.</p>
<section id="en-la-teor√≠a-confiamos" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="en-la-teor√≠a-confiamos"><span class="header-section-number">5.3.1</span> En la teor√≠a confiamos</h3>
<p>La teor√≠a describe cierto comportamiento de los MCMC, muchos diagn√≥sticos est√°n basados en evaluar si los resultados te√≥ricos se verifican emp√≠ricamente. Por ejemplo, la teor√≠a de MCMC dice que:</p>
<ul>
<li>El valor inicial es irrelevante, siempre debemos llegar al mismo resultado</li>
<li>Las muestras no son realmente independientes, pero el valor de un punto solo depende del punto anterior, no hay correlaciones de largo alcance.</li>
<li>Si miramos la muestra como una secuencia no deber√≠amos ser capaces de encontrar patr√≥n alguno
<ul>
<li>Por ej, para una muestra lo suficientemente larga, la primera porci√≥n debe ser indistinguible de la √∫ltima (y la mismo cualquier otra combinaci√≥n de regiones).</li>
</ul></li>
<li>Para un mismo problema cada muestra generada va a ser diferente de las otras, pero a los fines pr√°cticos las muestras deber√≠an ser indistinguibles unas de otros</li>
</ul>
</section>
<section id="trace-plots" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="trace-plots"><span class="header-section-number">5.3.2</span> Trace plots</h3>
<p>Este es un gr√°fico muy com√∫n. Para cada par√°metro graficamos su valor (eje-y) en cada iteraci√≥n (eje-x). Lo esperable es no ver ning√∫n patr√≥n, solo ruido como en primer panel de la siguiente figura (marco turquesa).</p>
<center>
<img src="diapo/img/trace_single_good_bad.png" width="800">
</center>
<p>En cambio los otros tres paneles (marco magenta) muestran problemas. De izquierda a derecha y arriba a abajo:</p>
<ul>
<li><p>El segundo panel muestra que el muestreo es ‚Äúpegajoso‚Äù, le toma muchos pasos a la cadena moverse de valores altos a valores bajos, es dif√≠cil predecir que suceder√≠a si seguimos corriendo, la cadena se mover√≠a hacia arriba nuevamente, se estabilizar√≠a en valos bajos, continuar√≠a bajando a√∫n m√°s?</p></li>
<li><p>El tercer panel muestra una cadena menos ‚Äúpegajosa‚Äù, pero tambi√©n dar√≠a la impresi√≥n que a√∫n no ha terminado de estabilizarse</p></li>
<li><p>El √∫ltimo panel, en cambio, muestra que hay una regi√≥n donde el sampler se mueve bien, pero cada tanto ‚Äúsalta‚Äù a estados donde se queda atascado. Quiz√° esto se deba a una distribuci√≥n a posteriori multimodal o dificultades en el sampler para explorar regiones con distinta curvatura.</p></li>
</ul>
<p>Como ya vimos por defecto PyMC corre m√°s de una cadena, por lo que un traceplot ideal deber√≠a verse como esto:</p>
<center>
<img src="diapo/img/trace_multiple_good.png" width="800/">
</center>
<p>ArviZ permite graficar trace-plots usando la funci√≥n <code>az.plot_trace()</code>. Por defecto obtenemos el trace a la derecha y un KDE (para variables continuas) y un histograma (para discretas) a la izquierda</p>
<center>
<img src="diapo/img/trace_multiple_good_arviz.png" width="900">
</center>
</section>
<section id="rank-plots" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="rank-plots"><span class="header-section-number">5.3.3</span> Rank plots</h3>
<p>Los trace plots son muy comunes, pero existe una alternativa m√°s moderna llamada rank plots. La idea b√°sica es la siguiente. Para un par√°metro tomamos todas las cadenas y ordenamos los valores de menor a mayor y les asignamos un rango es decir al valor m√°s bajo le ponemos 0, al que sigue 1 y as√≠ hasta llegar a un n√∫mero que ser√° igual a la cantidad de muestras totales (cantidad de cadenas multiplicado por la cantidad de muestras por cadena). Luego reagrupamos los rankings seg√∫n las cadenas que les dieron origen y para cada cadena hacemos un histograma. Si las cadenas fuesen indistinguibles esperariamos que los histogramas sean uniformes. Ya que no hay raz√≥n para que una cadena tenga m√°s rankings bajos (o medios o altos) que el resto.</p>
<p>La siguiente figura muestra 4 ejemplos, donde solo uno (marco cyan) no muestra problemas</p>
<center>
<img src="diapo/img/rankbar_single_good_bad.png" width="800">
</center>
<p>En ArviZ los rank plots se pueden obtener con la funci√≥n <code>az.plot_rank</code> o pasando un argumento a plot_trace <code>az.plot_trace(‚ãÖ, kind="rank_bars")</code></p>
</section>
<section id="hat-r-r-sombrero" class="level3" data-number="5.3.4">
<h3 data-number="5.3.4" class="anchored" data-anchor-id="hat-r-r-sombrero"><span class="header-section-number">5.3.4</span> <span class="math inline">\(\hat R\)</span> (R sombrero)</h3>
<p>Los gr√°ficos suelen ser √∫tiles para descrubir patrones, pero aveces queremos n√∫meros, por ejemplo al evaluar r√°pidamente mucho par√°metros. <span class="math inline">\(\hat R\)</span> es la respuesta a la pregunta. Lograron las cadenas mezclarse adecuadamente? Pero tambi√©n me gusta pensarlo como el jurado en un concurso de trace (o rank) plots. La versi√≥n implementada en ArviZ hace varias cosas debajo del capot, pero la idea central es que compara la varianza <em>entre</em> cadenas con la varianza <em>dentro</em> de cada cadena.</p>
<center>
<img src="diapo/img/r_hat.gif" width="900">
</center>
<p>Idealmente <span class="math inline">\(\hat R = 1\)</span>, en la pr√°ctica <span class="math inline">\(\hat R \lessapprox 1.01\)</span> son considerados seguros y en la primer fase de modelado valores m√°s altos como <span class="math inline">\(\hat R \approx 1.1\)</span> pueden est√°r bien.</p>
<p>Usando ArviZ podemos obtener <span class="math inline">\(\hat R\)</span> usando <code>az.rhat(‚ãÖ)</code>, <code>az.summary(‚ãÖ)</code> y <code>az.plot_forest(‚ãÖ, r_hat=True)</code></p>
</section>
<section id="gr√°fico-de-autocorrelaci√≥n" class="level3" data-number="5.3.5">
<h3 data-number="5.3.5" class="anchored" data-anchor-id="gr√°fico-de-autocorrelaci√≥n"><span class="header-section-number">5.3.5</span> Gr√°fico de autocorrelaci√≥n</h3>
<p>Idealmente, una muestra debe ser independiente e id√©nticamente distribuida (iid). Por definici√≥n, las muestras MCMC est√°n correlacionadas. En la pr√°ctica, queremos muestras con baja autocorrelaci√≥n. En ArviZ obtenemos este gr√°fico con la funci√≥n <code>az.plot_autocorr()</code></p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>cadenas_defectuosas <span class="op">=</span> {<span class="st">"cadenas_defectuosas"</span>: np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>).reshape(<span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>)}</span>
<span id="cb8-2"><a href="#cb8-2"></a>az.plot_autocorr(cadenas_defectuosas)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_Diagn√≥stico_MCMC_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>cadenas_adecuadas <span class="op">=</span> {<span class="st">"cadena_adecuadas"</span>: pz.Uniform(<span class="dv">0</span>, <span class="dv">1</span>).rvs(size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">500</span>))}</span>
<span id="cb9-2"><a href="#cb9-2"></a>az.plot_autocorr(cadenas_adecuadas)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_Diagn√≥stico_MCMC_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="tama√±o-de-muestra-efectivo-ess" class="level3" data-number="5.3.6">
<h3 data-number="5.3.6" class="anchored" data-anchor-id="tama√±o-de-muestra-efectivo-ess"><span class="header-section-number">5.3.6</span> Tama√±o de muestra efectivo (ESS)</h3>
<p>Como las muestras de un MCMC est√°n correlacionadas la cantidad de informaci√≥n ‚Äú√∫til‚Äù es menor que una muestra del mismo tama√±o pero iid.</p>
<br> <br>
<center>
<img src="diapo/img/ess.gif" width="600">
</center>
<p>Podemos estimar el <strong>tama√±o de muestra efectivo</strong> (ESS), es decir, el tama√±o de una muestra con la cantidad equivalente de informaci√≥n pero sin autocorrelaci√≥n. Esto es √∫til para determinar si la muestra que tenemos es lo suficientemente grande. Se recomienta que el ESS sea superior a 100 por cadena. Es decir para para 4 cadenas queremos un m√≠nimo de 400.</p>
<p>Con ArviZ podemos obtenerlo <code>az.ess(‚ãÖ)</code>, <code>az.summary(‚ãÖ)</code> y <code>az.plot_forest(‚ãÖ, ess=True)</code></p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>pd.concat((az.ess(cadenas_defectuosas).to_pandas(),</span>
<span id="cb10-2"><a href="#cb10-2"></a>           az.ess(cadenas_adecuadas).to_pandas()))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>cadenas_defectuosas      2.282878
cadena_adecuadas       910.058723
dtype: float64</code></pre>
</div>
</div>
<p>Vemos que <code>az.summary(‚ãÖ)</code> devuelve dos valores de ESS, <code>ess_bulk</code> y <code>ess_tail</code>. Esto se debe a que, distintas regiones del espacio de los par√°metros pueden tener distinto valor de ESS, ya que no todas las regiones son muestreadas con la misma eficiencia. Intuitivamente uno puede pensar que al muestrear una distribuci√≥n como una Gaussiana es m√°s f√°cil obtener mejor calidad de muestra alrededor de la media que de las colas, simplemente por que tenemos m√°s muestras de esa regi√≥n.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>pd.concat([az.summary(cadenas_adecuadas, kind<span class="op">=</span><span class="st">"diagnostics"</span>),</span>
<span id="cb12-2"><a href="#cb12-2"></a>           az.summary(cadenas_defectuosas, kind<span class="op">=</span><span class="st">"diagnostics"</span>)])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mcse_mean</th>
<th data-quarto-table-cell-role="th">mcse_sd</th>
<th data-quarto-table-cell-role="th">ess_bulk</th>
<th data-quarto-table-cell-role="th">ess_tail</th>
<th data-quarto-table-cell-role="th">r_hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">cadena_adecuadas</td>
<td>0.010</td>
<td>0.007</td>
<td>910.0</td>
<td>988.0</td>
<td>1.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">cadenas_defectuosas</td>
<td>0.198</td>
<td>0.165</td>
<td>2.0</td>
<td>11.0</td>
<td>3.05</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Si las muestras de MCMC las vamos a usar para calcular valores centrales como medias o medianas entonces tenemos que asegurarnos que el <code>ess_bulk</code> sea lo suficientemente algo, en cambio, si queremos calcular intervalos como un HDI 95% hay que asegurarse que <code>ess_tail</code> sea adecuado.</p>
<p>ArviZ ofrece varias funciones vinculadas al ESS. Por ejemplo si queremos evaluar el desempe√±o del sampler para varias regiones al mismo tiempo podemos usar <code>az.plot_ess</code>.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-2"><a href="#cb13-2"></a>az.plot_ess(cadenas_adecuadas, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb13-3"><a href="#cb13-3"></a>az.plot_ess(cadenas_defectuosas, ax<span class="op">=</span>axes[<span class="dv">1</span>])<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_Diagn√≥stico_MCMC_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Una forma simple de aumentar el ESS es aumentar la cantidad de muestras, pero podr√≠a darse el caso que el ESS crezca muy lento con el n√∫mero de muestras, por lo que a√∫n si aumentaramos 10 veces la cantidad de muestras estar√≠amos por debajo de lo requerido. Una forma de estimar ‚Äúcuanto nos falta‚Äù es usar <code>az.plot_ess(‚ãÖ, kind="evolution")</code>. Este gr√°fico nos muestra como fue cambiando el ESS con cada muestra, lo que nos permite hacer proyecciones. En el siguiente ejemplo vemos que para <code>cadenas_adecuadas</code> el ESS crece lineamente con el n√∫mero de muestras mientras que para <code>cadenas_defectuosas</code> no crece para nada. Este √∫ltimo caso no hay esperanzas de mejorar el ESS simplemente aumentando la cantidad de muestras.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-2"><a href="#cb14-2"></a>az.plot_ess(cadenas_adecuadas, kind<span class="op">=</span><span class="st">"evolution"</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb14-3"><a href="#cb14-3"></a>az.plot_ess(cadenas_defectuosas,  kind<span class="op">=</span><span class="st">"evolution"</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>])<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_Diagn√≥stico_MCMC_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="error-est√°ndard-del-monte-carlo-mcse" class="level3" data-number="5.3.7">
<h3 data-number="5.3.7" class="anchored" data-anchor-id="error-est√°ndard-del-monte-carlo-mcse"><span class="header-section-number">5.3.7</span> Error est√°ndard del Monte Carlo (MCSE)</h3>
<p>Una ventaja del ESS es que no tiene escala, da igual si un par√°metro var√≠a entre 0.1 y 0.2 y otro entre -2000 y 5000, un ESS de 400 tiene el mismo significado en ambos casos. En modelos con muchos par√°metros r√°pidamente podemos indentificar cuales par√°metros son m√°s problem√°ticos. Sin embargo, a la hora de reportar resultados no es muy informativo saber si el ESS fue de 1372 o 1501. En cambio nos gustar√≠a saber el orden del error que estamos cometiendo al aproximar la distribuci√≥n a posterori. Esa informaci√≥n la da el <strong>error est√°ndard del Monte Carlo</strong> (MCSE). Al igual que el ESS, el MCSE tiene en cuenta la autocorrelaci√≥n de las muestras. Este error debe estar por debajo de la precisi√≥n deseada en nuestros resultados. Es decir si para un par√°metro el MCSE es 0.1, no tiene sentido reportar que la media de ese par√°metro es 3.15. Ya que tranquilamente el valor correcto podr√≠a estar entre 3.4 y 2.8.</p>
<p>Una de las cantidades devueltas por <code>az.summary(‚ãÖ)</code> es mc_error.</p>
</section>
</section>
<section id="diagn√≥stico-de-algoritmos-basados-en-gradiente" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="diagn√≥stico-de-algoritmos-basados-en-gradiente"><span class="header-section-number">5.4</span> Diagn√≥stico de algoritmos basados en gradiente</h2>
<p>Debido a su funcionamiento interno, algoritmos como NUTS ofrecen algunas pruebas espec√≠ficas que no est√°n disponibles para otros m√©todos. Generalmente estas pruebas son muy sensibles</p>
<p>Para ejemplificar esto vamos a cargar dos InferenceData de modelos pre-calculados. Los detalles de como se generaron estos idatas no son relevantes por el momento. Solo diremos que son dos modelos que son matem√°ticamente equivalente pero parametrizados de formas distintas. En este caso la parametrizaci√≥n afecta la eficiencia del sampler. El modelo <code>centrado</code> es muestreado de forma m√°s eficiente que el modelo <code>no centrado</code>.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>idata_cm <span class="op">=</span> az.load_arviz_data(<span class="st">"centered_eight"</span>)</span>
<span id="cb15-2"><a href="#cb15-2"></a>idata_ncm <span class="op">=</span> az.load_arviz_data(<span class="st">"non_centered_eight"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="energ√≠a-de-transici√≥n-vs-energ√≠a-marginal" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="energ√≠a-de-transici√≥n-vs-energ√≠a-marginal"><span class="header-section-number">5.4.1</span> Energ√≠a de transici√≥n vs energ√≠a marginal</h3>
<p>Podemos pensar en un Monte Carlo Hamiltoniano como un proceso de dos pasos<br>
* Un muestreo determinista (siguiendo el hamiltoniano)<br>
* Una caminata aleatorio en el espacio del momentum</p>
<p>Si la distribuci√≥n de la energ√≠a de transici√≥n es similar a la distribuci√≥n de la energ√≠a marginal, entonces NUTS es capaz de generar muestras de la distribuci√≥n marginal de la energ√≠a que sean <em>casi</em> independientes entre transiciones. Esto lo podemos evaluar visualmente o num√©ricamente, calculando el Bayesian Fraction of Missing Information (BFMI), como se muestra en la siguiente figura.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>), constrained_layout<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-2"><a href="#cb16-2"></a></span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="cf">for</span> ax, idata, nombre <span class="kw">in</span> <span class="bu">zip</span>(axes.ravel(), (idata_cm, idata_ncm), (<span class="st">"centrado"</span>, <span class="st">"no centrado"</span>)):</span>
<span id="cb16-4"><a href="#cb16-4"></a>    az.plot_energy(idata, ax<span class="op">=</span>ax)</span>
<span id="cb16-5"><a href="#cb16-5"></a>    ax.set_title(nombre)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_Diagn√≥stico_MCMC_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="divergencias" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="divergencias"><span class="header-section-number">5.4.2</span> Divergencias</h3>
<p>Una ventaja de NUTS es que <em>falla con el estilo</em>. Esto sucede por ejemplo al intentar pasar de regiones de baja curvatura a regiones de alta curvatura. En estos casos las trayectorias num√©ricas pueden divergir. En esencia esto sucede por que en esos casos no existe un √∫nico conjunto de hiper-par√°metros que permita el muestreo eficiente de ambas regiones. Por lo que una de la regiones es muestreada adecuandamente y cuando el sampler se mueve hacia la otra regi√≥n falla. Las trayectorias num√©ricas divergentes son identificadores extremadamente sensibles de <em>vecindarios patol√≥gicos</em>.</p>
<p>El siguiente ejemplo muestra dos cosas el modelo <code>no centrado</code> muestra varias divergencias (c√≠rculos turquesas) agrupados en una regi√≥n. En el modelo <code>centrado</code>, que no tiene divergencias, se puede ver que alrededor de esa misma regi√≥n hay muestras para valores m√°s peque√±os de <code>tau</code>. Es decir el modelo <code>no centrado</code> falla en muestrear una regi√≥n, pero al menos avisa que est√° teniendo problemas en muestrear esa regi√≥n!</p>
<div class="cell" data-scrolled="true" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>), constrained_layout<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-2"><a href="#cb17-2"></a></span>
<span id="cb17-3"><a href="#cb17-3"></a></span>
<span id="cb17-4"><a href="#cb17-4"></a><span class="cf">for</span> ax, idata, nombre <span class="kw">in</span> <span class="bu">zip</span>(axes.ravel(), (idata_cm, idata_ncm), (<span class="st">"centrado"</span>, <span class="st">"no_centrado"</span>)):</span>
<span id="cb17-5"><a href="#cb17-5"></a>    az.plot_pair(idata, var_names<span class="op">=</span>[<span class="st">'theta'</span>, <span class="st">'tau'</span>], coords<span class="op">=</span>{<span class="st">'school'</span>:<span class="st">"Choate"</span>}, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb17-6"><a href="#cb17-6"></a>                 divergences<span class="op">=</span><span class="va">True</span>, divergences_kwargs<span class="op">=</span>{<span class="st">'color'</span>:<span class="st">'C1'</span>},</span>
<span id="cb17-7"><a href="#cb17-7"></a>                 ax<span class="op">=</span>ax)</span>
<span id="cb17-8"><a href="#cb17-8"></a>    ax.set_title(nombre)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_Diagn√≥stico_MCMC_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>az.plot_parallel(idata_cm, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_Diagn√≥stico_MCMC_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="qu√©-hacer-cuando-los-diagn√≥sticos-no-dan-bien" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="qu√©-hacer-cuando-los-diagn√≥sticos-no-dan-bien"><span class="header-section-number">5.5</span> Qu√© hacer cuando los diagn√≥sticos no dan bien?</h2>
<p><br></p>
<ul>
<li><p><font color="gray"> M√°s muestras o m√°s pasos de tuning. Esto solo suele ser √∫til cuando los problemas son menores</font></p></li>
<li><p><font color="gray"> Burn-in. Software moderno como PyMC utiliza una cantidad de muestras para ajustar los hiper-par√°metros de los m√©todos de muestreo. Por defecto esas muestras son eliminadas, por lo que en general no es necesario hacer Burn-in manualmente. </font></p></li>
<li><p><font color="gray"> Cambiar el m√©todo de muestreo! </font></p></li>
<li><p>Reparametrizar el modelo</p></li>
<li><p><font color="orange"> Mejorar las distribuciones <em>a priori</em> </font></p>
<ul>
<li>El <em>teorema popular</em> de la estad√≠stica computacional: Cuando tienes problemas computacionales, a menudo hay un problema con tu modelo. La recomendaci√≥n NO es cambiar la distribuci√≥n <em>a priori</em> para mejorar la calidad del muestreo. La recomendaci√≥n es que si el muestreo es malo, quiz√° el modelo tambi√©n lo sea. En ese caso, podemos pensar en mejorar el modelo, una forma de mejorarlo es usar conocimiento previo para mejorar las distribuciones <em>a priori</em>.</li>
</ul></li>
<li><p>Algunos modelos pueden expresarse en m√°s de una forma, todas matem√°ticamente equivalentes. En esos casos, algunas parametrizaciones pueden ser m√°s eficientes que otras. Por ejemplo, como veremos m√°s adelante con modelos lineales jer√°rquicos.</p></li>
<li><p>En el caso de las divergencias, estas suelen eliminarse aumentando la tasa de aceptaci√≥n (<code>pm.sample(..., target_accept=x)</code> x&gt;0.8)</p></li>
<li><p>Leer los mensajes de advertencia y sugerencias de PyMC! ;-)</p></li>
</ul>
</section>
<section id="ejercicios" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="ejercicios"><span class="header-section-number">5.6</span> Ejercicios</h2>
<ol type="1">
<li><p>Explic√° en tus propias palabras que es el ESS, el <span class="math inline">\(\hat R\)</span> y el MCSE. ¬øQu√© informaci√≥n nos dan?</p></li>
<li><p>¬øQu√© significa que el <span class="math inline">\(\hat R\)</span> sea 1.01? ¬øQu√© significa que sea 1.5? ¬øQu√© significa que sea 1.9?</p></li>
<li><p>¬øQu√© significa que el ESS sea 100? ¬øQu√© significa que sea 1000? ¬øQu√© significa que sea 10000?</p></li>
<li><p>Eleg√≠ al menos un modelo de los cap√≠tulos anteriores, genera un traceplot, un rank plot. Calcula el ESS, el <span class="math inline">\(R \hat\)</span> y el <span class="math inline">\(MCSE\)</span>. Ofrece una breve interpretaci√≥n de los resultados de los diag√≥sticos.</p></li>
</ol>
</section>
<section id="para-seguir-leyendo" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="para-seguir-leyendo"><span class="header-section-number">5.7</span> Para seguir leyendo</h2>
<p><a href="https://github.com/arviz-devs/Exploratory-Analysis-of-Bayesian-Models/tree/main/content">Exploratory Analysis of Bayesian Models</a> Trabajo en Progreso!</p>
<p><a href="https://arxiv.org/abs/1701.02434">A Conceptual Introduction to Hamiltonian Monte Carlo</a></p>
<p><a href="https://arxiv.org/abs/1903.08008">Rank-normalization, folding, and localization</a></p>
<p><a href="https://arxiv.org/abs/2004.06425">Computing Bayes: Bayesian Computation from 1763 to the 21st Century</a>.</p>


</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"state":{},"version_major":2,"version_minor":0}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./03_Modelos_jer√°rquicos.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Modelado Jer√°rquico</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./05_Regresi√≥n_lineal.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Regresi√≥n lineal</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center"><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Licencia Creative Commons" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png"></a><br>Este obra est√° bajo <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">licencia Creative Commons Reconocimiento 4.0 Internacional</a>.</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>